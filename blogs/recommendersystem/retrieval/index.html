<!doctype html><html lang=en class=no-js><head><script src=/js/critical.bundle.min.85a7f5f23dc031d38877ecdb71b00d49e8a62c54f1ba98e75a734706ea09f30a.js integrity="sha256-haf18j3AMdOId+zbcbANSeimLFTxupjnWnNHBuoJ8wo=" crossorigin=anonymous></script><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta name=generator content="Hugo 0.143.1"><meta name=theme content="Hinode 0.29.3"><link rel=stylesheet href="/css/main.min.2d9f08a384019794d7cb9e682556930966cd9db5fc51ca90d439a9f5b1032e59.css" integrity="sha256-LZ8Io4QBl5TXy55oJVaTCWbNnbX8UcqQ1Dmp9bEDLlk=" crossorigin=anonymous><link rel=preload href=/fonts/inter-v12-latin-regular.woff2 as=font type=font/woff2 crossorigin><meta name=robots content="index, follow"><meta name=googlebot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><meta name=bingbot content="index, follow, max-snippet:-1, max-image-preview:large, max-video-preview:-1"><title>EV's Blog - RecommenderSystem-2-召回</title>
<meta name=description content="【笔记】wangshusen-推荐系统：召回"><meta property="og:locale" content="en_US"><meta property="og:type" content="article"><meta property="og:title" content="RecommenderSystem-2-召回"><meta property="og:description" content="【笔记】wangshusen-推荐系统：召回"><meta property="og:url" content="https://eveydyw.github.io/blogs/recommendersystem/retrieval/"><meta property="og:site_name" content="EV's Blog"><meta property="article:published_time" content="2024-09-15T18:31:01+08:00"><meta property="article:modified_time" content="2024-09-15T18:31:01+08:00"><meta property="og:image" content="https://eveydyw.github.io/img/logo1280x640.png"><meta property="og:image:alt" content="RecommenderSystem-2-召回"><meta name=twitter:card content="summary_large_image"><meta name=twitter:title content="RecommenderSystem-2-召回"><meta name=twitter:description content="【笔记】wangshusen-推荐系统：召回"><meta name=twitter:image content="https://eveydyw.github.io/img/logo1280x640.png"><meta name=twitter:image:alt content="RecommenderSystem-2-召回"><script type=application/ld+json>{"@context":"https://schema.org","@graph":[{"@type":"Organization","@id":"https://eveydyw.github.io/#/schema/organization/1","name":"Hinode","url":"https://eveydyw.github.io/","sameAs":[null,"https://github.com/gethinode/hinode"],"logo":{"@type":"ImageObject","@id":"https://eveydyw.github.io/#/schema/image/1","url":"https://eveydyw.github.io/img/logo512x512.png","width":512,"height":512,"caption":"Hinode"},"image":{"@id":"https://eveydyw.github.io/#/schema/image/1"}},{"@type":"WebSite","@id":"https://eveydyw.github.io/#/schema/website/1","url":"https://eveydyw.github.io/","name":"EV\u0027s Blog","description":"Hinode is a clean documentation and blog theme for your Hugo site based on Bootstrap 5.","publisher":{"@id":"https://eveydyw.github.io/#/schema/organization/1"}},{"@type":"WebPage","@id":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/","url":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/","name":"RecommenderSystem-2-召回","description":"【笔记】wangshusen-推荐系统：召回","isPartOf":{"@id":"https://eveydyw.github.io/#/schema/website/1"},"about":{"@id":"https://eveydyw.github.io/#/schema/organization/1"},"datePublished":"2024-09-15T18:31:01CET","dateModified":"2024-09-15T18:31:01CET","breadcrumb":{"@id":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/#/schema/breadcrumb/1"},"primaryImageOfPage":{"@id":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/#/schema/image/2"},"inLanguage":"en-US","potentialAction":[{"@type":"ReadAction","target":["https://eveydyw.github.io/blogs/recommendersystem/retrieval/"]}]},{"@type":"BreadcrumbList","@id":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/#/schema/breadcrumb/1","name":"Breadcrumbs","itemListElement":[{"@type":"ListItem","position":1,"item":{"@type":"WebPage","@id":"https://eveydyw.github.io/","url":"https://eveydyw.github.io/","name":"Home"}},{"@type":"ListItem","position":2,"item":{"@type":"WebPage","@id":"https://eveydyw.github.io/blogs/","url":"https://eveydyw.github.io/blogs/","name":"Blogs"}},{"@type":"ListItem","position":3,"item":{"@type":"WebPage","@id":"https://eveydyw.github.io/blogs/recommendersystem/","url":"https://eveydyw.github.io/blogs/recommendersystem/","name":"Recommendersystem"}},{"@type":"ListItem","position":4,"item":{"@id":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/"}}]},{"@context":"https://schema.org","@graph":[{"@type":"ImageObject","@id":"https://eveydyw.github.io/blogs/recommendersystem/retrieval/#/schema/image/2","url":"https://eveydyw.github.io/img/logo1280x640.png","contentUrl":"https://eveydyw.github.io/img/logo1280x640.png","caption":"RecommenderSystem-2-召回"}]}]}</script><link rel=icon type=image/png sizes=16x16 href=/img/my_logo_hu_10729e67805acfd8.png><link rel=icon type=image/png sizes=32x32 href=/img/my_logo_hu_f267cd4735c3fb50.png><link rel=icon type=image/png sizes=48x48 href=/img/my_logo_hu_bc348718a5ba4099.png><link rel=apple-touch-icon sizes=180x180 href=/img/my_logo_hu_a8f52fe79483cdab.png><script>MathJax={loader:{load:["[tex]/html","[tex]/ams","[tex]/amscd"]},tex:{inlineMath:[["\\(","\\)"],["$","$"]],displayMath:[["\\[","\\]"],["$$","$$"]],processEscapes:!0,packages:["base","ams","amscd"],tags:"ams"},options:{skipHtmlTags:["script","noscript","style","textarea","pre","code"],renderActions:{addMenu:[0,"",""],checkLoading:[0,"",""]}},chtml:{scale:1,displayAlign:"center",displayIndent:"0em",lineWidth:"container"},svg:{fontCache:"global"}}</script><script id=MathJax-script async src=https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-svg.js></script></head><body><div class="d-flex flex-column min-vh-100"><div class="d-flex flex-column"><div class="container-fluid fixed-top p-0"><nav class="navbar p-4 bg-body navbar-fixed-top navbar-expand-md"><div class="container-xxl p-0"><div class="d-flex navbar-container justify-content-center"><div class="d-flex align-items-center"><button class="navbar-toggler collapsed p-0 mx-auto invisible fw-30" type=button><svg class="svg-inline--fa fas fa-ellipsis fa-fw" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 448 512"><use href="#fas-ellipsis"/></svg></button></div><div class=mx-auto><a class=navbar-brand href=/ aria-label=Home><img src=/img/my_logo.svg alt="EV's Blog logo" height=30 width=30></a></div><div class="d-flex align-items-center"><button class="navbar-toggler main-nav-toggler collapsed p-0" type=button data-bs-toggle=collapse data-bs-target=#navbar-0-collapse aria-controls=navbar-0 aria-expanded=false aria-label="Toggle main navigation">
<span class="toggler-icon top-bar emphasis"></span>
<span class="toggler-icon middle-bar emphasis"></span>
<span class="toggler-icon bottom-bar emphasis"></span></button></div></div><div class="navbar-collapse collapse" id=navbar-0-collapse><div class="d-flex flex-fill ms-md-3 mt-4 mt-md-0"><form class="search flex-fill position-relative me-auto"><input class="search-input form-control is-search" type=search placeholder="Search this site" aria-label="Search this site" autocomplete=off name=search-input><div class="search-suggestions shadow bg-body rounded d-none" data-no-results="No results for"></div></form></div><ul class="navbar-nav ms-auto"><li class=nav-item><a class=nav-link data-nav=main data-nav-main=home href=/><span>Home</span>&nbsp;</a></li><li class=nav-item><a class=nav-link data-nav=main data-nav-main=blogs href=/blogs/><span>Blogs</span>&nbsp;</a></li><li class=nav-item><a class=nav-link data-nav=main data-nav-main=tags href=/tags><span>Tags</span>&nbsp;</a></li><li class="d-flex mode-switch align-items-center" id=navbar-mode><input type=checkbox class="checkbox navbar-mode-selector" id=navbar-mode-checkbox aria-label="Toggle theme">
<label class=label for=navbar-mode-checkbox><svg class="svg-inline--fa fas fa-sun fa-fw" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 512 512"><use href="#fas-sun"/></svg><svg class="svg-inline--fa fas fa-moon fa-fw" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 384 512"><use href="#fas-moon"/></svg><div class=ball></div></label></li></ul></div></div></nav></div><div class=main-content></div></div><div class="container-xxl flex-fill p-4 px-xxl-0"><div class="row row-cols-1 row-cols-md-2 row-cols-lg-3"><div class="col col-lg-2 d-none d-lg-block sidebar-overflow sticky-top pt-5"></div><div class="col-12 col-md-9 col-lg-8 mb-5 p-4"><nav aria-label=breadcrumb class=d-sm-none><ol class=breadcrumb><li class=breadcrumb-item><a href=/blogs/recommendersystem/><svg class="svg-inline--fa fas fa-angle-left" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 320 512"><use href="#fas-angle-left"/></svg>&nbsp;&nbsp;RecommenderSystem</a></li></ol></nav><nav aria-label=breadcrumb class="d-none d-sm-block"><ol class=breadcrumb><li class=breadcrumb-item><a href=/>Home</a></li><li class=breadcrumb-item><a href=/blogs/>Blogs</a></li><li class=breadcrumb-item><a href=/blogs/recommendersystem/>RecommenderSystem</a></li><li class="breadcrumb-item active" aria-current=page>RecommenderSystem-2-召回</li></ol></nav><p class="display-4 mt-5">RecommenderSystem-2-召回</p><small class="text-body-secondary text-uppercase">Posted on September 15, 2024
&bull;
19&nbsp;min read &bull;
3,914&nbsp;words</small><p class="lead mb-5 mt-3">【笔记】wangshusen-推荐系统：召回</p><div class="d-md-none pb-5"><div class="d-grid gap-2 mx-auto"><a aria-label="On this page" href=#toc-collapse class="btn btn-outline-secondary position-relative toc-button" data-bs-toggle=collapse aria-expanded=false aria-controls=toc-collapse role=button><span class="d-flex justify-content-between"><span class=my-auto>On this page</span><span class="align-self-center ps-1"><svg class="svg-inline--fa fas fa-sort" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 320 512"><use href="#fas-sort"/></svg></span></span></a></div><div class="collapse border bg-body-tertiary rounded p-1 navbar-nav-scroll" id=toc-collapse><small><div class="toc toc-panel text-body p-2"><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#基于物品的协同过滤itemcf>基于物品的协同过滤（ItemCF） </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#物品相似度>物品相似度 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#itemcf-召回的完整流程>ItemCF 召回的完整流程 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-2>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#swing-召回通道>Swing 召回通道 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#基于用户的协同过滤usercf>基于用户的协同过滤（UserCF） </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#用户的相似度>用户的相似度 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#usercf-召回的完整流程>UserCF 召回的完整流程 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-4>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#离散特征处理>离散特征处理 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#one-hot-编码>One-Hot 编码 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#embedding嵌入>Embedding(嵌入) </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#embedding-与-one-hot-编码-的关系>Embedding 与 One-Hot 编码 的关系 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-5>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#矩阵补充>矩阵补充 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#模型结构>模型结构 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#模型训练>模型训练 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#矩阵补充的缺点>矩阵补充的缺点 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#线上服务>线上服务 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-6>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#近似最近邻查找-approximate-nearest-neighbor-search>近似最近邻查找 （Approximate Nearest Neighbor Search） </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-7>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#双塔模型>双塔模型 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#模型和训练>模型和训练 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#正负样本>正负样本 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#线上召回和更新>线上召回和更新 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#双塔模型自监督学习>双塔模型+自监督学习 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#deep-retrieval>Deep Retrieval </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#索引-2>索引 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#预估模型>预估模型 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#线上召回-1>线上召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#训练-1>训练 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-13>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#其它召回通道>其它召回通道 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#地理位置召回>地理位置召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#作者召回>作者召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#缓存召回>缓存召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-14>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#曝光过滤--bloom-filter>曝光过滤 & Bloom Filter </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#曝光过滤问题>曝光过滤问题 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#bloom-filter>Bloom Filter </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#曝光过滤的链路>曝光过滤的链路 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#bloom-filter-的缺点>Bloom Filter 的缺点</a></div></small></div></div><div class=content><h2 id=基于物品的协同过滤itemcf class=heading>基于物品的协同过滤（<code>ItemCF</code>）<a href=#%e5%9f%ba%e4%ba%8e%e7%89%a9%e5%93%81%e7%9a%84%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4itemcf aria-labelledby=基于物品的协同过滤itemcf><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><strong>基于物品的协同过滤 (Item collaborative filtering)</strong></p><p><strong>【<code>ItemCF </code>的原理】</strong></p><p>从用户的行为中挖掘出物品之间的相似性，再利用物品之间的相似性做推荐。</p><p><strong>【<code>ItemCF </code>的实现】</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250401220256859.png width=50% alt></center><p>量化用户对物品的兴趣，如点击、点赞、收藏、转发，这四种行为各算
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>分</p><ul><li>例如图中用户对四个物品的兴趣分数分别是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>。</li></ul><p>右边是用户没有交互过的候选物品，我们要决定是否把这个物品推荐给用户</p><ul><li><p>假设我们知道物品两两之间的相似度，比如他们的相似度分别是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.1</mn></mrow><annotation encoding="application/x-tex">0.1</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.4</mn></mrow><annotation encoding="application/x-tex">0.4</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.2</mn></mrow><annotation encoding="application/x-tex">0.2</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.6</mn></mrow><annotation encoding="application/x-tex">0.6</annotation></semantics></math></span>
</span>。</p></li><li><p>用公式来预估 <strong>用户对候选物品的兴趣</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><munder><munder><mrow><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>用户对第 j 个物品的兴趣</mtext></munder><mo>×</mo><munder><munder><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>第 j 个物品与候选物品之间的相似度</mtext></munder></mrow><annotation encoding="application/x-tex">
  \sum_{j} \underbrace{\mathrm{like}(\mathrm{user}, \mathrm{item}_j)}_{\text{用户对第 j 个物品的兴趣}} \times \underbrace{\mathrm{sim}(\mathrm{item}_j, \mathrm{item})}_{\text{第 j 个物品与候选物品之间的相似度}}
  </annotation></semantics></math></span></div><p>预估用户对候选物品的兴趣：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo><mn>0.1</mn><mo>+</mo><mn>1</mn><mo>×</mo><mn>0.4</mn><mo>+</mo><mn>4</mn><mo>×</mo><mn>0.2</mn><mo>+</mo><mn>3</mn><mo>×</mo><mn>0.6</mn><mo>=</mo><mn>3.2</mn></mrow><annotation encoding="application/x-tex">2\times0.1 + 1\times0.4 + 4\times0.2 + 3\times0.6 = 3.2</annotation></semantics></math></span></span></p></li></ul><p><strong>【例】</strong>
有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2000</mn></mrow><annotation encoding="application/x-tex">2000</annotation></semantics></math></span>
</span>个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回其中分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品。</p><h3 id=物品相似度 class=heading>物品相似度<a href=#%e7%89%a9%e5%93%81%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-labelledby=物品相似度><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p>两个物品的受众重合度越高，两个物品越相似。</p><p>可以从数据中挖掘出物品的相似度：喜欢《射雕英雄传》和《神雕侠侣》的读者重合度很高，可以认为《射雕英雄传》和《神雕侠侣》相似。</p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401220852808.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401220918575.png width=45% alt></center><h4 id=计算物品相似度 class=heading>计算物品相似度<a href=#%e8%ae%a1%e7%ae%97%e7%89%a9%e5%93%81%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-labelledby=计算物品相似度><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">W</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{W}_1</annotation></semantics></math></span>
</span>：喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span>
</span>的用户集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{W}_2</annotation></semantics></math></span>
</span>：喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span>
</span>的用户集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi><mo>=</mo><msub><mi mathvariant="script">W</mi><mn>1</mn></msub><mo>∩</mo><msub><mi mathvariant="script">W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{V} =  \mathcal{W}_1 \cap \mathcal{W}_2</annotation></semantics></math></span></span></p></li><li><p><strong>两个物品的相似度</strong>(没有考虑喜欢的程度 like(user, item)):</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="script">V</mi><mi mathvariant="normal">∣</mi></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">W</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">W</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">
  \begin{align}
  \mathrm{sim}(i_1, i_2)=\frac{|\mathcal{V}|}{\sqrt{|\mathcal{W}_1|\cdot|\mathcal{W}_2|}} \in [0,1]
  \end{align}
  </annotation></semantics></math></span></div></li><li><p>考虑用户喜欢物品的程度</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mi mathvariant="script">V</mi></mrow></munder><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><msub><mi>i</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo>⋅</mo><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mi>v</mi><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><mrow><msqrt><mrow><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>1</mn></msub><mo>∈</mo><msub><mi mathvariant="script">W</mi><mn>1</mn></msub></mrow></munder><msup><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mn>2</mn></msup><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>1</mn></msub><mo stretchy="false">)</mo></mrow></msqrt><mo>⋅</mo><msqrt><mrow><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>2</mn></msub><mo>∈</mo><msub><mi mathvariant="script">W</mi><mn>2</mn></msub></mrow></munder><msup><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mn>2</mn></msup><mo stretchy="false">(</mo><msub><mi>u</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></msqrt></mrow></mfrac><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">
  \begin{align}
  \mathrm{sim}(i_1, i_2)=\frac{\sum_{v\in\mathcal{V}}\mathrm{like}(v, i_1)\cdot \mathrm{like}(v, i_2)}{\sqrt{\sum_{u_1\in \mathcal{W}_1}\mathrm{like}^2(u_1, i_1)}\cdot \sqrt{\sum_{u_2\in \mathcal{W}_2}\mathrm{like}^2(u_2, i_2)}} \in [0,1]
  \end{align}
  </annotation></semantics></math></span></div><p>即<strong>余弦相似度（Cosine similarity）</strong>：</p><ul><li><p>把一个物品表示为一个向量，向量每个元素对应一个用户。</p></li><li><p>元素的值就是用户对物品的兴趣分数。</p></li><li><p>两个向量的夹角的余弦就是这个公式。</p></li></ul></li></ul><h4 id=总结 class=heading>总结<a href=#%e6%80%bb%e7%bb%93 aria-labelledby=总结><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong><code>ItemCF</code> 的基本思想</strong>：</p><ul><li>如果用户喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{item}_1</annotation></semantics></math></span>
</span>, 而且物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{item}_1</annotation></semantics></math></span>
</span>与
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{item}_2</annotation></semantics></math></span>
</span>相似</li><li>那么用户很可能喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{item}_1</annotation></semantics></math></span>
</span>。</li></ul><p><strong>预估用户对候选物品的兴趣</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\sum_{j}\mathrm{like}(\mathrm{user}, \mathrm{item}_j) \times \mathrm{sim}(\mathrm{item}_j, \mathrm{item})
</annotation></semantics></math></span></div><p><strong>计算两个物品的相似度</strong>：</p><ul><li>把每个物品表示为一个稀疏向量，向量每个元素对应一个用户。</li><li>相似度
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{sim}(i_1,i_2)</annotation></semantics></math></span>
</span>就是两个向量夹角的余弦。</li></ul><h3 id=itemcf-召回的完整流程 class=heading><code>ItemCF </code>召回的完整流程<a href=#itemcf-%e5%8f%ac%e5%9b%9e%e7%9a%84%e5%ae%8c%e6%95%b4%e6%b5%81%e7%a8%8b aria-labelledby=itemcf-召回的完整流程><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=索引 class=heading>索引<a href=#%e7%b4%a2%e5%bc%95 aria-labelledby=索引><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>为了能在线上做到实时的推荐系统，必须要 <strong>事先做离线计算</strong>。</p><ul><li><p><strong>建立 “
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>" 的索引</strong>。</p><ul><li><p>记录每个用户最近点击、交互过的物品 ID。</p></li><li><p>给定任意用户 ID，可以找到他近期感兴趣的物品列表。</p></li></ul></li><li><p><strong>建立 “
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>物品 </mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{物品 } \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>”的索引</strong>。</p><ul><li><p>计算物品之间两两相似度。</p></li><li><p>对于每个物品，索引它最相似的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品。</p></li><li><p>给定任意物品 ID，可以快速找到它最相似的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品。</p></li></ul></li></ul><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401221526069.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401221551954.png width=45% alt></center><h4 id=线上做召回 class=heading>线上做召回<a href=#%e7%ba%bf%e4%b8%8a%e5%81%9a%e5%8f%ac%e5%9b%9e aria-labelledby=线上做召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ol><li><p><strong>给定用户 ID</strong>，通过 <strong>“
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>”</strong> 索引，找到用户近期感兴趣的物品列表 (<strong><code>last-n</code></strong>)</p><p>记录用户最近感兴趣的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>200</mn></mrow><annotation encoding="application/x-tex">n= 200</annotation></semantics></math></span>
</span>个物品。</p></li><li><p>对于 <code>last-n</code> 列表中 <strong>每个物品</strong>，通过 <strong>“
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>物品 </mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{物品 } \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>”</strong> 的索引找到 <strong><code>top-k</code></strong> 相似物品。</p><p>取回每个物品最相似的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>10</mn></mrow><annotation encoding="application/x-tex">k= 10</annotation></semantics></math></span>
</span>个物品。</p></li><li><p>对于取回的相似物品：（最多有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span>
</span>个），用公式预估用户对物品的兴趣分数。</p><p>给取回的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi><mo>=</mo><mn>2000</mn></mrow><annotation encoding="application/x-tex">nk= 2000</annotation></semantics></math></span>
</span>个物品打分（用户对物品的兴趣)。</p></li><li><p>返回分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品，作为推荐结果。</p><p>返回分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品作为 <code>ItemCF</code> 通道的输出。</p></li></ol><ul><li><p><strong>索引的意义在于避免枚举所有的物品。</strong></p></li><li><p><strong>用索引，离线计算量大，线上计算量小。</strong></p></li></ul><h4 id=总结-1 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-1 aria-labelledby=总结-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250401221850401.png width=50% alt></center><ol><li><p>给定用户的 id，利用用户到物品的索引找到用户近期感兴趣的物品。这个列表记录了物品的 id 和兴趣分数。</p></li><li><p>利用物品到物品的索引找到每个物品的 <code>top k</code> 相似物品的 id 和相似度。</p></li><li><p>计算用户对召回物品的兴趣分数。做计算的时候，如果取回的物品 id 有重复则去重把分数加起来</p></li><li><p>根据算出的分数做排序，返回排在前
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>的物品。</p></li></ol><h3 id=总结-2 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-2 aria-labelledby=总结-2><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><strong><code>ItemCF</code> 的原理</strong></p><ul><li><p>用户喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span>
</span>，那么用户喜欢与物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span>
</span>相似的物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span>
</span>。</p></li><li><p>物品相似度：<strong>根据用户的行为来判定物品相似</strong> 而不是根据物品的内容判定物品相似。</p><ul><li><p>如果喜欢
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span>
</span>的用户有很大的重叠，那么
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span>
</span>相似。</p></li><li><p>公式：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">W</mi><mn>1</mn></msub><mo>∩</mo><msub><mi mathvariant="script">W</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">W</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">W</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathrm{sim}(i_1,i_2)=\frac{ |\mathcal{W}_1 \cap \mathcal{W}_2|}{\sqrt{|\mathcal{W}_1|\cdot|\mathcal{W}_2|}} \in [0,1]</annotation></semantics></math></span></span></p></li></ul></li></ul><hr><p><strong><code>ItemCF</code> 召回通道</strong></p><ul><li><p>维护两个索引：</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>列表：用户最近交互过的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个物品。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>物品 </mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{物品 } \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>列表：相似度最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品。</p></li></ul></li><li><p>线上做召回：</p><ul><li><p>利用两个索引，每次取回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span>
</span>个物品。</p></li><li><p>预估用户对每个物品的兴趣分数。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
    \sum_{j}\mathrm{like}(\mathrm{user}, \mathrm{item}_j) \times \mathrm{sim}(\mathrm{item}_j, \mathrm{item})
    </annotation></semantics></math></span></div></li><li><p>返回分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品，作为召回结果。</p></li></ul></li></ul><h2 id=swing-召回通道 class=heading>Swing 召回通道<a href=#swing-%e5%8f%ac%e5%9b%9e%e9%80%9a%e9%81%93 aria-labelledby=swing-召回通道><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><strong><code>Swing</code></strong> 跟 <strong><code>Itemcf</code></strong> 区别在于 <strong>怎么样定义物品的相似度</strong>。</p><hr><p><strong><code>Itemcf</code> 的缺点</strong>：</p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250401222315046.png width=50% alt></center><p>假如重合的用户是一个小圈子。</p><p>比方说
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>个用户都在同一个微信群里面，左边的物品是笔记：某网站护肤品打折，右边的物品是笔记：字节裁员了。这两篇笔记没有什么相似之处，他们的受众差别很大，但是两篇笔记碰巧被分享到同一个微信群里面，微信群里有很多人同时点开这两篇笔记。</p><p>这样就造成一个问题：两篇笔记的受众完全不同，但是很多用户同时交互过两篇笔记，导致系统错误的判断两篇笔记的相似度很高。</p><p>想要解决这个问题，就要降低小圈子用户的权重。我们希望两个物品重合的用户广泛而且多样，而不是集中在一个小圈子里。一个小圈子的用户同时交互两个物品不能说明两个物品相似。反过来，如果大量不相关的用户同时交互两个物品，则说明两个物品有相同的受众。</p><p><code>Swing</code> 模型的原理就是给 <strong>用户设置权重</strong>，解决小圈子问题。</p><hr><p><strong>Swing 模型</strong></p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">J</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{J}_1</annotation></semantics></math></span>
</span>：用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>喜欢的物品集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">J</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{J}_2</annotation></semantics></math></span>
</span>：用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>喜欢的物品集合。</p></li><li><p><strong>定义两个用户的重合度</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">p</mi></mrow><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mo>∩</mo><msub><mi mathvariant="script">J</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow><annotation encoding="application/x-tex">
  \mathrm{overlap}(u_1, u_2)=|\mathcal{J}_1\cap \mathcal{J}_2|
  </annotation></semantics></math></span></div><p><code>overlap</code> 值越大，说明两个用户的重合度越高，越有可能是一个小圈子的人，要降低他们的权重。</p></li><li><p>用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>和 用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>的重合度高，他们可能来自一个小圈子，要降低他们的权重。</p></li></ul><hr><p><strong>Swing 模型</strong></p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">W</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{W}_1</annotation></semantics></math></span>
</span>：喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">i_1</annotation></semantics></math></span>
</span>的用户集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{W}_2</annotation></semantics></math></span>
</span>：喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>i</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">i_2</annotation></semantics></math></span>
</span>的用户集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi><mo>=</mo><msub><mi mathvariant="script">W</mi><mn>1</mn></msub><mo>∩</mo><msub><mi mathvariant="script">W</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{V} =  \mathcal{W}_1 \cap \mathcal{W}_2</annotation></semantics></math></span></span></p></li><li><p>两个物品的相似度:</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>i</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>i</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>1</mn></msub><mo>∈</mo><mi mathvariant="script">V</mi></mrow></munder><munder><mo>∑</mo><mrow><msub><mi>u</mi><mn>2</mn></msub><mo>∈</mo><mi mathvariant="script">V</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>α</mi><mo>+</mo><mrow><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">p</mi></mrow><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">
  \mathrm{sim}(i_1, i_2)=\sum_{u_1\in\mathcal{V}}\sum_{u_2\in\mathcal{V}}\frac1{\alpha+\mathrm{ overlap}(u_1, u_2)}
  </annotation></semantics></math></span></div><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span>
</span>是个人工设置的参数需要调。</p></li><li><p><code>overlap</code>：用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>和用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>的重叠有多大。</p><ul><li><p><code>overlap</code> 大，说明两个人是一个小圈子的，那么他们两个人对相似的贡献会比较小。</p></li><li><p><code>overlap</code> 小，则他们对相似度的贡献比较大</p></li></ul></li></ul><p>用 <code>overlap</code> 可以降低小圈子对相似度的影响。</p></li></ul><hr><p><strong>总结</strong></p><ul><li><p><code>Swing</code> 与 <code>ItemCF</code> 唯一的区别在于物品相似度。</p></li><li><p><code>ItemCF</code>：两个物品重合的用户比例高，则判定两个物品相似。</p></li><li><p><code>Swing</code>：额外考虑重合的用户是否来自一个小圈子。</p><ul><li>同时喜欢两个物品的用户记作集合
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">\mathcal{V}</annotation></semantics></math></span>
</span>。</li><li>对于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">V</mi></mrow><annotation encoding="application/x-tex">\mathcal{V}</annotation></semantics></math></span>
</span>中的用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>和用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>，重合度记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">o</mi><mi mathvariant="normal">v</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">p</mi></mrow><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{ overlap}(u_1,u_2)</annotation></semantics></math></span></span></li><li>两个用户重合度大，则可能来自一个小圈子，权重降低</li></ul></li></ul><p>总而言之，<code>Swing</code> 与 <code>ItemCF</code> 的区别就是在计算物品相似度的时候，要降低小圈子用户的影响。</p><h2 id=基于用户的协同过滤usercf class=heading>基于用户的协同过滤（<code>UserCF</code>）<a href=#%e5%9f%ba%e4%ba%8e%e7%94%a8%e6%88%b7%e7%9a%84%e5%8d%8f%e5%90%8c%e8%bf%87%e6%bb%a4usercf aria-labelledby=基于用户的协同过滤usercf><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><strong>基于用户的协同过滤 (User collaborative filtering)</strong></p><p><strong>【<code>UserCF</code> 的原理】</strong></p><p>推荐系统如何找到跟我兴趣非常相似的网友呢？</p><ol><li><p>点击、点赞、收藏、转发的笔记有很大的重合。</p></li><li><p>关注的作者有很大的重合。</p></li></ol><p><strong>【<code>UserCF</code> 的实现】</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250401223116369.png width=50% alt></center><p>在用 <code>UserCF</code> 做推荐之前需要先计算每两个用户之间的相似度。</p><ul><li>用户之间的相似度数值越大, 表示用户越相似。</li></ul><p>右边是用户没有交互过的候选物品，我们想要预估左边的用户对右边的候选物品的兴趣有多大。</p><ul><li><p>历史数据反应要用户对物品的兴趣，比如点击、点赞、收藏、转发四种行为各算
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>分。</p></li><li><p>四位用户对候选物品的兴趣分数分别是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>， 分数越大，表示用互对物品越感兴趣，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>表示用户没有看过物品或者对物品不感兴趣。</p></li><li><p>用公式来预估 <strong>用户对候选物品的兴趣</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><munder><munder><mrow><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>用户与第 j 个用户之间的相似度</mtext></munder><mo>×</mo><munder><munder><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mi>j</mi></msub><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>第 j 个用户对候选物品的兴趣</mtext></munder></mrow><annotation encoding="application/x-tex">
  \sum_{j} \underbrace{\mathrm{like}(\mathrm{user}, \mathrm{item}_j)}_{\text{用户与第 j 个用户之间的相似度}} \times \underbrace{\mathrm{sim}(\mathrm{item}_j, \mathrm{item})}_{\text{第 j 个用户对候选物品的兴趣}}
  </annotation></semantics></math></span></div><p>预估用户对候选物品的兴趣：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.9</mn><mo>×</mo><mn>0</mn><mo>+</mo><mn>0.7</mn><mo>×</mo><mn>1</mn><mo>+</mo><mn>0.7</mn><mo>×</mo><mn>3</mn><mo>+</mo><mn>0.4</mn><mo>×</mo><mn>0</mn><mo>=</mo><mn>2.8</mn></mrow><annotation encoding="application/x-tex">0.9 \times 0 + 0.7 \times 1 + 0.7\times 3 + 0.4\times 0 = 2.8</annotation></semantics></math></span></span></p></li></ul><p>【例】
有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2000</mn></mrow><annotation encoding="application/x-tex">2000</annotation></semantics></math></span>
</span>个候选物品，我们逐一计算用户对候选物品的兴趣分数，然后返回其中分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品。</p><h3 id=用户的相似度 class=heading>用户的相似度<a href=#%e7%94%a8%e6%88%b7%e7%9a%84%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-labelledby=用户的相似度><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><strong>用户的相似度，指用户有共同的兴趣点。</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401223422971.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401223401421.png width=45% alt></center><h4 id=计算用户相似度 class=heading>计算用户相似度<a href=#%e8%ae%a1%e7%ae%97%e7%94%a8%e6%88%b7%e7%9b%b8%e4%bc%bc%e5%ba%a6 aria-labelledby=计算用户相似度><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">J</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{J}_1</annotation></semantics></math></span>
</span>：用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>喜欢的物品集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="script">J</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{J}_2</annotation></semantics></math></span>
</span>：用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>喜欢的物品集合。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">I</mi><mo>=</mo><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mo>∩</mo><msub><mi mathvariant="script">J</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathcal{I} =  \mathcal{J}_1 \cap \mathcal{J}_2</annotation></semantics></math></span></span></p></li><li><p>两个用户的相似度 (不论冷门、热门，物品权重都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>):</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="script">I</mi><mi mathvariant="normal">∣</mi></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi mathvariant="script">I</mi></mrow></munder><mn>1</mn></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">
  \mathrm{sim}(u_1, u_2)=\frac{|\mathcal{I}|}{\sqrt{|\mathcal{J}_1|\cdot|\mathcal{J}_2|}}=\frac{\sum_{l\in \mathcal{I}}1}{\sqrt{|\mathcal{J}_1|\cdot|\mathcal{J}_2|}} \in [0,1]
  </annotation></semantics></math></span></div></li><li><p>降低热门物品权重</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><munder><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi mathvariant="script">I</mi></mrow></munder><mfrac><mn>1</mn><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msub><mi>n</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
  \sin(u_1, u_2)=\frac{\sum_{l\in \mathcal{I}}\frac1{\log(1+n_l)}}{\sqrt{|\mathcal{J}_1|\cdot|\mathcal{J}_2|}}.
  </annotation></semantics></math></span></div><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msub><mi>n</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac1{\log(1+n_l)}</annotation></semantics></math></span>
</span>: 物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span>
</span>的权重。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">n_l</annotation></semantics></math></span>
</span>：喜欢物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span>
</span>的用户数量，反映物品的热门程度。</p></li><li><p>物品越热门，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>n</mi><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">n_l</annotation></semantics></math></span>
</span>越大，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mn>1</mn><mrow><mi>log</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>+</mo><msub><mi>n</mi><mi>l</mi></msub><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac1{\log(1+n_l)}</annotation></semantics></math></span>
</span>越小，即物品权重越小。</p></li><li><p>冷门物品的贡献度更大。</p></li></ul></li></ul><h4 id=总结-3 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-3 aria-labelledby=总结-3><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>UserCF 的基本思想</strong>：</p><ul><li><p>如果用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{user}_1</annotation></semantics></math></span>
</span>跟用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{user}_2</annotation></semantics></math></span>
</span>相似，而且
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{user}_2</annotation></semantics></math></span>
</span>喜欢某物品。</p></li><li><p>那么用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{user}_1</annotation></semantics></math></span>
</span>也很可能喜欢该物品。</p></li></ul><p><strong>预估用户 user 对候选物品 item 的兴趣</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mi>j</mi></msub><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
\sum_{j}\mathrm{sim}(\mathrm{user}, \mathrm{user}_j) \times \mathrm{like}(\mathrm{user}_j, \mathrm{item})
</annotation></semantics></math></span></div><p><strong>计算两个用户的相似度</strong>：</p><ul><li><p>把每个用户表示为一个稀疏向量，向量每个元素对应一个物品。</p></li><li><p>相似度
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{sim}(u_1,u_2)</annotation></semantics></math></span>
</span>就是两个向量夹角的余弦</p></li></ul><h3 id=usercf-召回的完整流程 class=heading>UserCF 召回的完整流程<a href=#usercf-%e5%8f%ac%e5%9b%9e%e7%9a%84%e5%ae%8c%e6%95%b4%e6%b5%81%e7%a8%8b aria-labelledby=usercf-召回的完整流程><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=索引-1 class=heading>索引<a href=#%e7%b4%a2%e5%bc%95-1 aria-labelledby=索引-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>为了能在线上做到实时的推荐系统，必须要 <strong>事先做离线计算</strong>。</p><ul><li><p><strong>建立“
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>" 的索引</strong> 。</p><ul><li><p>记录每个用户最近点击、交互过的物品 ID。</p></li><li><p>给定任意用户 ID，可以找到他近期感兴趣的物品列表。</p></li></ul></li><li><p><strong>建立“
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>用户</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{用户}</annotation></semantics></math></span>
</span>”的索引</strong>。</p><ul><li><p>计算用户之间两两相似度。</p></li><li><p>对于每个用户，索引它最相似的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个用户。</p></li><li><p>给定任意用户 ID，可以快速找到它最相似的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个用户。</p></li></ul></li></ul><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401223927488.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250401223956438.png width=45% alt></center><h4 id=线上做召回-1 class=heading>线上做召回<a href=#%e7%ba%bf%e4%b8%8a%e5%81%9a%e5%8f%ac%e5%9b%9e-1 aria-labelledby=线上做召回-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ol><li><p><strong>给定用户 ID</strong>，通过 <strong>“
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>用户</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{用户}</annotation></semantics></math></span>
</span>”</strong> 索引，找到 <strong><code>top-k</code></strong> 相似用户。</p></li><li><p>对于每个 <strong><code>top-k</code></strong> 相似用户，通过 <strong>“
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>”</strong> 的索引找到用户近期感兴趣的物品列表 <strong>(<code>last-n</code>)</strong>。</p></li><li><p>对于取回的相似物品：（最多有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span>
</span>个），用公式预估用户对物品的兴趣分数。</p></li><li><p>返回分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品作为 <code>UserCF</code> 通道的输出。</p></li></ol><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250401224128187.png width=50% alt></center><h3 id=总结-4 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-4 aria-labelledby=总结-4><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><strong><code>UserCF</code> 的原理</strong></p><ul><li><p>用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>跟用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>相似，而且
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>喜欢某物品，那么
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>也可能喜欢该物品。</p></li><li><p>用户相似度：</p><ul><li><p>如果用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>跟用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>喜欢的物品有很大的重叠，那么
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">u_1</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>u</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">u_2</annotation></semantics></math></span>
</span>相似。</p></li><li><p>公式：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><msub><mi>u</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>u</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∣</mi><mi mathvariant="script">I</mi><mi mathvariant="normal">∣</mi></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mo>=</mo><mfrac><mrow><msub><mo>∑</mo><mrow><mi>l</mi><mo>∈</mo><mi mathvariant="script">I</mi></mrow></msub><mn>1</mn></mrow><msqrt><mrow><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mo>⋅</mo><mi mathvariant="normal">∣</mi><msub><mi mathvariant="script">J</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi></mrow></msqrt></mfrac><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\mathrm{sim}(u_1, u_2)=\frac{|\mathcal{I}|}{\sqrt{|\mathcal{J}_1|\cdot|\mathcal{J}_2|}}=\frac{\sum_{l\in \mathcal{I}}1}{\sqrt{|\mathcal{J}_1|\cdot|\mathcal{J}_2|}} \in [0,1]</annotation></semantics></math></span></span></p></li></ul></li></ul><hr><p><strong><code>UserCF</code> 召回通道</strong></p><ul><li><p>维护两个索引：</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{物品}</annotation></semantics></math></span>
</span>列表：用户最近交互过的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个物品。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>用户</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow  \text{用户}</annotation></semantics></math></span>
</span>列表：相似度最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个用户。</p></li></ul></li><li><p>线上做召回：</p><ul><li><p>利用两个索引，每次取回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mi>k</mi></mrow><annotation encoding="application/x-tex">nk</annotation></semantics></math></span>
</span>个物品。</p></li><li><p>预估用户对每个物品的兴趣分数。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mo>∑</mo><mi>j</mi></munder><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>×</mo><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">k</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mi>j</mi></msub><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
    \sum_{j}\mathrm{sim}(\mathrm{user}, \mathrm{user}_j) \times \mathrm{like}(\mathrm{user}_j, \mathrm{item})
    </annotation></semantics></math></span></div></li><li><p>返回分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn></mrow><annotation encoding="application/x-tex">100</annotation></semantics></math></span>
</span>个物品，作为召回结果。</p></li></ul></li></ul><h2 id=离散特征处理 class=heading>离散特征处理<a href=#%e7%a6%bb%e6%95%a3%e7%89%b9%e5%be%81%e5%a4%84%e7%90%86 aria-labelledby=离散特征处理><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><strong>离散特征</strong>：</p><ul><li>性别：男、女两种类别。</li><li>国籍：中国、美国、印度等 200 个国家。</li><li>英文单词：常见的英文单词有几万个。</li><li>物品 ID：小红书有几亿篇笔记，每篇笔记有一个 ID。</li><li>用户 ID：小红书有几亿个用户，每个用户有一个 ID。</li></ul><hr><p><strong>离散特征处理</strong></p><ul><li><p><strong>建立字典：把类别映射成序号。</strong></p><ul><li>中国 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></li><li>美国 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span></span></li><li>印度 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span></span></li></ul></li><li><p><strong>向量化：把序号映射成向量。</strong></p><ul><li><code>One-hot</code> 编码：把序号映射成高维稀疏向量。</li><li>Embedding：把序号映射成低维稠密向量。</li></ul></li></ul><h3 id=one-hot-编码 class=heading><code>One-Hot</code> 编码<a href=#one-hot-%e7%bc%96%e7%a0%81 aria-labelledby=one-hot-编码><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p>【例 1】性别特征。</p><ul><li><p>性别：男、女两种类别。</p></li><li><p>字典：男 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，女 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>。</p></li><li><p><code>One-hot</code> 编码：用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>维向量表示性别。</p><ul><li>未知 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,0]</annotation></semantics></math></span></span></li><li>男 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[1,0]</annotation></semantics></math></span></span></li><li>女 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1]</annotation></semantics></math></span></span></li></ul></li></ul><hr><p>【例 2】国籍特征。</p><ul><li><p>国籍：中国、美国、印度等
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn></mrow><annotation encoding="application/x-tex">200</annotation></semantics></math></span>
</span>种类别。</p></li><li><p>字典：中国 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，美国 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>，印度 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>。</p></li><li><p>One-hot 编码：用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn></mrow><annotation encoding="application/x-tex">200</annotation></semantics></math></span>
</span>维稀疏向量表示国籍。</p><ul><li>未知 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,0,0,0,\cdots,0]</annotation></semantics></math></span></span></li><li>中国 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[1,0,0,0,\cdots,0]</annotation></semantics></math></span></span></li><li>美国 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,1,0,0,\cdots,0]</annotation></semantics></math></span></span></li><li>印度 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[0,0,1,0,\cdots,0]</annotation></semantics></math></span></span></li></ul></li></ul><hr><p><strong><code>One-Hot</code> 编码的局限</strong>：</p><p>类别数量太大时，通常不用 <code>one-hot</code> 编码。</p><p>【例 1】：自然语言处理中，对单词做编码。</p><ul><li>英文有几万个常见单词，那么 <code>one-hot</code> 向量的维度是几万。</li></ul><p>【例 2】：推荐系统中，对物品 ID 做编码。</p><ul><li>小红书有几亿篇笔记，那么<code> one-hot</code> 向量的维度是几亿。</li></ul><h3 id=embedding嵌入 class=heading>Embedding(嵌入)<a href=#embedding%e5%b5%8c%e5%85%a5 aria-labelledby=embedding嵌入><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p>【例 1】：国籍的 Embedding</p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407193724849.png width=50% alt></center><ul><li><p>embedding 把每个序号映射成一个向量，这些向量都是低维向量，比如向量大小都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">4\times1</annotation></semantics></math></span>
</span>。</p></li><li><p>一个向量就是对一个国家的表示。未知国籍就用全零向量表示。</p></li><li><p><strong>参数数量</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>向量维度</mtext><mo>×</mo><mtext>类别数量</mtext></mrow><annotation encoding="application/x-tex">\text{向量维度} \times \text{类别数量}</annotation></semantics></math></span>
</span>。</p><ul><li>设 embedding 得到的向量都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>维的。</li><li>一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>200</mn></mrow><annotation encoding="application/x-tex">200</annotation></semantics></math></span>
</span>个国籍。</li><li>参数数量：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mn>200</mn><mo>=</mo><mn>800</mn></mrow><annotation encoding="application/x-tex">4 \times 200=800</annotation></semantics></math></span>
</span>。</li></ul></li><li><p><strong>编程实现</strong>：TensorFlow、PyTorch 提供 embedding 层。</p><ul><li>参数以矩阵的形式保存，矩阵大小是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>向量维度</mtext><mo>×</mo><mtext>类别数量</mtext></mrow><annotation encoding="application/x-tex">\text{向量维度} \times \text{类别数量}</annotation></semantics></math></span>
</span>。</li><li><strong>输入</strong> 是序号，比如“美国”的序号是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>。</li><li><strong>输出</strong> 是向量，比如“美国”对应参数矩阵的第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>列。</li></ul></li></ul><hr><p>【例 2】：物品 ID 的 Embedding</p><ul><li>数据库里一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">10,000</annotation></semantics></math></span>
</span>部电影。</li><li>任务是给用户推荐电影。</li><li>设 embedding 向量的维度是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>16</mn></mrow><annotation encoding="application/x-tex">16</annotation></semantics></math></span>
</span>。</li><li>参数数量：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>向量维度</mtext><mo>×</mo><mtext>类别数量</mtext><mo>=</mo><mn>160</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">\text{向量维度} \times \text{类别数量}=160,000</annotation></semantics></math></span>
</span>。</li></ul><p>如果类别数量特别大，比如推荐系统中的物品数量有几十亿，那么 embedding 层会特别大。</p><p>一个神经网络绝大多数的参数都在 embedding 层，所以工业界深度学习系统都会对 embedding 层做很多优化，这是存储和计算效率的关键所在。</p><p><strong>embedding 得到的向量的物理意义</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407194625425.png width=50% alt></center><p>图中的每个点表示一部电影的 embedding，如果训练得好，从物品的 embedding 可以看出物品的特点。</p><p>比如动画片的距离比较近，间谍片的距离也比较近。但是间谍片和动画片之间的距离会比较远。</p><h3 id=embedding-与-one-hot-编码-的关系 class=heading>Embedding 与 One-Hot 编码 的关系<a href=#embedding-%e4%b8%8e-one-hot-%e7%bc%96%e7%a0%81-%e7%9a%84%e5%85%b3%e7%b3%bb aria-labelledby=embedding-与-one-hot-编码-的关系><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407194937202.png width=50% alt></center><h3 id=总结-5 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-5 aria-labelledby=总结-5><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><ul><li><p>离散特征处理：<code>one-hot</code> 编码、embedding。</p></li><li><p>类别数量很大时，用 embedding。</p><ul><li>Word embedding</li><li>用户 ID embedding</li><li>物品 ID embedding</li></ul></li></ul><h2 id=矩阵补充 class=heading>矩阵补充<a href=#%e7%9f%a9%e9%98%b5%e8%a1%a5%e5%85%85 aria-labelledby=矩阵补充><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><strong>矩阵补充</strong> 是 <strong>向量召回</strong> 最简单的一种方法，不过现在已经不太常用这种方法了。</p><p><strong>矩阵补充</strong> 把用户 id 或者物品 id 映射成向量。</p><h3 id=模型结构 class=heading>模型结构<a href=#%e6%a8%a1%e5%9e%8b%e7%bb%93%e6%9e%84 aria-labelledby=模型结构><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407195231677.png width=50% alt></center><ul><li><p>输入：用户 id 和物品 id。</p></li><li><p>输出：用户对物品兴趣的预估值，越大表示用户对物品越感兴趣。</p></li><li><p>左边的结构只有一个 embedding 层，把一个用户 id 映射到向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>，为对用户的表征。</p></li><li><p>右边的结构是另一个 embedding 层，把一个物品 id 映射到向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span>，为对物品的表征。</p></li></ul><p>模型的两个 embedding 层不共享参数，对向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span>求内积得到一个实数，作为模型的输出。</p><h3 id=模型训练 class=heading>模型训练<a href=#%e6%a8%a1%e5%9e%8b%e8%ae%ad%e7%bb%83 aria-labelledby=模型训练><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407195622522.png width=50% alt></center><ul><li>用户 embedding 参数矩阵记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>。第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>号用户对应矩阵第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>列，记作向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">a</mi><mi>u</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{a}_u</annotation></semantics></math></span>
</span>。</li><li>物品 embedding 参数矩阵记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf B</annotation></semantics></math></span>
</span>。第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>号物品对应矩阵第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>列，记作向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{b}_i</annotation></semantics></math></span>
</span>。</li><li>内积
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">a</mi><mi>u</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex"> \langle \mathbf{a}_u, \mathbf{b}_i \rangle</annotation></semantics></math></span>
</span>是第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>号用户对第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>号物品兴趣的预估值。</li><li>训练模型的目的是学习矩阵
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf B</annotation></semantics></math></span>
</span>，使得预估值拟合真实观测的兴趣分数。</li></ul><h4 id=数据集 class=heading>数据集<a href=#%e6%95%b0%e6%8d%ae%e9%9b%86 aria-labelledby=数据集><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>数据集：（用户 ID，物品 ID，兴趣分数）的集合，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Ω</mi><mo>=</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo></mrow></mrow><annotation encoding="application/x-tex">\Omega ={(u,i,y)}</annotation></semantics></math></span>
</span>。</p><p>数据集中的兴趣分数是系统记录的：</p><ul><li>曝光但是没有点击 ->
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>分</li><li>点击、点赞、收藏、转发 -> 各算
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>分</li><li>分数最低是 0，最高是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span></span></li></ul><h4 id=训练 class=heading>训练<a href=#%e8%ae%ad%e7%bb%83 aria-labelledby=训练><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>把用户 ID、物品 ID 映射成向量：</p><ul><li>第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>号用户 -> 向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">a</mi><mi>u</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{a}_u</annotation></semantics></math></span></span></li><li>第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>号物品 -> 向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{b}_i</annotation></semantics></math></span></span></li></ul><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munder><mrow><mi>min</mi><mo>⁡</mo></mrow><mrow><mi mathvariant="bold">A</mi><mo separator="true">,</mo><mi mathvariant="bold">B</mi></mrow></munder><munder><mo>∑</mo><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo separator="true">,</mo><mi>y</mi><mo stretchy="false">)</mo><mo>∈</mo><mi mathvariant="normal">Ω</mi></mrow></munder><mo stretchy="false">(</mo><mi>y</mi><mo>−</mo><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">a</mi><mi>u</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo><msup><mo stretchy="false">)</mo><mn>2</mn></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
\min_{\mathbf{A, B}}\sum_{(u, i, y)\in\Omega}(y-\langle\mathbf{a}_u,\mathbf{b}_i\rangle)^{2}.
</annotation></semantics></math></span></div><hr><p><strong>矩阵补充</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407200034397.png width=50% alt></center><p>矩阵中每一行对应一个用户，每一列对应一个物品。</p><p>矩阵中的每个元素表示一个用户对一个物品的真实兴趣分数。系统里物品很多，一个用户看过的物品只是系统中的极少数。</p><p>在矩阵中：</p><ul><li>绿色位置表示<strong>曝光给用户的物品</strong>。</li><li>灰色位置表示<strong>没有曝光的物品</strong>。</li></ul><p>只要把物品曝光给用户，我们就知道用户对物品是否感兴趣。</p><ul><li><p>曝光了没点击说明不感兴趣，分数是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>。</p></li><li><p>曝光之后，用户可能会点击点赞收藏转发，每个都算
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>分，加起来最多有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>分。</p><p>比如这个绿色位置表示第 3 号用户对第 2 号物品的兴趣，分数等于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>。</p></li></ul><p>矩阵中只有少数位置是绿色，大多数位置都是灰色，即没有曝光给用户的。我们并不知道用户对没曝光的物品是否感兴趣。</p><p>用绿色位置的数据训练出了模型，用模型即可预估出所有灰色位置的分数，把矩阵的元素给补全。</p><p>把矩阵元素补全之后，我们就可以做推荐。给定一个用户，我们选出用户对应的行中分数较高的物品推荐给该用户。</p><h3 id=矩阵补充的缺点 class=heading>矩阵补充的缺点<a href=#%e7%9f%a9%e9%98%b5%e8%a1%a5%e5%85%85%e7%9a%84%e7%bc%ba%e7%82%b9 aria-labelledby=矩阵补充的缺点><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><ol><li><p>仅用 ID embedding，<strong>没利用物品、用户属性</strong>。</p><ul><li><p>物品属性：类目、关键词、地理位置、作者信息。</p></li><li><p>用户属性：性别、年龄、地理定位、感兴趣的类目。</p></li><li><p>双塔模型可以看做矩阵补充的升级版。</p></li></ul></li><li><p><strong>负样本的选取方式不对</strong>。</p><ul><li><p>样本：用户 - 物品的二元组，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>i</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(u,i)</annotation></semantics></math></span></span></p></li><li><p>正样本：曝光之后，有点击、交互。(正确的做法)</p></li><li><p>负样本：曝光之后，没有点击、交互。 (错误的做法)</p></li></ul></li><li><p><strong>做训练的方法不好</strong></p><ul><li><p>内积
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><msub><mi mathvariant="bold">a</mi><mi>u</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex"> \langle \mathbf{a}_u, \mathbf{b}_i \rangle</annotation></semantics></math></span>
</span>不如余弦相似度</p></li><li><p>用平方损失（回归），不如用交叉熵损失（分类)</p></li></ul></li></ol><h3 id=线上服务 class=heading>线上服务<a href=#%e7%ba%bf%e4%b8%8a%e6%9c%8d%e5%8a%a1 aria-labelledby=线上服务><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=模型存储 class=heading>模型存储<a href=#%e6%a8%a1%e5%9e%8b%e5%ad%98%e5%82%a8 aria-labelledby=模型存储><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ol><li><p>训练得到矩阵
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf B</annotation></semantics></math></span>
</span>，他们是 embedding 层的参数</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>的每一列对应一个用户</li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf B</annotation></semantics></math></span>
</span>的每一列对应一个物品</li></ul><p>矩阵
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf B</annotation></semantics></math></span>
</span>可能会很大，比如小红书有几亿用户、几亿篇笔记，那么这两个矩阵的列数都是好几亿。</p><p>为了快速读取和快速查找，需要特殊的存储方式。</p></li><li><p>把矩阵
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>的列存储到 key-value 表</p><ul><li>key 是用户 ID，value 是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">A</mi></mrow><annotation encoding="application/x-tex">\mathbf A</annotation></semantics></math></span>
</span>的一列。</li><li>给定用户 ID，返回一个向量（用户的 embedding）。</li></ul></li><li><p>矩阵
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">B</mi></mrow><annotation encoding="application/x-tex">\mathbf B</annotation></semantics></math></span>
</span>的存储和索引比较复杂，不能简单的用 key-value 存储。</p></li></ol><h4 id=线上服务-1 class=heading>线上服务<a href=#%e7%ba%bf%e4%b8%8a%e6%9c%8d%e5%8a%a1-1 aria-labelledby=线上服务-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ol><li><p>把用户 ID 作为 key，查询 key-value 表，得到该用户的向量，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>。</p></li><li><p><strong>最近邻查找</strong>（Nearest Neighbor Search）：查找用户最有可能感兴趣的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品作为召回结果。</p><ul><li>第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>号物品的 embedding 向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{b}_i</annotation></semantics></math></span></span></li><li>内积
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle \mathbf{a}, \mathbf{b}_i \rangle</annotation></semantics></math></span>
</span>是用户对第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>号物品兴趣的预估。</li><li>返回内积最大的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品。</li></ul></li></ol><p>【问题】：如果枚举所有物品，时间复杂度正比于物品数量。</p><h3 id=总结-6 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-6 aria-labelledby=总结-6><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><ul><li>把物品 ID、用户 ID 做 embedding，映射成向量。</li><li>两个向量的内积
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle \mathbf{a}, \mathbf{b}_i \rangle</annotation></semantics></math></span>
</span>作为用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>对物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>兴趣的预估。</li><li>让
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle \mathbf{a}, \mathbf{b}_i \rangle</annotation></semantics></math></span>
</span>拟合真实观测的兴趣分数，用回归的方式学习模型的 embedding 层参数。</li><li>矩阵补充模型有很多缺点，效果不好。</li></ul><h2 id=近似最近邻查找-approximate-nearest-neighbor-search class=heading>近似最近邻查找 （Approximate Nearest Neighbor Search）<a href=#%e8%bf%91%e4%bc%bc%e6%9c%80%e8%bf%91%e9%82%bb%e6%9f%a5%e6%89%be-approximate-nearest-neighbor-search aria-labelledby=近似最近邻查找-approximate-nearest-neighbor-search><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><strong>支持最近邻查找的系统</strong></p><ul><li><p>系统：Milvus、Faiss、HnswLib、等等</p></li><li><p><strong>衡量最近邻的标准</strong>：</p><ul><li><p>欧式距离最小 (<code>L2</code> 距离)</p></li><li><p>向量内积最大 (内积相似度)</p></li><li><p>向量夹角余弦最大（cosine 相似度)</p></li></ul><p>有些系统不支持余弦相似度，可以对向量都做归一化。此时，内积相似度等于余弦相似度。</p></li></ul><hr><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407204911901.png width=30% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407204939565.png width=30% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407205017579.png width=30% alt></center><p>对于散点图，每个点是一个物品的 embedding 向量，embedding 向量为训练模型所计算。</p><p>图一右边的五角星表示一个用户的 embedding 向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>。如果想要召回这个用户可能感兴趣的物品，则需要计算向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>与所有点的相似度。</p><p>如果用暴力枚举的话，计算量正比于点的数量即物品的数量。想要减少最近零查找的计算量必须要避免暴力枚举。</p><p>在做线上服务之前先对数据做预处理：</p><ul><li><p>把数据划分成很多区域：</p><ul><li>如果是 cos 相似度，那么划分的结果就是这样的扇形。</li><li>如果是用欧式距离，那么划分的结果就是多边形。</li></ul></li><li><p>划分之后，每个区域用一个向量表示，这些向量的长度都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span></p></li><li><p>划分区域之后建立索引，把每个区域的向量作为 key，把区域中所有点的列表作为 value，给定一个向量可以快速取回这个区域内所有的点。</p></li></ul><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407205310704.png width=30% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407205337757.png width=30% alt></center><p>在线上给一个用户做推荐，这个用户的 embedding 向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>。</p><p>把向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>跟索引中这些向量做对比计，算它们的相似度。如果物品数量是几亿，索引中的向量数量也只有几万而已，这一步的计算开销不大。</p><p>计算相似度之后，我们发现索引中某个向量与
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>最相似，通过索引我们找到该向量对应区域内所有的点，每个点对应一个物品。</p><p>接下来计算点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>跟区域内所有点的相似度，如果一共有几亿个物品被划分到了几万个区域，平均每个区域只有几万个点。所以这一步只需要计算几万次相似度，计算量也不大。</p><h3 id=总结-7 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-7 aria-labelledby=总结-7><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><ul><li>把用户向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>作为 query，查找使得
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex">\langle \mathbf{a}, \mathbf{b}_i \rangle</annotation></semantics></math></span>
</span>最大化的物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>。</li><li>暴力枚举速度太慢。实践中用近似最近邻查找。</li><li>Milvus、Faiss、HnswLib 等向量数据库支持近似最近邻查找。</li></ul><h2 id=双塔模型 class=heading>双塔模型<a href=#%e5%8f%8c%e5%a1%94%e6%a8%a1%e5%9e%8b aria-labelledby=双塔模型><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><h3 id=模型和训练 class=heading>模型和训练<a href=#%e6%a8%a1%e5%9e%8b%e5%92%8c%e8%ae%ad%e7%bb%83 aria-labelledby=模型和训练><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=双塔模型-1 class=heading>双塔模型<a href=#%e5%8f%8c%e5%a1%94%e6%a8%a1%e5%9e%8b-1 aria-labelledby=双塔模型-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407205645687.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407205715427.png width=45% alt></center><hr><p><strong>用户的特征</strong></p><p>用户 id 能从用户填写的资料和用户行为中获取很多特征，包括离散特征和连续特征。所有这些特征不能直接输入神经网络，而是要先做一些处理。</p><ul><li><p>用 embedding 层把 <strong>用户 id</strong> 映射到一个向量。</p></li><li><p><strong>离散特征</strong>：对于每个离散特征用单独 embedding 层得到向量：</p><ul><li><p>用户所在城市用一个 embedding 层。</p></li><li><p>用户感兴趣的话题用另一个 embedding 层。</p></li><li><p>对于性别这样类别数量很少的离散特征可以直接用 <code>OneHot</code> 编码，不做 embedding。</p></li></ul></li><li><p><strong>连续特征</strong>：比如年龄、活跃程度、消费金额等等。</p><ul><li><p>不同类型的连续特征有不同的处理方法，最简单的是做归一化，让特征均值是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，标准差是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。</p></li><li><p>有些长尾分布的延续特征需要特殊处理，比如取 log，比如做分桶。</p></li></ul></li></ul><p>做完特征处理得到很多特征向量，把这些向量都拼起来输入神经网络。神经网络可以是简单的全连接网络，也可以是更复杂的结构，比如深度交叉网络。</p><p>神经网络输出一个向量，这个向量即为对 <strong>用户的表征</strong>。</p><hr><p><strong>物品的特征</strong></p><p>物品的特征与用户的特征处理方法类似：</p><ul><li><p>用 embedding 层处理 <strong>物品 id</strong> 和其他 <strong>离散特征</strong>。</p></li><li><p>用归一化、取对数或者分桶等方法处理物品的连续特征。</p></li></ul><p>把得到的特征输入一个神经网络，神经网络输出的向量就是物品的表征，用于召回。</p><hr><p><strong>双塔模型</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407210108848.png width=50% alt></center><p>左边的塔提取用户的特征，右边的塔提取物品的特征。</p><p>与矩阵补充模型相比，双塔模型的不同之处在于使用了 id 之外的多种特征作为双塔的输入。</p><p>两个塔各输出一个向量，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span>，两个向量的内积（现在更常用 <strong>余弦相似度</strong>）即为模型最终的输出：预估用户对物品的兴趣。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">a</mi><mo separator="true">,</mo><mi mathvariant="normal">b</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mfrac><mrow><mo stretchy="false">⟨</mo><mrow><mi mathvariant="normal">a</mi><mo separator="true">,</mo><mi mathvariant="normal">b</mi></mrow><mo stretchy="false">⟩</mo></mrow><mrow><mo stretchy="false">∥</mo><mi mathvariant="normal">a</mi><msub><mo stretchy="false">∥</mo><mn>2</mn></msub><mo>⋅</mo><mo stretchy="false">∥</mo><mi mathvariant="normal">b</mi><msub><mo stretchy="false">∥</mo><mn>2</mn></msub></mrow></mfrac><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">
\cos(\mathrm{a, b})=\frac{\langle\mathrm{a, b}\rangle}{\lVert \mathrm{a} \rVert _2\cdot \lVert\mathrm{b} \lVert _2} \in [0,1]
</annotation></semantics></math></span></div><h4 id=双塔模型的训练 class=heading>双塔模型的训练<a href=#%e5%8f%8c%e5%a1%94%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%ae%ad%e7%bb%83 aria-labelledby=双塔模型的训练><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><blockquote class=blockquote><ul><li><p><strong><code>Pointwise</code></strong>：</p><p>独立看待每个正样本、负样本；做简单的二元分类。</p><p>把正样本负样本组成一个数据集，在数据集上做随机梯度下降训练双塔模型。</p></li><li><p><strong><code>Pairwise</code></strong>：</p><p>每次取一个正样本、一个负样本组成一个二元组，损失函数用 <code>triplet hinge loss</code> 或 <code>triplet logistic loss</code>。</p><p><a href=https://arxiv.org/abs/2006.11632 class=markdown-link>Embedding-based Retrieval in Facebook Search</a></p></li><li><p><strong><code>Listwise</code></strong>：</p><p>每次取一个正样本、多个负样本组成一个 list，训练方式类似于多元分类</p><p><a href=https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/ class=markdown-link>Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</a></p></li></ul></blockquote><p><strong>正负样本的选择</strong></p><ul><li><p>正样本：用户点击的物品。</p></li><li><p>负样本：用户不感兴趣的物品。</p><ul><li><p>没有被召回的？</p></li><li><p>召回但是被粗排、精排淘汰的?</p></li><li><p>曝光但是未点击的？</p></li></ul></li></ul><hr><h5 id=pointwise class=heading><code>Pointwise</code><a href=#pointwise aria-labelledby=pointwise><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><ul><li><p>把召回看做二元分类任务。</p></li><li><p>对于正样本（历史记录显示用户对物品感兴趣)，鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b})</annotation></semantics></math></span>
</span>接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math></span></span></p></li><li><p>对于负样本（用户对物品不感兴趣），鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><mi mathvariant="bold">b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b})</annotation></semantics></math></span>
</span>接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span></span></p></li><li><p>控制正负样本数量为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>:</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">1:2</annotation></semantics></math></span>
</span>或者
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>:</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">1:3</annotation></semantics></math></span></span></p></li></ul><h5 id=pairwise class=heading><code>Pairwise</code><a href=#pairwise aria-labelledby=pairwise><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407210514538.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407210539966.png width=45% alt></center><ul><li><p>每一组的输入是一个三元组，包括一个用户和两个物品：</p><ul><li><p>左边的物品是 <strong>正样本</strong>即<strong>用户感兴趣的物品</strong>。</p></li><li><p>右边的物品是 <strong>负样本</strong>即<strong>用户不感兴趣的物品</strong>。</p></li></ul></li><li><p>把 <strong>用户的特征</strong> 和 <strong>物品的特征</strong> 各自做变换后输入神经网络，最终输出三个向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo separator="true">,</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathbf{b}^+, \mathbf{a},\mathbf{b}^-)</annotation></semantics></math></span>
</span>，表示
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>正样本向量</mtext><mo separator="true">,</mo><mtext> 用户向量</mtext><mo separator="true">,</mo><mtext> 负样本向量</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{正样本向量},~ \text{用户向量},~ \text{负样本向量})</annotation></semantics></math></span>
</span>。</p><p>两个物品塔相同，里面的 embedding 层和全连接层<strong>参数共享</strong>。</p></li><li><p>分别计算用户对两个物品的兴趣。</p><ul><li><p><strong>用户对正样本的兴趣</strong> 是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^+)</annotation></semantics></math></span>
</span>，值越接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">+1</annotation></semantics></math></span>
</span>越好。</p></li><li><p><strong>用户对负样本的兴趣</strong> 是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^-)</annotation></semantics></math></span>
</span>，值越接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span>
</span>越好。</p></li></ul></li></ul><hr><p><strong>基本想法</strong></p><p>让用户对正样本的兴趣尽量大，对负样本的兴趣尽量小。即
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo>&gt;</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^+) &gt; \cos(\mathbf{a}, \mathbf{b}^-)</annotation></semantics></math></span>
</span>，且两者之差越大越好。</p><hr><p><strong><code>Triplet hinge loss</code>:</strong></p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo>=</mo><mi>max</mi><mo>⁡</mo><mo stretchy="false">{</mo><mn>0</mn><mo separator="true">,</mo><mtext> </mtext><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>m</mi><mo>−</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo stretchy="false">}</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
L(\mathbf{a},\mathbf{b}^+,\mathbf{b}^-)=\max\{0,~\cos(\mathbf{a}, \mathbf{b}^-)+m-\cos(\mathbf{a}, \mathbf{b}^+)\}.
</annotation></semantics></math></span></div><ul><li><p>如果
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo>&gt;</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>m</mi></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^+) &gt; \cos(\mathbf{a}, \mathbf{b}^-)+m</annotation></semantics></math></span>
</span>，则没有损失。</p></li><li><p>否则，损失等于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo>+</mo><mi>m</mi><mo>−</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^-) + m - \cos(\mathbf{a}, \mathbf{b}^-)</annotation></semantics></math></span>
</span>。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>是需要调的超参数。</p></li></ul><hr><p><strong><code>Triplet logistic loss</code>:</strong></p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>L</mi><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mtext> </mtext><mo>=</mo><mtext> </mtext><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mn>1</mn><mo>+</mo><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">{</mo><mi>σ</mi><mo>⋅</mo><mrow><mo fence="true">[</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>−</mo></msup><mo stretchy="false">)</mo><mo>−</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo fence="true">]</mo></mrow><mo fence="true">}</mo></mrow><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
L(\mathbf{a},\mathbf{b}^+,\mathbf{b}^-)~=~\log \left(1+\exp \left\{\sigma\cdot \left [\cos(\mathbf{a}, \mathbf{b}^-)-\cos (\mathbf{a}, \mathbf{b}^+ )\right]\right\}\right)
</annotation></semantics></math></span></div><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>σ</mi><mo>&gt;</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\sigma &gt; 0</annotation></semantics></math></span>
</span>控制损失函数的形状，需要手动设置。</li></ul><hr><h5 id=listwise class=heading><code>Listwise</code><a href=#listwise aria-labelledby=listwise><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><p>非原教旨主义的 <code>Listwise</code>，此处仅考虑
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>对 <code>Pairwise</code>，未考虑 rank 的因素。</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>条数据包含：</p><ul><li>一个用户，特征向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>。</li><li>一个正样本，特征向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\mathbf{b}^+</annotation></semantics></math></span>
</span>。</li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个负样本，特征向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mn>1</mn><mo>−</mo></msubsup><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>n</mi><mo>−</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}^-_1, \cdots, \mathbf{b}^-_n</annotation></semantics></math></span>
</span>。</li></ul></li><li><p>鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^+)</annotation></semantics></math></span>
</span>尽量大。</p></li><li><p>鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mn>1</mn><mo>−</mo></msubsup><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>n</mi><mo>−</mo></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^-_1), \cdots,  \cos(\mathbf{a}, \mathbf{b}^-_n)</annotation></semantics></math></span>
</span>尽量小。</p></li></ul><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407211236628.png width=50% alt></center><p><strong>样本</strong></p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msup><mi mathvariant="bold">b</mi><mo>+</mo></msup><mo stretchy="false">)</mo><mo>∈</mo><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^+) \in [-1, 1]</annotation></semantics></math></span>
</span>为用户对正样本物品兴趣的预估分数，越接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>越好。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mn>1</mn><mo>−</mo></msubsup><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>n</mi><mo>−</mo></msubsup><mo stretchy="false">)</mo><mo>∈</mo><mo stretchy="false">[</mo><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}, \mathbf{b}^-_1), \cdots,  \cos(\mathbf{a}, \mathbf{b}^-_n) \in [-1, 1]</annotation></semantics></math></span>
</span>为用户对
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个负样本兴趣的预估分数，越接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">-1</annotation></semantics></math></span>
</span>越好。</p></li></ul><p>把这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math></span>
</span>个分数输入 <code>Softmax</code> 激活函数，激活函数输出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n+1</annotation></semantics></math></span>
</span>个分数，这些分数都介于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>∼</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">0 \sim 1</annotation></semantics></math></span>
</span>之间。</p><ul><li><p>最左边的分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>s</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">s^+</annotation></semantics></math></span>
</span>对应正样本，这个分数越大越好，最好是能接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。</p></li><li><p>其余
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个分数对应负样本，这些分数越小越好，最好都接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>。</p></li></ul><p><strong>标签</strong>：</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo>+</mo></msup><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">y^+=1</annotation></semantics></math></span>
</span>：正样本的标签，是鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>s</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">s^+</annotation></semantics></math></span>
</span>加接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>y</mi><mn>1</mn><mo>−</mo></msubsup><mo>=</mo><mo>⋯</mo><mo>=</mo><msubsup><mi>y</mi><mi>n</mi><mo>−</mo></msubsup><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">y^-_1= \cdots = y^-_n=0</annotation></semantics></math></span>
</span>：负样本的标签，鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>s</mi><mn>1</mn><mo>−</mo></msubsup><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msubsup><mi>s</mi><mi>n</mi><mo>−</mo></msubsup></mrow><annotation encoding="application/x-tex">s^-_1, \cdots , s^-_n</annotation></semantics></math></span>
</span>都接近零。</p></li></ul><p>用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">s</mi></mrow><annotation encoding="application/x-tex">\mathbf{s}</annotation></semantics></math></span>
</span>的 <strong>交叉熵作为损失函数</strong>，训练的时候最小化交叉熵，鼓励 <code>Softmax</code> 输出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">s</mi></mrow><annotation encoding="application/x-tex">\mathbf{s}</annotation></semantics></math></span>
</span>接近标签
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">y</mi></mrow><annotation encoding="application/x-tex">\mathbf{y}</annotation></semantics></math></span>
</span>。</p><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">C</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">L</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi><mo stretchy="false">(</mo><mi mathvariant="bold">y</mi><mo separator="true">,</mo><mi mathvariant="bold">s</mi><mo stretchy="false">)</mo></mrow><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msup><mi>s</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">\mathrm{CrossEntropyLoss(\mathbf{y},\mathbf{s})}=-\log s^+</annotation></semantics></math></span>
</span>等价于最大化
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>s</mi><mo>+</mo></msup></mrow><annotation encoding="application/x-tex">s^+</annotation></semantics></math></span>
</span>，即等价于最大化正样本的余弦相似度，最小化负样本的余弦相似度。</p><hr><h4 id=总结-8 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-8 aria-labelledby=总结-8><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>双塔模型</strong></p><ul><li><p>用户塔、物品塔各输出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个向量。</p></li><li><p>两个向量的余弦相似度作为兴趣的预估值。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>种训练方式：</p><ul><li><p><code>Pointwise</code>：每次用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个用户、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个物品（可正可负）。</p></li><li><p><code>Pairwise</code>：每次用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>用户、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个正样本、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个负样本。</p></li><li><p><code>Listwise</code>：每次用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>用户、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个正样本、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个负样本。</p></li></ul></li></ul><hr><p><strong>不适用于召回的模型</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407211739799.png width=50% alt></center><p><strong>模型结构</strong></p><ul><li><p>下层结构跟双塔模型一样，都是分别提取用户和物品的特征得到两个特征向量。</p></li><li><p>上层的结构不一样：直接把两个向量做 concatenation 然后输入一个神经网络。</p></li></ul><p>在 <strong>进入全连接层之前就把特征向量拼起来</strong> 的神经网络结构属于 <strong>前期融合</strong>。</p><p>双塔模型属于 <strong>后期融合</strong>，两个塔在 <strong>最终输出相似度的时候才融合</strong> 起来。</p><ul><li><p><strong>前期融合模型不适用于召回</strong>。</p><ul><li><p>如果把前期融的模型用于召回，就必须把所有物品的特征都输入模型，预估用户对所有物品的兴趣。假设一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>亿个物品，每给用户做
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>次召回，就要把这个模型跑
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>亿次，这种计算量显然不可行。</p></li><li><p>用前期融的模型没办法用近似最近邻查找来加速计算</p></li></ul></li><li><p><strong>前期融合模型通常用于排序</strong>，从几千个候选物品中选出几百个计算量不会太大。</p></li></ul><p><strong>召回</strong> 只能使用双塔那样的 <strong>后期融合模型</strong>。</p><h3 id=正负样本 class=heading>正负样本<a href=#%e6%ad%a3%e8%b4%9f%e6%a0%b7%e6%9c%ac aria-labelledby=正负样本><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=正样本 class=heading>正样本<a href=#%e6%ad%a3%e6%a0%b7%e6%9c%ac aria-labelledby=正样本><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>正样本</strong>：<strong>曝光而且有点击</strong> 的 <strong>用户一物品二元组</strong>(用户对物品感兴趣)。</p><p><strong>问题</strong>：少部分物品占据大部分点击，导致正样本大多是热门物品。</p><p><strong>解决方案</strong>：过采样冷门物品，或降采样热门物品。</p><ul><li><p><strong>过采样（up-sampling）</strong>：一个样本出现多次。</p></li><li><p><strong>降采样（down-sampling）</strong>：一些样本被抛弃。</p></li></ul><h4 id=负样本 class=heading>负样本<a href=#%e8%b4%9f%e6%a0%b7%e6%9c%ac aria-labelledby=负样本><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407212328427.png width=50% alt></center><p><strong>负样本</strong>：用户不感兴趣的物品，也即链路上每一步被淘汰的物品。</p><ul><li><p><strong>召回模块</strong>：从几亿个物品中选出几千个被召回的物品，没被召回的几亿个物品可以看作是负样本。</p></li><li><p><strong>粗排和精排</strong>：从几千个召回的物品中选出几百个，也就是说几千个物品会被这一步淘汰。</p></li></ul><p>最终有几十个物品曝光给用户，但不是每个曝光的物品都会被用户点击曝光了。用户没有点击的也可以视作是负样本。</p><h4 id=简单负样本 class=heading>简单负样本<a href=#%e7%ae%80%e5%8d%95%e8%b4%9f%e6%a0%b7%e6%9c%ac aria-labelledby=简单负样本><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><h5 id=简单负样本全体物品 class=heading>简单负样本：全体物品<a href=#%e7%ae%80%e5%8d%95%e8%b4%9f%e6%a0%b7%e6%9c%ac%e5%85%a8%e4%bd%93%e7%89%a9%e5%93%81 aria-labelledby=简单负样本全体物品><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><p>未被召回的物品，大概率是用户不感兴趣的。</p><p>未被召回的物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span>
</span>全体物品。</p><p>从全体物品中做抽样，作为 <strong>负样本。</strong></p><hr><p><strong>均匀抽样 or 非均匀抽样</strong></p><p><strong>均匀抽样</strong>：对冷门物品不公平。</p><ul><li><p>正样本大多是热门物品。</p></li><li><p>如果均匀抽样产生负样本，负样本大多是冷门物品。</p></li></ul><p><strong>非均抽采样</strong>：目的是打压热门物品。</p><ul><li><p>负样本抽样概率与热门程度 (点击次数)正相关。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>抽样概率</mtext><mo>∝</mo><mo stretchy="false">(</mo><mtext>点击次数</mtext><msup><mo stretchy="false">)</mo><mn>0.75</mn></msup></mrow><annotation encoding="application/x-tex">\text{抽样概率} \propto (\text{点击次数})^{0.75}</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0.75</mn></mrow><annotation encoding="application/x-tex">0.75</annotation></semantics></math></span>
</span>是个经验值。</p></li></ul><hr><h5 id=简单负样本batch-内负样本 class=heading>简单负样本：batch 内负样本<a href=#%e7%ae%80%e5%8d%95%e8%b4%9f%e6%a0%b7%e6%9c%acbatch-%e5%86%85%e8%b4%9f%e6%a0%b7%e6%9c%ac aria-labelledby=简单负样本batch-内负样本><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407212611463.png width=35% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407212645068.png width=35% alt></center><p>一个 batch 内有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个正样本。</p><p>一个用户和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span>
</span>个物品组成点击负样本。</p><p>一个 batch 内一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo stretchy="false">(</mo><mi>n</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">n(n - 1)</annotation></semantics></math></span>
</span>个负样本。</p><p>都是简单负样本 （对于第一个用户来说，第二个物品就相当于是从全体物品中随机抽样的，大概率不会喜欢）。</p><hr><p><strong>batch 内负样本的问题</strong></p><p>图中这些二元组都是通过点击行为选取的，第一个用户和第一个物品之所以成为一个正样本，原因是用户点击了物品。</p><ul><li><p>一个物品出现在 batch 内的概率
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∝</mo><mtext>点击次数</mtext></mrow><annotation encoding="application/x-tex">\propto \text{点击次数}</annotation></semantics></math></span>
</span>。</p></li><li><p>物品成为负样本的概率本该是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∝</mo><mo stretchy="false">(</mo><mtext>点击次数</mtext><msup><mo stretchy="false">)</mo><mn>0.75</mn></msup></mrow><annotation encoding="application/x-tex">\propto (\text{点击次数})^{0.75}</annotation></semantics></math></span>
</span>，但在这里是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∝</mo><mtext>点击次数</mtext></mrow><annotation encoding="application/x-tex">\propto \text{点击次数}</annotation></semantics></math></span>
</span>。</p></li><li><p><strong>热门物品成为负样本的概率过大</strong>。</p></li></ul><p><strong>一个物品成为负样本的概率越大，模型对这个物品打压就会越狠</strong>，对负样本应该打压，但这里打压的太狠了这样会造成偏差。</p><p><strong>【解决方案】</strong></p><p><a href=https://research.google/pubs/sampling-bias-corrected-neural-modeling-for-large-corpus-item-recommendations/ class=markdown-link>Sampling-Bias-Corrected Neural Modeling for Large Corpus Item Recommendations</a></p><p>物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>被抽样到的概率：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>i</mi></msub><mo>∝</mo><mtext>点击次数</mtext></mrow><annotation encoding="application/x-tex">p_i \propto \text{点击次数}</annotation></semantics></math></span>
</span>。（反映出物品的热门程度）</p><p>预估用户对物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>的兴趣：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a},\mathbf{b}_i)</annotation></semantics></math></span>
</span>， 训练的时候要鼓励正样本的余弦相似度尽量大，鼓励负样本的余弦相似度尽量小。</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>：用户的特征向量</li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{b}_i</annotation></semantics></math></span>
</span>：物品的特征向量</li></ul><p>做训练的时候，调整为：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a},\mathbf{b}_i)- \log p_i</annotation></semantics></math></span>
</span>，这样可以纠偏，避免过分打压热门的物品。</p><p>训练结束之后，在线上做召回的时候，还是用原本的余弦相似度
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi mathvariant="bold">a</mi><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a},\mathbf{b}_i)</annotation></semantics></math></span></span></p><h4 id=困难负样本 class=heading>困难负样本<a href=#%e5%9b%b0%e9%9a%be%e8%b4%9f%e6%a0%b7%e6%9c%ac aria-labelledby=困难负样本><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>困难负样本</strong>：</p><ul><li><p>被<strong>粗排</strong>淘汰的物品(比较困难)。</p></li><li><p><strong>精排</strong>分数靠后的物品（非常困难）</p></li></ul><hr><p><strong>对正负样本做二元分类</strong>：</p><ul><li><p>全体物品（简单）分类准确率高。</p></li><li><p>被粗排淘汰的物品（比较困难）容易分错。</p></li><li><p>精排分数靠后的物品（非常困难）更容易分错。</p></li></ul><h5 id=训练数据 class=heading>训练数据<a href=#%e8%ae%ad%e7%bb%83%e6%95%b0%e6%8d%ae aria-labelledby=训练数据><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><p>混合几种负样本（简单负样本与困难负样本）:</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span>
</span>的负样本是从全体物品中随机非均匀抽样出来的（简单负样本)</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span>
</span>的负样本是从粗排和精排淘汰的物品中随机抽样出来的（困难负样本)</p></li></ul><h4 id=常见的错误 class=heading>常见的错误<a href=#%e5%b8%b8%e8%a7%81%e7%9a%84%e9%94%99%e8%af%af aria-labelledby=常见的错误><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>不能把曝光但是没有点击的物品作为负样本</strong>。</p><ul><li><p>重排之后前
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span>
</span>个物品曝光给了用户，第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>~
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>80</mn></mrow><annotation encoding="application/x-tex">80</annotation></semantics></math></span>
</span>物品没有曝光。</p></li><li><p>在曝光的物品里面，第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个和第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn></mrow><annotation encoding="application/x-tex">5</annotation></semantics></math></span>
</span>个被用户点击，其余
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>个物品没有被用户点击</p></li><li><p>不能把这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>个物品（有曝光但是没有点击）当做负样本。</p><p>这种负样本 <strong>不是给训练召回模型</strong> 用的，而是给 <strong>训练排序模型</strong> 用的。</p></li></ul><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407213209646.png width=50% alt></center><hr><p><strong>选择负样本的原理</strong>：</p><p><strong>召回的目标</strong>：快速找到用户可能感兴趣的物品。</p><p>凡是用户可能感兴趣的全都取回来，然后再交给后面的排序模型逐一做甄别。</p><p><strong>召回模型的任务</strong> 是区分用户不感兴趣的物品和可能感兴趣的物品，而不是区分比较感兴趣的物品和非常感兴趣的物品。这是选择负样本的基本思路。</p><hr><p><strong>可以作为召回负样本</strong>：</p><ul><li><p><strong>全体物品（easy）</strong>：绝大多数是用户根本不感兴趣的。</p></li><li><p><strong>被排序（粗排精排）淘汰（hard）</strong>：用户可能感兴趣，但是不够感兴趣。</p></li></ul><hr><p><strong>不能作为召回负样本</strong>：</p><ul><li><strong>有曝光没点击（没用）</strong>：用户感兴趣，可能碰巧没有点击。</li></ul><hr><p>一个物品能够通过精排模型的甄别最终曝光给用户，说明物品已经非常匹配用户的兴趣点。每次给用户展示几十个物品，用户不可能每个物品都点击。没有点击不代表不感兴趣，可能只是用户对别的物品更感兴趣，就点击了别的，或者是用户感兴趣只是碰巧没有点击。</p><p>曝光但是没有点击的物品已经算是非常匹配了，甚至可以拿来做召回的正样本，不应该把曝光但是没有点击的物品作为召回的负样本。</p><ul><li><strong>召回的目的</strong> 是区分不感兴趣的和比较感兴趣的。</li></ul><ul><li><strong>排序的目的</strong> 是区分比较感兴趣的和非常感兴趣的。</li></ul><h4 id=总结-9 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-9 aria-labelledby=总结-9><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>正样本</strong>：曝光而且有点击。</p><p><strong>负样本</strong>：</p><ul><li>简单负样本：<ul><li>全体物品。</li><li>batch 内负样本。</li></ul></li><li>困难负样本：被召回，但是被排序淘汰。</li></ul><p><strong>错误</strong>：曝光、但是未点击的物品做召回的负样本。</p><h3 id=线上召回和更新 class=heading>线上召回和更新<a href=#%e7%ba%bf%e4%b8%8a%e5%8f%ac%e5%9b%9e%e5%92%8c%e6%9b%b4%e6%96%b0 aria-labelledby=线上召回和更新><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=线上召回 class=heading>线上召回<a href=#%e7%ba%bf%e4%b8%8a%e5%8f%ac%e5%9b%9e aria-labelledby=线上召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407213805840.png width=30% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407213835499.png width=30% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407213858427.png width=30% alt></center><p>用训练好的两个塔分别提取 <strong>用户特征</strong> 和 <strong>物品特征</strong>。</p><p><strong>离线存储</strong>：把 <strong>物品向量</strong>
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span><strong>存入向量数据库</strong>。</p><ol><li><p>完成训练之后，用物品塔计算每个物品的特征向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span>。</p></li><li><p>把几亿个
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">⟨</mo><mtext>特征向量</mtext><mi mathvariant="bold">b</mi><mo separator="true">,</mo><mtext>物品</mtext><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mo stretchy="false">⟩</mo></mrow><annotation encoding="application/x-tex"> \langle \text{特征向量} \mathbf{b}, \text{物品}\mathrm{ID} \rangle</annotation></semantics></math></span>
</span>二元组存入向量数据库（比如 Milvus、Faiss、HnswLib）。</p></li><li><p>向量数据库建索引：把向量空间划分成很多区域，每个区域用一个向量表示。以便加速最近邻查找。</p></li></ol><p><strong>线上召回</strong>：查找用户最感兴趣的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品。</p><ol><li><p>给定 <strong>用户 ID 和画像</strong>，<strong>线上实时</strong> 用神经网络算用户向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>。（不要事先计算和存储用户向量，而是当用户发起推荐请求的时候调用神经网络在线上实时计算一个特征向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>）。</p></li><li><p>最近邻查找：</p><ul><li><p>把向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>作为 query，调用向量数据库做最近邻查找。</p></li><li><p>返回余弦相似度最大的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品，作为召回结果。</p></li></ul></li></ol><ul><li>接下来这些物品会跟 <code>Itemcf</code>、<code>Swing</code>、<code>Usercf</code> 等召回通道的结果融合，然后经过排序，最终展示给用户。</li></ul><hr><p><strong>事先存储物品向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span>，线上实时计算用户向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>的原因</strong></p><ul><li><p>每做一次召回，用到一个用户向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>，几亿物品向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">b</mi></mrow><annotation encoding="application/x-tex">\mathbf{b}</annotation></semantics></math></span>
</span>（<strong>线上算物品向量的代价过大</strong>）。</p></li><li><p><strong>用户兴趣动态变化，而物品特征相对稳定</strong>。（可以离线存储用户向量，但不利于推荐效果。）</p></li></ul><h4 id=模型更新 class=heading>模型更新<a href=#%e6%a8%a1%e5%9e%8b%e6%9b%b4%e6%96%b0 aria-labelledby=模型更新><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><h5 id=全量更新 class=heading>全量更新<a href=#%e5%85%a8%e9%87%8f%e6%9b%b4%e6%96%b0 aria-labelledby=全量更新><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><p><strong>今天凌晨，用昨天全天的数据训练模型</strong>。</p><ul><li><p>在 <strong>昨天模型参数的基础</strong> 上做训练。(不是随机初始化)</p></li><li><p>用昨天的数据，训练
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>epoch，即每天数据只用一遍。</p></li><li><p>发布新的 <strong>用户塔神经网络</strong> 和 <strong>物品向量</strong>，供线上召回使用。</p></li><li><p>全量更新对数据流、系统的要求比较低。</p></li></ul><h5 id=增量更新 class=heading>增量更新<a href=#%e5%a2%9e%e9%87%8f%e6%9b%b4%e6%96%b0 aria-labelledby=增量更新><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><p>做 online learning 更新模型参数，每隔几十分钟就把新的模型参数给发布出去。</p><p><strong>【原因】</strong>：用户 兴趣会随时发生变化，想要让模型在用户行为发生几小时之内就做出反应，模型需要做到小时级别的增量更新。</p><ul><li><p>实时收集线上数据，做流式处理；<strong>生成 TFRecord 文件</strong>。</p></li><li><p>对模型做 online learning，增量更新 <strong>ID Embedding 参数</strong>。（<strong>不更新神经网络其他部分的参数</strong>。）</p></li><li><p><strong>发布用户 ID Embedding</strong>，供用户塔在线上计算用户向量。</p></li><li><p>用户 ID Embedding 是一个哈希表的形式，给定用户 id 可以查出 ID Embedding 向量。发布用户 ID Embedding 的目的是为了线上计算用户的特征向量。最新的用户 ID Embedding 可以捕捉到用户的最新的兴趣点，对推荐很有帮助。</p></li><li><p>发布用户 ID Embedding 这个过程会有延迟。通过对系统做优化，延迟可以从几小时降低到几十分钟甚至更短。即用户的行为变化在几十分钟之后会造成他的用户向量被更新。当再次给该用户做推荐时，双塔模型会考虑到他最新的兴趣。</p></li></ul><hr><h5 id=全量更新-vs-增量更新 class=heading>全量更新 v.s. 增量更新<a href=#%e5%85%a8%e9%87%8f%e6%9b%b4%e6%96%b0-vs-%e5%a2%9e%e9%87%8f%e6%9b%b4%e6%96%b0 aria-labelledby=全量更新-vs-增量更新><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407214429230.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407214458694.png width=45% alt></center><p>昨天凌晨时，把 <strong>前天的数据</strong> 打包成 tf record 的文件，做 random shuffle 打乱，基于 <strong>前天凌晨全量训练出来的模型</strong> 做训练，只训练
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>epoch。</p><p>接下来是要 <strong>基于这个全量训练出来的模型</strong>，<strong>做分钟级别的增量更新</strong>。从昨天凌晨到今天凌晨不停做 online learning，每隔几十分钟发布一次模型，刷新线上的用户塔 embedding 层参数。</p><p>在昨天又积累了一天的数据，到了今天凌晨又该做一次全量更新。</p><p>今天凌晨的全量更新是基于 <strong>昨天凌晨全量训练出来的模型</strong>，<strong>而不是用下面增量训练出来的模型</strong>。在完成这次全量训练之后，下面增量训练出的模型就可以扔掉了。</p><p>然后再基于 <strong>今天凌晨全量训练出来的模型</strong>，做分钟级别的增量更新。从今天凌晨到明天凌晨，不停做 online learning，每隔几十分钟发布一次模型，刷新线上的用户塔 embedding 层参数</p><hr><p><strong>【问题】：能否只做增量更新，不做全量更新？</strong>(去掉上面的全量更新，接着昨天的增量更新训练)</p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407214730445.png width=50% alt></center><ul><li><p>小时级数据有偏；分钟级数据偏差更大。</p></li><li><p><strong>全量更新</strong>：<strong>random shuffle 一天的数据</strong>；做
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>epoch 训练。</p></li><li><p><strong>增量更新</strong>：<strong>按照数据从早到晚的顺序</strong>，做
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>epoch 训练。</p></li><li><p><strong>随机打乱优于按顺序排列数据，全量训练优于增量训练</strong>。</p></li></ul><h4 id=总结-10 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-10 aria-labelledby=总结-10><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>双塔模型</strong></p><ul><li><p>用户塔、物品塔各输出一个向量，两个向量的余弦相似度作为兴趣的预估值。</p></li><li><p>三种训练的方式：</p><ul><li><code>pointwise</code>、<code>pairwise</code>、<code>listwise</code></li></ul></li><li><p>正样本：用户点击过的物品。</p></li><li><p>负样本：全体物品（简单）、被排序淘汰的物品(困难）。</p></li></ul><hr><p><strong>召回</strong></p><ul><li><p>做完训练，把物品向量存储到向量数据库，供线上最近邻查找。</p></li><li><p>线上召回时，给定用户 ID、用户画像，调用用户塔现算用户向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>。</p></li><li><p>把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">a</mi></mrow><annotation encoding="application/x-tex">\mathbf{a}</annotation></semantics></math></span>
</span>作为 query，查询向量数据库，找到余弦相似度最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品向量，返回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个物品 ID。</p></li></ul><hr><p><strong>更新模型</strong></p><ul><li><p>全量更新：今天凌晨，用昨天的数据训练整个神经网络；做
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>epoch 的随机梯度下降。</p></li><li><p>增量更新：用实时数据训练神经网络，只更新 ID Embedding，锁住全连接层。</p></li></ul><p>实际的系统：</p><ul><li><p>全量更新 & 增量更新相结合。</p></li><li><p>每隔几十分钟，发布最新的用户 ID Embedding，供用户塔在线上计算用户向量。</p></li></ul><h3 id=双塔模型自监督学习 class=heading>双塔模型+自监督学习<a href=#%e5%8f%8c%e5%a1%94%e6%a8%a1%e5%9e%8b%e8%87%aa%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0 aria-labelledby=双塔模型自监督学习><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=双塔模型的训练-1 class=heading>双塔模型的训练<a href=#%e5%8f%8c%e5%a1%94%e6%a8%a1%e5%9e%8b%e7%9a%84%e8%ae%ad%e7%bb%83-1 aria-labelledby=双塔模型的训练-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407220038009.png width=50% alt></center><p>双塔模型，左边是用户塔，右边是物品塔。自监督学习的目的是把物品塔训练得更好。</p><h5 id=双塔模型的问题 class=heading>双塔模型的问题<a href=#%e5%8f%8c%e5%a1%94%e6%a8%a1%e5%9e%8b%e7%9a%84%e9%97%ae%e9%a2%98 aria-labelledby=双塔模型的问题><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><ul><li><p>推荐系统的头部效应严重：</p><ul><li><p>少部分物品占据大部分点击。</p></li><li><p>大部分物品的点击次数不高。</p></li></ul></li><li><p>高点击物品的表征学得好，长尾物品的表征学得不好。</p></li><li><p>自监督学习：做 data augmentation 更好地学习长尾物品的向量表征。</p></li></ul><p><a href=https://arxiv.org/abs/2007.12865 class=markdown-link>Self-supervised Learning for Large-scale Item Recommendations</a></p><hr><p><strong>复习：双塔模型的训练</strong></p><p><strong>batch 内负样本</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407212611463.png width=35% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407212645068.png width=35% alt></center><hr><p><strong><code>Listwise </code>训练</strong></p><p><strong>正样本</strong>: 一个 batch 包含
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>对（有点击）</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>n</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
(\mathbf{a}_1, \mathbf{b}_1), (\mathbf{a}_2, \mathbf{b}_2), \cdots ,(\mathbf{a}_n, \mathbf{b}_n)
</annotation></semantics></math></span></div><p><strong>负样本</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{(\mathbf{a}_i,\mathbf{b}_j)\}</annotation></semantics></math></span>
</span>，对于所有的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>j</mi></mrow><annotation encoding="application/x-tex">i \ne j</annotation></semantics></math></span>
</span>。</p><ul><li><p>一个 batch 内有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>对正样本组成
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个 list，每个 list 中有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>对正样本和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span>
</span>对负样本</p></li><li><p>鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos (\mathbf{a}_i, \mathbf{b}_i)</annotation></semantics></math></span>
</span>尽量大，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_j)</annotation></semantics></math></span>
</span>尽量小。</p></li></ul><p><strong>损失函数</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250407220913288.png width=50% alt></center><p>考虑 bath 内第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>个用户和全部
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个物品，这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个数值分别是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mn>1</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mn>2</mn></msub><mo stretchy="false">)</mo><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>n</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_1), \cos(\mathbf{a}_i, \mathbf{b}_2), \cdots ,\cos(\mathbf{a}_i, \mathbf{b}_n)</annotation></semantics></math></span>
</span>。</p><ul><li><p><strong>向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_i</annotation></semantics></math></span>
</span></strong>：把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个 cos 值输入 Softmax 激活函数，得到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个概率值
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{i,1}, p_{i,2}, \cdots , p_{i,n}</annotation></semantics></math></span>
</span>。把这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个概率值记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_i</annotation></semantics></math></span>
</span>。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathbf{a}_i, \mathbf{b}_i)</annotation></semantics></math></span>
</span>为一对正样本。如果双塔模型的预估足够准确，那么
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_i)</annotation></semantics></math></span>
</span>应该比其他
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n-1</annotation></semantics></math></span>
</span>个
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\cos</annotation></semantics></math></span>
</span>值相似度大很多。<code>Softmax</code> 输出的概率值
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">p_{i,i}</annotation></semantics></math></span>
</span>应该接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。</p></li><li><p><strong>标签
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math></span>
</span></strong>的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个数值除了第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>个元素（
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\mathbf{a}_i, \mathbf{b}_i)</annotation></semantics></math></span>
</span>的标签）是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>之外，其余全都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>。</p></li></ul><p><strong>损失函数</strong>：用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_i</annotation></semantics></math></span>
</span>的交叉熵作为损失函数：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>CrossEntropyLoss</mtext><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">p</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
\text{CrossEntropyLoss}(\mathbf{y}_i,\mathbf{p}_i) = -\log p_{i, i} = -\log\left( \frac{\exp(\cos(\mathbf{a}_i,\mathbf{b}_i)))}{\sum_{j = 1}^n\exp(\cos(\mathbf{a}_i,\mathbf{b}_j)))}\right)
</annotation></semantics></math></span></div><hr><p><strong>纠偏</strong></p><p>batch 内负样本会过度打压热门物品造成偏差，需要做纠偏。</p><ul><li><p>物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>被抽样到的概率：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mi>j</mi></msub><mo>∝</mo><mtext>点击次数</mtext></mrow><annotation encoding="application/x-tex">p_j \propto \text{点击次数}</annotation></semantics></math></span>
</span>。</p></li><li><p>预估用户
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>对物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span>
</span>的兴趣：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_j)</annotation></semantics></math></span>
</span>。</p></li><li><p>做训练的时候，把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_j)</annotation></semantics></math></span>
</span>替换为：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_j) - \log{p_j}</annotation></semantics></math></span>
</span>。</p></li><li><p>在线上做召回的时候，还是用原本的余弦相似度
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{a}_i, \mathbf{b}_j)</annotation></semantics></math></span>
</span>，不用做调整。</p></li></ul><hr><p><strong>总结</strong></p><ul><li><p>从点击数据中随机抽取
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个用户—物品二元组，组成一个 batch。</p></li><li><p>双塔模型的损失函数：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>i</mi></msub></mrow><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><mi>exp</mi><mo>⁡</mo><mo fence="false" stretchy="true" minsize="2.4em" maxsize="2.4em">(</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi mathvariant="bold">a</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">b</mi><mi>j</mi></msub><mo stretchy="false">)</mo><mo stretchy="false">)</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>p</mi><mi>i</mi></msub><mo fence="false" stretchy="true" minsize="2.4em" maxsize="2.4em">)</mo></mrow></mfrac><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
  L_{\mathrm{main}}[i] = -\log\left( \frac{\exp(\cos(\mathbf{a}_i,\mathbf{b}_i)))-\log p_i}{\sum_{j = 1}^n\exp\bigg(\cos(\mathbf{a}_i,\mathbf{b}_j))-\log p_i\bigg)}\right)
  </annotation></semantics></math></span></div></li><li><p>做梯度下降，减小损失函数</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>L</mi><mrow><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">
  \frac{1}{n}\sum_{i = 1}^nL_{\mathrm{main}}[i]
  </annotation></semantics></math></span></div></li></ul><h4 id=自监督学习 class=heading>自监督学习<a href=#%e8%87%aa%e7%9b%91%e7%9d%a3%e5%ad%a6%e4%b9%a0 aria-labelledby=自监督学习><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>用自监督学习训练物品塔</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407221517888.png width=45% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250407221541137.png width=45% alt></center><p>对两个不同的物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span>
</span>，对两个物品的特征做随机变换，得到特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">i^{\prime}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>j</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup></mrow><annotation encoding="application/x-tex">j^{\prime}</annotation></semantics></math></span>
</span>。</p><p>对两个物品做另一种特征变换，得到特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">i^{\prime \prime}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msup></mrow><annotation encoding="application/x-tex">j^{\prime \prime}</annotation></semantics></math></span>
</span>。</p><p>把这些变换过的特征输入物品塔模型 （同一个模型（共享参数））。</p><ul><li><p>物品塔输出物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>的向量表征，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">b^{\prime}_i</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">b^{\prime \prime}_i</annotation></semantics></math></span>
</span>，两者有较高的相似度。</p></li><li><p>物品塔输出物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span>
</span>的向量表征，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>j</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">b^{\prime}_j</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">b^{\prime \prime}_j</annotation></semantics></math></span>
</span>，两者有较高的相似度。</p></li></ul><p>不同的物品的向量表征应该离得尽量远，物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span>
</span>的向量表征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">b^{\prime}_i</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi>b</mi><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">b^{\prime \prime}_j</annotation></semantics></math></span>
</span>有较低的相似度。</p><p>做训练的时候， 鼓励
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{b}_i^{\prime}, \mathbf{b}_i^{\prime \prime})</annotation></semantics></math></span>
</span>尽量大，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\cos(\mathbf{b}_i^{\prime}, \mathbf{b}_j^{\prime \prime})</annotation></semantics></math></span>
</span>尽量小。</p><h5 id=特征变换 class=heading>特征变换<a href=#%e7%89%b9%e5%be%81%e5%8f%98%e6%8d%a2 aria-labelledby=特征变换><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><h6 id=random-mask class=heading>Random Mask<a href=#random-mask aria-labelledby=random-mask><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h6><p>随机选一些离散特征（比如类目），把它们遮住。</p><ul><li><p>某物品的类目特征是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>=</mo><mo stretchy="false">{</mo><mtext>数码</mtext><mo separator="true">,</mo><mtext>摄影</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">U = \{\text{数码},\text{摄影}\}</annotation></semantics></math></span>
</span>。</p></li><li><p>Mask 后的类目特征是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>U</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mo stretchy="false">{</mo><mtext>default</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">U^{\prime} = \{\text{default}\}</annotation></semantics></math></span>
</span>。</p></li></ul><p>如果不做 <code>random mask</code>，正常的特征处理方法是：对数码和摄影分别做 embedding 得到两个向量，再取加和或者平均，最终输出一个向量表征物品的类目。</p><p>如果对类目特征做 mask，这物品的类目特征就变成了 default，即默认的缺失值。然后对 defaults 做 embedding 得到一个向量表征类目。即做 mask 之后，物品的类目特征直接被丢掉，数码和摄影都没了。</p><p>​</p><h6 id=dropout class=heading><strong>Dropout</strong><a href=#dropout aria-labelledby=dropout><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h6><p>仅对多值离散特征生效。一个物品可以有多个类目，那么类目是一个多值离散特征。</p><p><code>Dropout</code>：随机丢弃特征中
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">50\%</annotation></semantics></math></span>
</span>的值</p><ul><li><p>某物品的类目特征是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>=</mo><mo stretchy="false">{</mo><mtext>美妆</mtext><mo separator="true">,</mo><mtext>摄影</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">U = \{\text{美妆},\text{摄影}\}</annotation></semantics></math></span>
</span>。</p></li><li><p><code>Dropout </code>后的类目特征是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>U</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msup><mo>=</mo><mo stretchy="false">{</mo><mtext>美妆</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">U^{\prime}= \{\text{美妆}\}</annotation></semantics></math></span></span></p></li></ul><hr><p><strong>Random Mask 和 Dropout 的区别</strong>：</p><ul><li><p>mask 意思是把整个类目特征都丢掉，把美妆和摄影这两个值都不要了。</p></li><li><p>Dropout 只丢掉摄影这一个值，还保留美妆这个值。</p></li></ul><hr><p>​</p><h6 id=互补特征-complementary class=heading>互补特征 (Complementary)<a href=#%e4%ba%92%e8%a1%a5%e7%89%b9%e5%be%81-complementary aria-labelledby=互补特征-complementary><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h6><p>假设物品一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>种特征：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mtext>ID</mtext><mo separator="true">,</mo><mtext>类目</mtext><mo separator="true">,</mo><mtext>关键词</mtext><mo separator="true">,</mo><mtext>城市</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\text{ID}, \text{类目},  \text{关键词}, \text{城市}\}</annotation></semantics></math></span>
</span>，随机分成两组：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mtext>ID</mtext><mo separator="true">,</mo><mtext>关键词</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\text{ID},\text{关键词}\}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mtext>类目</mtext><mo separator="true">,</mo><mtext>城市</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\text{类目},\text{城市}\}</annotation></semantics></math></span>
</span>。</p><ul><li><p>物品表征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mtext>ID</mtext><mo separator="true">,</mo><mtext>default</mtext><mo separator="true">,</mo><mtext>关键词</mtext><mo separator="true">,</mo><mtext>default</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\text{ID},\text{default},\text{关键词},\text{default}\}</annotation></semantics></math></span>
</span>。</p></li><li><p>物品表征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mtext>default</mtext><mo separator="true">,</mo><mtext>类目</mtext><mo separator="true">,</mo><mtext>default</mtext><mo separator="true">,</mo><mtext>城市</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{\text{default},\text{类目},\text{default},\text{城市}\}</annotation></semantics></math></span>
</span>。</p></li></ul><p>鼓励物品表征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>和物品表征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>相似。</p><hr><p>​</p><h6 id=mask-一组关联的特征 class=heading><strong>Mask 一组关联的特征</strong><a href=#mask-%e4%b8%80%e7%bb%84%e5%85%b3%e8%81%94%e7%9a%84%e7%89%b9%e5%be%81 aria-labelledby=mask-一组关联的特征><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h6><p>特征之间有较强的关联，遮住一个特征并不会损失太多的信息。模型可以从其他强关联特征中学到遮住的特征。最好是把关联的特征一次全都遮住。</p><p><strong>【例】</strong></p><ul><li><p>受众性别：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi><mo>=</mo><mo stretchy="false">{</mo><mtext>男</mtext><mo separator="true">,</mo><mtext>女</mtext><mo separator="true">,</mo><mtext>中性</mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">U=\{\text{男},\text{女},\text{中性}\}</annotation></semantics></math></span>
</span>。</p></li><li><p>类目：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi><mo>=</mo><mo stretchy="false">{</mo><mtext>美妆</mtext><mo separator="true">,</mo><mtext>数码</mtext><mo separator="true">,</mo><mtext>足球</mtext><mo separator="true">,</mo><mtext>摄影</mtext><mo separator="true">,</mo><mtext>科技</mtext><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">V=\{\text{美妆},\text{数码},\text{足球},\text{摄影},\text{科技},\cdots \}</annotation></semantics></math></span></span></p></li></ul><p>性别和类目之间不是独立的，而是 <strong>存在某种关联</strong>：</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>=</mo><mtext>女</mtext></mrow><annotation encoding="application/x-tex">u=\text{女}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mo>=</mo><mtext>美妆</mtext></mrow><annotation encoding="application/x-tex">v=\text{美妆}</annotation></semantics></math></span>
</span>同时出现的概率
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(u,v)</annotation></semantics></math></span>
</span>大。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi><mo>=</mo><mtext>女</mtext></mrow><annotation encoding="application/x-tex">u=\text{女}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi><mo>=</mo><mtext>数码</mtext></mrow><annotation encoding="application/x-tex">v=\text{数码}</annotation></semantics></math></span>
</span>同时出现的概率
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(u,v)</annotation></semantics></math></span>
</span>小。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(u)</annotation></semantics></math></span>
</span>：某特征取值为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>的概率。</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mtext>男</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>20</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p(\text{男})=20\%</annotation></semantics></math></span></span></li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mtext>女</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>30</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p(\text{女})=30\%</annotation></semantics></math></span></span></li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mtext>中性</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>50</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p(\text{中性})=50\%</annotation></semantics></math></span></span></li></ul></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(u,v)</annotation></semantics></math></span>
</span>：某特征取值为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>u</mi></mrow><annotation encoding="application/x-tex">u</annotation></semantics></math></span>
</span>，另一个特征取值为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span>
</span>，同时发生的概率：</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mtext>女</mtext><mo separator="true">,</mo><mtext>美妆</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>3</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p(\text{女},\text{美妆})=3\%</annotation></semantics></math></span></span></li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mtext>女</mtext><mo separator="true">,</mo><mtext>数码</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>0.1</mn><mi mathvariant="normal">%</mi></mrow><annotation encoding="application/x-tex">p(\text{女},\text{数码})=0.1\%</annotation></semantics></math></span></span></li></ul></li></ul><p>离线计算 <strong>特征两两之间的关联</strong>，用 <strong>互信息（mutual information）</strong> 衡量，两个特征关联越强，他们的 mutual information 就越大。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>M</mi><mi>I</mi><mo stretchy="false">(</mo><mi>U</mi><mo separator="true">,</mo><mi>V</mi><mo stretchy="false">)</mo><mo>=</mo><munder><mo>∑</mo><mrow><mi>u</mi><mo>∈</mo><mi>U</mi></mrow></munder><munder><mo>∑</mo><mrow><mi>v</mi><mo>∈</mo><mi>V</mi></mrow></munder><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>log</mi><mo>⁡</mo><mfrac><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo separator="true">,</mo><mi>v</mi><mo stretchy="false">)</mo></mrow><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>u</mi><mo stretchy="false">)</mo><mo>⋅</mo><mi>p</mi><mo stretchy="false">(</mo><mi>v</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow><annotation encoding="application/x-tex">
MI(U, V)=\sum_{u\in U}\sum_{v\in V} p(u, v)\cdot\log\frac{p(u, v)}{p(u)\cdot p(v)}
</annotation></semantics></math></span></div><p><strong>特征变换的目标</strong> 是 mask
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>组关联的特征：</p><ul><li><p>设一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>种特征。离线计算特征两两之间 <code>MI</code>，得到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>×</mo><mi>k</mi></mrow><annotation encoding="application/x-tex">k \times k</annotation></semantics></math></span>
</span>的矩阵，表示特征之间的关联。</p></li><li><p>随机选一个特征作为种子，找到种子最相关的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>k</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{k}{2}</annotation></semantics></math></span>
</span>种特征。</p></li><li><p>Mask 种子及其相关的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>k</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{k}{2}</annotation></semantics></math></span>
</span>种特征，保留其余的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mi>k</mi><mn>2</mn></mfrac></mrow><annotation encoding="application/x-tex">\frac{k}{2}</annotation></semantics></math></span>
</span>种特征。</p></li></ul><hr><p><strong>【优点】</strong>：比 <code>random mask</code>、<code>dropout</code>、互补特征等方法效果更好</p><p><strong>【缺点】</strong>：方法复杂，实现的难度大，不容易维护。每添加一个新的特征都需要重新算一遍。</p><h5 id=训练模型 class=heading>训练模型<a href=#%e8%ae%ad%e7%bb%83%e6%a8%a1%e5%9e%8b aria-labelledby=训练模型><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><p>从全体物品中 <strong>均匀抽样</strong>，得到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个物品，作为一个 batch</p><ul><li><p><strong>冷门物品和热门物品被抽样到的概率是相同的</strong>。</p></li><li><p><strong>【注意】</strong>：训练双塔的区别，训练双塔用的数据是根据点击行为抽样的，热门物品被抽到的概率大。</p></li></ul><p>做两类特征变换，每个物品被表征为两个向量：</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mn>1</mn><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mn>2</mn><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>m</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_1^{\prime},\mathbf{b}_2^{\prime},\cdots,\mathbf{b}_m^{\prime}</annotation></semantics></math></span></span></li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mn>1</mn><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mn>2</mn><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>m</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_1^{\prime\prime},\mathbf{b}_2^{\prime\prime},\cdots,\mathbf{b}_m^{\prime\prime}</annotation></semantics></math></span></span></li></ul><p><strong>第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>个物品的损失函数</strong></p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>L</mi><mtext>self</mtext></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mtext> </mtext><mo>=</mo><mtext> </mtext><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow></mfrac><mo fence="true">)</mo></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
L_\text{self}[i]~=~-\log\left(\frac{\exp(\cos(\mathbf{b}_i^{\prime},\mathbf{b}_i^{\prime\prime}))}{\Sigma_{j = 1}^m\exp\left(\cos\left(\mathbf{b}_i^{\prime},\mathbf{b}_j^{\prime\prime}\right)\right)}\right).
</annotation></semantics></math></span></div><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250408000629389.png width=50% alt></center><p>考虑 batch 中第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>个物品的特征向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime}</annotation></semantics></math></span>
</span>和 还有全部
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个物品的特征向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime\prime}</annotation></semantics></math></span>
</span>，计算第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>个物品和所有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个物品(包括自身)的 cos 相似度。</p><p>把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个数值输入 <code>Softmax</code> 激活函数得到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个概率值记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>1</mn></mrow></msub><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mn>2</mn></mrow></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>m</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i,1}, s_{i,2}, \cdots , s_{i,m}</annotation></semantics></math></span>
</span>。</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime\prime}</annotation></semantics></math></span>
</span>对应的是一组正样本，都是对物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span>
</span>的表征，只不过做了不同的特征变换，导致两个向量不相等。如果物品塔足够好，那么两个向量的 cos 相似度应该很高。</p></li><li><p>其余
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">m-1</annotation></semantics></math></span>
</span>个数值都对应负样本，两个向量属于不同的物品，它们的 cos 相似度应该比较小。</p></li><li><p><code>Softmax </code>输出的概率值
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub></mrow><annotation encoding="application/x-tex">s_{i,i}</annotation></semantics></math></span>
</span>应该接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>， 其余
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">m-1</annotation></semantics></math></span>
</span>个概率值应该接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，把这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个概率值记作向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{s}_i</annotation></semantics></math></span>
</span>。</p></li></ul><p>上面的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个数值是标签全都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，只有正样本对应的是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。把这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个标签记作向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math></span>
</span>。</p><p>做训练的时候，我们希望向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{s}_i</annotation></semantics></math></span>
</span>尽量接近向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math></span>
</span>，如果
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{s}_i</annotation></semantics></math></span>
</span>接近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math></span>
</span>，说明物品塔训练的比较好，即使做随机特征变换，对物品的向量表征也影响不大。</p><p><strong>损失函数</strong>：用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{y}_i</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">s</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\mathbf{s}_i</annotation></semantics></math></span>
</span>的交叉熵作为损失函数：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mtext>CrossEntropyLoss</mtext><mo stretchy="false">(</mo><msub><mi mathvariant="bold">y</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi mathvariant="bold">s</mi><mi>i</mi></msub><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><msub><mi>s</mi><mrow><mi>i</mi><mo separator="true">,</mo><mi>i</mi></mrow></msub><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mrow><mi>exp</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo stretchy="false">)</mo><mo stretchy="false">)</mo></mrow><mrow><msubsup><mi mathvariant="normal">Σ</mi><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mi>cos</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup><mo separator="true">,</mo><msubsup><mi mathvariant="bold">b</mi><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow></mrow></mfrac><mo fence="true">)</mo></mrow><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
\text{CrossEntropyLoss}(\mathbf{y}_i,\mathbf{s}_i) = -\log s_{i, i} = -\log\left(\frac{\exp(\cos(\mathbf{b}_i^{\prime},\mathbf{b}_i^{\prime\prime}))}{\Sigma_{j = 1}^m\exp\left(\cos\left(\mathbf{b}_i^{\prime},\mathbf{b}_j^{\prime\prime}\right)\right)}\right).
</annotation></semantics></math></span></div><p>训练的过程中要做梯度下降，对
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>项损失函数取平均作为自监督学习的损失:</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi>L</mi><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">f</mi></mrow></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
\frac{1}{m}\sum_{i = 1}^m L_{\mathrm{self}}[i].
</annotation></semantics></math></span></div><h4 id=总结-11 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-11 aria-labelledby=总结-11><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ul><li><p>双塔模型学不好低曝光物品的向量表征。</p><p>这不是双塔模型的问题，而是数据的问题。真实推荐系统都存在头部效应，小部分物品占据了大部分的曝光和点击。</p></li><li><p>自监督学习：</p><ul><li>对于同一个物品，用不同的特征变换。</li><li>特征向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime\prime}</annotation></semantics></math></span>
</span>相似度高 (相同物品)。</li><li>特征向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>i</mi><mo mathvariant="normal" lspace="0em" rspace="0em">′</mo></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_i^{\prime}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mi mathvariant="bold">b</mi><mi>j</mi><mrow><mo mathvariant="normal">′</mo><mo mathvariant="normal">′</mo></mrow></msubsup></mrow><annotation encoding="application/x-tex">\mathbf{b}_j^{\prime\prime}</annotation></semantics></math></span>
</span>相似度低（不同物品)。</li></ul><p>让物品的向量表征尽量 spread out，分散在整个特征空间上，而不是集中在一起。</p></li><li><p>实验效果：<strong>低曝光物品、新物品的推荐变得更准</strong>。</p></li></ul><hr><p><strong>【训练模型】</strong></p><p>对点击做随机抽样，得到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>对用户-物品二元组，作为一个 batch。这个 batch 用来训练双塔，包括用户塔和物品塔。热门物品被抽到的概率高。</p><p>从全体物品中均匀抽样（热门和冷门物品被抽到的概率相同），得到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个物品，作为一个 batch。这个 batch 用来做自监督学习，只训练物品。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><munder><munder><mrow><mfrac><mn>1</mn><mi>n</mi></mfrac><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>n</mi></munderover><msub><mi>L</mi><mtext>main</mtext></msub><mo stretchy="false">[</mo><mi>i</mi><mo stretchy="false">]</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>双塔模型的损失</mtext></munder><mo>+</mo><munder><munder><mrow><mi>α</mi><mo>⋅</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></munderover><msub><mi>L</mi><mtext>self</mtext></msub><mo stretchy="false">[</mo><mi>j</mi><mo stretchy="false">]</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>自监督学习的损失</mtext></munder></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
\begin{aligned}
\underbrace{\frac1n\sum_{i = 1}^nL_\text{main}[i]}_{\text{双塔模型的损失}}+\underbrace{\alpha \cdot\frac1m\sum_{j = 1}^mL_\text{self}[j]}_{\text{自监督学习的损失}}
\end{aligned}
</annotation></semantics></math></span></div><p>alpha：超参数，决定自监督学习起到的作用。</p><h2 id=deep-retrieval class=heading>Deep Retrieval<a href=#deep-retrieval aria-labelledby=deep-retrieval><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p><a href=https://arxiv.org/abs/2007.07203 class=markdown-link>Deep Retrieval: Learning A Retrievable Structure for Large-Scale Recommendations</a></p><ul><li><p>经典的双塔模型把用户、物品表示为向量，线上做最近邻查找。</p></li><li><p>Deep Retrieval 把物品表征为路径（path），线上查找用户最匹配的路径。</p></li><li><p>Deep Retrieval 类似于阿里的 <code>TDM</code> (
<a href=https://arxiv.org/abs/1801.02294 class=markdown-link>Learning Tree-based Deep Model for Recommender Systems</a>)</p></li></ul><h3 id=索引-2 class=heading>索引<a href=#%e7%b4%a2%e5%bc%95-2 aria-labelledby=索引-2><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><strong>物品表征为路径</strong></p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250615220149664.png width=20% alt></center><ul><li><p>深度:
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>depth</mtext><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">\text{depth} = 3</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>L</mi><mn>2</mn></msub><mo separator="true">,</mo><msub><mi>L</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">L_1, L_2, L_3</annotation></semantics></math></span>
</span>表示结构的三层。</p></li><li><p>宽度:
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>width</mtext><mo>=</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">\text{width}=K</annotation></semantics></math></span>
</span>，每一层里面有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点。</p></li><li><p>把一个物品表示为一条路径 (path)，比如
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[2,4,1]</annotation></semantics></math></span>
</span>。</p></li><li><p>一个物品可以表示为多条路径，每条路径都有三个节点，路径可以有重合的节点，比如
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo><mo separator="true">,</mo><mo stretchy="false">[</mo><mn>4</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{[2,4,1], [4,1, 1]\}</annotation></semantics></math></span></span></p></li></ul><hr><p><strong>Deep Retrieval</strong> 用到 <strong>两个索引</strong>：</p><ul><li><p><strong>索引：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>item</mtext><mo>→</mo><mtext>List(path)</mtext></mrow><annotation encoding="application/x-tex">\text{item}  \rightarrow \text{List(path)}</annotation></semantics></math></span></span></strong></p><ul><li><p>一个物品对应多条路径。</p></li><li><p>假设结构有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>层，则用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>个节点表示一条路径：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>α</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path}=[α,b,c]</annotation></semantics></math></span>
</span>。</p></li><li><p>训练神经网络的时候要用到这个索引。</p></li></ul></li><li><p><strong>索引：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>→</mo><mtext>List(item)</mtext></mrow><annotation encoding="application/x-tex">\text{path}  \rightarrow \text{List(item)}</annotation></semantics></math></span></span></strong></p><ul><li><p>一条路径对应多个物品。</p></li><li><p>线上做召回的时候要用到这个索引，给定一条路径会取回很多个物品作为召回的结果。</p></li></ul></li></ul><h3 id=预估模型 class=heading>预估模型<a href=#%e9%a2%84%e4%bc%b0%e6%a8%a1%e5%9e%8b aria-labelledby=预估模型><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><strong>预估用户对路径的兴趣</strong></p><p>给定用户特征，神经网络可以预估用户对路径的兴趣分数。用这种神经网络可以根据用户特征召回多条路径。</p><p>假设结构有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>层, 用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>个节点表示一条路径：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path}=[a,b,c]</annotation></semantics></math></span>
</span>。</p><ul><li><p>给定用户特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>，预估用户对节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>的兴趣
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{p}_1(a |\mathbf{x})</annotation></semantics></math></span>
</span>。</p></li><li><p>给定
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>，预估用户对节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>
</span>的兴趣
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{p}_2(b |a;\mathbf{x})</annotation></semantics></math></span>
</span>。</p></li><li><p>给定
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>
</span>，预估用户对节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span>
</span>的兴趣
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>3</mn></msub><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathbf{p}_3(c |a,b;\mathbf{x})</annotation></semantics></math></span>
</span>。</p></li></ul><p>预估用户对
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>α</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path}=[α,b,c]</annotation></semantics></math></span>
</span>兴趣：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="bold">p</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi mathvariant="bold">p</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi mathvariant="bold">p</mi><mn>3</mn></msub><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">
\mathbf{p}(a, b, c|\mathbf{x}) = \mathbf{p}_1(a|\mathbf{x})\times \mathbf{p}_2(b|a;\mathbf{x})\times \mathbf{p}_3(c|a, b;\mathbf{x}).
</annotation></semantics></math></span></div><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615220902227.png width=40% alt><br><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615220933363.png width=40% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615221003866.png width=40% alt></center><p>​</p><ol><li><p>模型的输入是用户特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>，输入神经网络，最后通过 <code>Softmax</code> 激活函数得到向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_1</annotation></semantics></math></span>
</span>。</p><ul><li><p>如果结构的每一层有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点，那么
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_1</annotation></semantics></math></span>
</span>就是个
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>维向量。</p></li><li><p>图中的结构一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>层，每层有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点。向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_1</annotation></semantics></math></span>
</span>对应
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span>
</span>层。</p></li><li><p>向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_1</annotation></semantics></math></span>
</span>的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个元素是神经网络给
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span>
</span>层
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点打的分数。分数越高，节点就越有可能被选中。</p></li><li><p>根据向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_1</annotation></semantics></math></span>
</span>可以从
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点中选出一个节点，记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>。</p></li><li><p>使用 <code>beam search</code> 的方法。</p></li></ul></li><li><p>把向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>一起输入下一层神经网络，从结构的第二层
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span>
</span>中选出一个节点。</p><ul><li>向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>不变，直接作为下一层的输入。</li><li>对节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>做 embedding 得到黄色的向量记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>emb</mtext><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{emb}(a)</annotation></semantics></math></span>
</span>。</li><li>对向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>emb</mtext><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{emb}(a)</annotation></semantics></math></span>
</span>做 concatenation 然后输入另一个神经网络(输出层也用 Softmax 激活函数)得到输出向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_2</annotation></semantics></math></span>
</span>，也为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>维向量。向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_2</annotation></semantics></math></span>
</span>对应
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span>
</span>层。</li><li>向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_2</annotation></semantics></math></span>
</span>的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个元素是神经网络给
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span>
</span>层
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点打的分数。根据分数从
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点中选出一个节点记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span></span></li><li>使用 <code>beam search</code> 的方法。</li></ul></li><li><p>最后把向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>
</span>一起输入下一层神经网络。</p><ul><li><p>向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>emb</mtext><mo stretchy="false">(</mo><mi>a</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{emb}(a)</annotation></semantics></math></span>
</span>不变，直接作为下一层的输入。</p></li><li><p>对节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>b</mi></mrow><annotation encoding="application/x-tex">b</annotation></semantics></math></span>
</span>作 embedding 得到向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>emb</mtext><mo stretchy="false">(</mo><mi>b</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{emb}(b)</annotation></semantics></math></span>
</span>。</p></li><li><p>对三个向量做 concatenation 然后输入神经网络（输出层也用 soft max 激活函数）得到输出向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_3</annotation></semantics></math></span>
</span>，也为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>维向量。向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_3</annotation></semantics></math></span>
</span>对应
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">L_3</annotation></semantics></math></span>
</span>层。</p></li><li><p><strong>三层神经网络不共享参数</strong>。</p></li><li><p>根据分数从
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点中选出一个记作节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>c</mi></mrow><annotation encoding="application/x-tex">c</annotation></semantics></math></span>
</span>。</p></li></ul></li><li><p>从三层中各选出一个节点组成了路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path}=[a,b,c]</annotation></semantics></math></span>
</span>。</p></li></ol><h3 id=线上召回-1 class=heading>线上召回<a href=#%e7%ba%bf%e4%b8%8a%e5%8f%ac%e5%9b%9e-1 aria-labelledby=线上召回-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>路径</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow \text{路径} \rightarrow \text{物品}</annotation></semantics></math></span></span></p><ol><li><p>给定用户特征，用 <code>beam search</code> 召回一批路径。</p></li><li><p>利用索引
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>→</mo><mtext>List(item)</mtext></mrow><annotation encoding="application/x-tex">\text{path} \rightarrow \text{List(item)}</annotation></semantics></math></span>
</span>，召回一批物品。</p></li><li><p>对物品做打分和排序，选出一个子集。</p></li></ol><h4 id=beam-search class=heading>Beam Search<a href=#beam-search aria-labelledby=beam-search><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>假设有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>层，每层
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点，那么一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>K</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">K^3</annotation></semantics></math></span>
</span>条路径。用神经网络给所有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>K</mi><mn>3</mn></msup></mrow><annotation encoding="application/x-tex">K^3</annotation></semantics></math></span>
</span>条路径打分，计算量太大。</p><p>用 <code>beam search</code>，可以减小计算量。需要设置超参数 <code>beam size</code>。<code>beam size</code> 越大，计算量越大，search 的结果也会越好。</p><h5 id=beam-size--1 class=heading>Beam size = 1<a href=#beam-size--1 aria-labelledby=beam-size--1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615222113939.png width=40% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615222142524.png width=40% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615222240972.png width=40% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615222319285.png width=40% alt></center><ol><li><p>第一层一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点，用前面讲的神经网络的第一层给这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点打分。设置了
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>beam size</mtext><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\text{beam size} = 1</annotation></semantics></math></span>
</span>，所以每次只选一个节点，选分数最高的节点（5 号）。</p></li><li><p>第二层有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点，从第一层的 5 号节点出发，有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>条路径通往第二层。</p><p>把用户特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和第一层的 5 号节点作为输入，计算出这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个分数记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_2</annotation></semantics></math></span>
</span>。在这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个分数当中选出分数最高的节点（4 号）。</p></li><li><p>从第一层的 5 号节点出发，到达第二层的 4 号节点。然后有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>条路径通往第三层。</p><p>把用户特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>和前两层的 5 号节点、4 号节点作为输入，计算出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个分数记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="bold">p</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">\mathbf{p}_3</annotation></semantics></math></span>
</span>。在这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个分数当中选出分数最高的节点（1 号）。</p></li><li><p>从这些路径中选出这条红色的路径。结构有三层，每条路径可以表示为三个节点。这条选中的红色路径可以表示为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>5</mn><mo separator="true">,</mo><mn>4</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[5,4,1]</annotation></semantics></math></span>
</span>。</p></li></ol><hr><ul><li><p>用户对
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path} =[a, b, c]</annotation></semantics></math></span>
</span>兴趣：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>p</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mn>3</mn></msub><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
  p(a, b, c|\mathbf{x}) = p_1(a|\mathbf{x})\times p_2(b|a;\mathbf{x})\times p_3(c|a, b;\mathbf{x})
  </annotation></semantics></math></span></div><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">p_1</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">p_2</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">p_3</annotation></semantics></math></span>
</span>表示神经网络的三个输出。</p></li><li><p>最优的路径是分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>
</span>最大的路径：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mo>⋆</mo></msup><mo separator="true">,</mo><msup><mi>b</mi><mo>⋆</mo></msup><mo separator="true">,</mo><msup><mi>c</mi><mo>⋆</mo></msup><mo stretchy="false">]</mo><mo>=</mo><mi><munder><mo><mi mathvariant="normal">argmax</mi><mo>⁡</mo></mo><mrow><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi></mrow></munder></mi><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
  [a^\star, b^\star, c^\star] = \underset{a, b, c}{\operatorname*{argmax}} p(a, b, c\mid\mathbf{x})
  </annotation></semantics></math></span></div></li><li><p>贪心算法（beam size = 1）选中的路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a,b,c]</annotation></semantics></math></span>
</span>未必是最优的路径。</p></li></ul><h5 id=beam-size--4 class=heading>Beam size = 4<a href=#beam-size--4 aria-labelledby=beam-size--4><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h5><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615222926821.png width=40% alt>
<img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615223013502.png width=40% alt></center><p>​</p><ol><li><p>用神经网络给
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span>
</span>层的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>K</mi></mrow><annotation encoding="application/x-tex">K</annotation></semantics></math></span>
</span>个节点打分，由于 <code>beam size</code> 等于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>，因此选出分数最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>个节点。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span>
</span>选出了
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>个节点，因此从
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span>
</span>到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span>
</span>有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">4\times K</annotation></semantics></math></span>
</span>条路径</p><ul><li>对于每个被选中的节点
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>a</mi></mrow><annotation encoding="application/x-tex">a</annotation></semantics></math></span>
</span>，计算用户对路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a,b]</annotation></semantics></math></span>
</span>的兴趣:
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>p</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p_1(a|\mathbf{x})\times p_2(b|a;\mathbf{x})</annotation></semantics></math></span>
</span>。</li><li>算出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">4\times K</annotation></semantics></math></span>
</span>个分数，每个分数对应一条路径，选出分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>top </mtext><mn>4</mn></mrow><annotation encoding="application/x-tex">\text{top } 4</annotation></semantics></math></span>
</span>的路径。</li></ul></li><li><p>从
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">L_1</annotation></semantics></math></span>
</span>到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>L</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">L_2</annotation></semantics></math></span>
</span>一共有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mo>×</mo><mi>K</mi></mrow><annotation encoding="application/x-tex">4\times K</annotation></semantics></math></span>
</span>条路径，从这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn><mi>K</mi></mrow><annotation encoding="application/x-tex">4K</annotation></semantics></math></span>
</span>条路径中选出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>条。</p></li><li><p>最终选中的路径为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[2,1,1]</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>1</mn><mo separator="true">,</mo><mn>4</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[2,1,4]</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>2</mn><mo separator="true">,</mo><mn>8</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[2,8,1]</annotation></semantics></math></span>
</span>，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mn>5</mn><mo separator="true">,</mo><mn>3</mn><mo separator="true">,</mo><mn>8</mn><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[5,3,8]</annotation></semantics></math></span>
</span>。</p></li></ol><h4 id=线上召回-2 class=heading>线上召回<a href=#%e7%ba%bf%e4%b8%8a%e5%8f%ac%e5%9b%9e-2 aria-labelledby=线上召回-2><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ol><li><p>给定用户特征，用神经网络做预估，用 <code>beam search</code> 召回一批路径。</p></li><li><p>利用索引，召回一批物品。</p><ul><li><p>查看索引
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>→</mo><mtext>List(item)</mtext></mrow><annotation encoding="application/x-tex">\text{path}  \rightarrow \text{List(item)}</annotation></semantics></math></span>
</span>。</p></li><li><p>每条路径对应多个物品 （在线上做召回之前，已经在线下把路径和物品匹配好了已经有了从路径到物品的索引）。</p></li></ul></li><li><p>做完前两步已经取回了很多物品，很可能会超出这条召回通道的配额，所以要做个筛选。对物品做排序，选出一个子集。</p><p>用一个小的排序模型给取回的物品打分，返回分数最高的一批物品。</p></li></ol><p>线上召回：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>user</mtext><mo>→</mo><mtext>path</mtext><mo>→</mo><mtext>item</mtext></mrow><annotation encoding="application/x-tex">\text{user} \rightarrow \text{path} \rightarrow \text{item}</annotation></semantics></math></span>
</span>。</p><h3 id=训练-1 class=heading>训练<a href=#%e8%ae%ad%e7%bb%83-1 aria-labelledby=训练-1><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><strong>学习神经网络参数</strong></p><p>神经网络
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(a, b, c|\mathbf{x})</annotation></semantics></math></span>
</span>预估用户对路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a,b,c]</annotation></semantics></math></span>
</span>的兴趣。</p><p><strong>学习物品表征 (
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>物品</mtext><mo>→</mo><mtext>路径</mtext></mrow><annotation encoding="application/x-tex">\text{物品} \rightarrow  \text{路径}</annotation></semantics></math></span>
</span>)</strong></p><ul><li><p>一个物品表征为多条路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\{[a,b,c]\}</annotation></semantics></math></span>
</span>，建立索引：</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>item</mtext><mo>→</mo><mtext>List(path)</mtext></mrow><annotation encoding="application/x-tex">\text{item}  \rightarrow \text{List(path)}</annotation></semantics></math></span></span></li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>→</mo><mtext>List(item)</mtext></mrow><annotation encoding="application/x-tex">\text{path} \rightarrow \text{List(item)}</annotation></semantics></math></span></span></li></ul></li><li><p>只用正样本
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mtext>user</mtext><mo separator="true">,</mo><mtext>item</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(\text{user}, \text{item})</annotation></semantics></math></span>
</span>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>click</mtext><mo stretchy="false">(</mo><mtext>user</mtext><mo separator="true">,</mo><mtext>item</mtext><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\text{click}(\text{user},\text{item})= 1</annotation></semantics></math></span></span></p></li></ul><h4 id=学习神经网络参数 class=heading>学习神经网络参数<a href=#%e5%ad%a6%e4%b9%a0%e7%a5%9e%e7%bb%8f%e7%bd%91%e7%bb%9c%e5%8f%82%e6%95%b0 aria-labelledby=学习神经网络参数><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>物品表征为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msub><mi>a</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>b</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>c</mi><mn>1</mn></msub><mo stretchy="false">]</mo><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><mo stretchy="false">[</mo><msub><mi>a</mi><mi>J</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>J</mi></msub><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a_1,b_1,c_1], \cdots, [a_{J},b_{j},c_{J}]</annotation></semantics></math></span>
</span>。</p><p>用户对路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a,b,c]</annotation></semantics></math></span>
</span>的兴趣：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>p</mi><mn>1</mn></msub><mo stretchy="false">(</mo><mi>a</mi><mi mathvariant="normal">∣</mi><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mn>2</mn></msub><mo stretchy="false">(</mo><mi>b</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo><mo>×</mo><msub><mi>p</mi><mn>3</mn></msub><mo stretchy="false">(</mo><mi>c</mi><mi mathvariant="normal">∣</mi><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">;</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
p(a, b, c|\mathbf{x}) = p_1(a|\mathbf{x})\times p_2(b|a;\mathbf{x})\times p_3(c|a, b;\mathbf{x})
</annotation></semantics></math></span></div><p>如果用户点击过物品，说明用户对
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径全部感兴趣。
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(a_j,b_j,c_j\mid\mathbf{x})</annotation></semantics></math></span>
</span>为神经网络给一条路径打的分数，表示用户对这条路径的兴趣有多大。</p><p>一个物品对应
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>个分数，应该让
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msubsup><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></msubsup><mi>p</mi><mo stretchy="false">(</mo><msub><mi>a</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\sum_{j=1}^Jp(a_j,b_j,c_j\mid\mathbf{x})</annotation></semantics></math></span>
</span>变大。</p><p><strong>损失函数</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo fence="true" stretchy="true" minsize="2.4em" maxsize="2.4em">(</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mi>p</mi><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><msub><mi>a</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>j</mi></msub><mo separator="true">,</mo><msub><mi>c</mi><mi>j</mi></msub><mo>∣</mo><mi mathvariant="bold">x</mi><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo><mo fence="true" stretchy="true" minsize="2.4em" maxsize="2.4em">)</mo></mrow><annotation encoding="application/x-tex">
\mathrm{loss}=-\log\biggl(\sum_{j=1}^Jp\bigl(a_j,b_j,c_j\mid\mathbf{x}\bigr)\biggr)
</annotation></semantics></math></span></div><p>这个神经网络的作用是判断用户对路径有多感兴趣。</p><p>如果用户点击过物品，我们就认为用户对物品的这条路径都感兴趣，应该让神经网络给这些路径打的分数更高。</p><h4 id=学习物品表征 class=heading>学习物品表征<a href=#%e5%ad%a6%e4%b9%a0%e7%89%a9%e5%93%81%e8%a1%a8%e5%be%81 aria-labelledby=学习物品表征><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><strong>用户 user 对路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path} =[a,b,c]</annotation></semantics></math></span>
</span>的兴趣</strong> 记作:</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><mi>p</mi><mo stretchy="false">(</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
p(\mathrm{path}\mid\mathrm{user})= p(a, b, c\mid\mathbf{x})
</annotation></semantics></math></span></div><p><strong>物品 item 与路径 path 的相关性</strong>：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><munder><munder><mrow><munder><mo>∑</mo><mtext>user</mtext></munder><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>用户对路径的兴趣</mtext></munder><mo>×</mo><munder><munder><mrow><mrow><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">k</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>是否点击 (0 或 1)</mtext></munder></mrow><annotation encoding="application/x-tex">
\mathrm{score}(\mathrm{item},\mathrm{path})=\underbrace{\sum_\text{user}p(\mathrm{path}\mid\mathrm{user})}_{\text{用户对路径的兴趣}} \times \underbrace{\mathrm{click}(\mathrm{user},\mathrm{item})}_{\text{是否点击 (0 或 1)}}
</annotation></semantics></math></span></div><p>分数越高，说明这对物品和路径有越强的关联。</p><p>根据
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>score</mtext><mo stretchy="false">(</mo><mtext>item</mtext><mo separator="true">,</mo><mtext>path</mtext><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\text{score}(\text{item},\text{path})</annotation></semantics></math></span>
</span>选出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Π</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>J</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Pi=\{\mathrm{path}_1,\cdots,\mathrm{path}_J\}</annotation></semantics></math></span>
</span>作为 item 的表征。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo separator="true">,</mo><mi mathvariant="normal">Π</mi><mo stretchy="false">)</mo><mo>=</mo><mo>−</mo><mi>log</mi><mo>⁡</mo><mo fence="true" stretchy="true" minsize="2.4em" maxsize="2.4em">(</mo><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi></mrow><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">(</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>j</mi></msub><mo fence="true" stretchy="true" minsize="1.2em" maxsize="1.2em">)</mo><mo fence="true" stretchy="true" minsize="2.4em" maxsize="2.4em">)</mo></mrow><annotation encoding="application/x-tex">
\mathrm{loss}(\mathrm{item},\Pi)=- \log\biggl(\sum_{j = 1}^J\mathrm{score}\bigl(\mathrm{item},\mathrm{path}_j\bigr)\biggr)
</annotation></semantics></math></span></div><ul><li><p><code>score</code> 是物品与某条路径之间的相关性。</p></li><li><p>对
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>路径的分数取连加，这些路径与物品越相关，<code>score</code> 的加和就越大</p></li><li><p>最小化损失函数相当于根据分数 <code>score</code> 对路径做排序，取排序结果的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>top </mtext><mi>J</mi></mrow><annotation encoding="application/x-tex">\text{top } J</annotation></semantics></math></span>
</span>。</p><p>即对于每个物品 item，选择分数 <code>score</code> 最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径，用这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径作为物品的表征。</p></li></ul><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">g</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>j</mi></msub><mo stretchy="false">)</mo><mo>=</mo><msup><mrow><mo fence="true">(</mo><msub><mtext>number of items on path</mtext><mi>j</mi></msub><mo fence="true">)</mo></mrow><mn>4</mn></msup></mrow><annotation encoding="application/x-tex">
\mathrm{reg}(\mathrm{path}_j)=\left(\text{number of items on path}_j\right)^4
</annotation></semantics></math></span></div><ul><li>希望每条路径上的物品数量比较平衡，不希望少数路径上有超级多的物品。</li><li>如果某条路径上已经有了很多个物品，这条路径就会受到惩罚，避免让它关联到更多的物品。</li></ul><p><strong>用贪心算法更新路径</strong></p><ul><li><p>假设已经把物品表征为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Π</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>J</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">\Pi=\{\mathrm{path}_1,\cdots,\mathrm{path}_J\}</annotation></semantics></math></span>
</span>。</p></li><li><p>每次固定其中的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">J-1</annotation></semantics></math></span>
</span>条路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">{</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>i</mi></msub><msub><mo stretchy="false">}</mo><mrow><mi>i</mi><mo mathvariant="normal">≠</mo><mi>l</mi></mrow></msub></mrow><annotation encoding="application/x-tex">\{\mathrm{path}_i\}_{i \ne l}</annotation></semantics></math></span>
</span>，并从未被选中的路径中，选出一条作为新的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>l</mi></msub></mrow><annotation encoding="application/x-tex">\mathrm{path}_l</annotation></semantics></math></span>
</span>关联到物品，我们用
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>l</mi></mrow><annotation encoding="application/x-tex">l</annotation></semantics></math></span>
</span>作为新选中的路径的序号，从候选的路径中选出能让 <strong>损失函数</strong> 和 <strong>正则项</strong> <strong>最小化</strong> 的一条路径作为新的路径：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>l</mi></msub><mo>←</mo><msub><mrow><mtext> </mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mrow><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>l</mi></msub></msub><mrow><mtext> </mtext><mi mathvariant="normal">l</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo separator="true">,</mo><mi mathvariant="normal">Π</mi><mo stretchy="false">)</mo><mo>+</mo><mi>α</mi><mo>⋅</mo><mrow><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">g</mi></mrow><mo stretchy="false">(</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>l</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
  \mathrm{path}_l\leftarrow\mathrm{~argmin}_{\mathrm{path}_l}\mathrm{~loss}(\mathrm{item},\Pi)+\alpha\cdot\mathrm{reg}(\mathrm{path}_l)
  </annotation></semantics></math></span></div></li><li><p>选中的路径有较高的分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\mathrm{score}(\mathrm{item},\mathrm{path})</annotation></semantics></math></span>
</span>，而且路径上的物品数量不会太多</p></li></ul><hr><p><strong>物品 item 与路径 path 的相关性</strong>：</p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250615224832535.png width=50% alt></center><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mrow><mi mathvariant="normal">s</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo stretchy="false">)</mo><mo>=</mo><munder><munder><mrow><munder><mo>∑</mo><mtext>user</mtext></munder><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>用户对路径的兴趣</mtext></munder><mo>×</mo><munder><munder><mrow><mrow><mi mathvariant="normal">c</mi><mi mathvariant="normal">l</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">k</mi></mrow><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">u</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">r</mi></mrow><mo separator="true">,</mo><mrow><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">m</mi></mrow><mo stretchy="false">)</mo></mrow><mo stretchy="true">⏟</mo></munder><mtext>是否点击 (0 或 1)</mtext></munder></mrow><annotation encoding="application/x-tex">
\mathrm{score}(\mathrm{item},\mathrm{path})=\underbrace{\sum_\text{user}p(\mathrm{path}\mid\mathrm{user})}_{\text{用户对路径的兴趣}} \times \underbrace{\mathrm{click}(\mathrm{user},\mathrm{item})}_{\text{是否点击 (0 或 1)}}
</annotation></semantics></math></span></div><ul><li><p>左边表示用户点击过物品，也就是说中间的用户全都对左边的物品感兴趣。</p></li><li><p>右边表示用户对路径的兴趣，分数分数介于零和一之间。这些分数由神经网络计算。</p></li><li><p>如果其中很多用户也对路径感兴趣，就判断物品跟路径有很强的关联，可以把路径作为物品的表征。</p></li><li><p>图中用户是物品与路径之间的中介，把左右两边的分数相乘，然后取连加，就是物品与路径之间的相关性分数。</p></li><li><p>根据这些分数选出
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径作为物品的表征。</p></li></ul><h4 id=总结-12 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-12 aria-labelledby=总结-12><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>交替做更新神经网络和更新物品的表征的训练。</p><p><strong>更新神经网络</strong></p><ul><li><p>神经网络判断 <strong>用户对路径的兴趣</strong>，给定用户特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>, 神经网络给路径打分记作
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>
</span>。分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi></mrow><annotation encoding="application/x-tex">p</annotation></semantics></math></span>
</span>越高，说明用户对路径的兴趣越大：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">
  p(\mathrm{path}\mid\mathbf{x})
  </annotation></semantics></math></span></div></li><li><p>训练所需的数据：</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>物品</mtext><mo>→</mo><mtext>路径</mtext></mrow><annotation encoding="application/x-tex">\text{物品} \rightarrow \text{路径}</annotation></semantics></math></span>
</span>的索引。</p></li><li><p>用户点击过的物品。</p></li></ul></li><li><p>如果用户点击过物品，且物品对应路径 path，则更新神经网络参数使
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\mathrm{path}\mid\mathbf{x})</annotation></semantics></math></span>
</span>变大。</p></li><li><p>把物品作为中介，将用户和路径关联起来。</p></li></ul><p><strong>更新物品的表征</strong></p><ul><li><p>判断物品与路径的相关性，把用户作为物品和路径之间的中介：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mtext>物品 </mtext><munder><munder><mrow><mtext> </mtext><mo>⟵</mo><mtext> </mtext></mrow><mo stretchy="true">⏟</mo></munder><mtext>用户点击过物品</mtext></munder><mtext> 用户 </mtext><munder><munder><mrow><mtext> </mtext><mo>⟶</mo><mtext> </mtext></mrow><mo stretchy="true">⏟</mo></munder><mtext>神经网络的打分</mtext></munder><mtext>路径</mtext></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">
  \begin{aligned}
  \text{物品 }\underbrace{~\longleftarrow~}_{\text{用户点击过物品}}\text{ 用户 }\underbrace{~\longrightarrow~}_{\text{神经网络的打分}}\text{路径}
  \end{aligned}
  </annotation></semantics></math></span></div><ul><li><p>给定一个物品，找到点击过物品的所有用户。</p></li><li><p>用神经网络计算用户对路径的兴趣分数。</p></li><li><p>把分数加起来就是物品与路径的相关性。</p></li></ul></li><li><p>让每个物品关联
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径。</p><ul><li><p>物品和路径要有很高的相关性。</p></li><li><p>一条路径上不能有过多的物品。</p></li></ul></li></ul><h3 id=总结-13 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-13 aria-labelledby=总结-13><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=召回 class=heading>召回<a href=#%e5%8f%ac%e5%9b%9e aria-labelledby=召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>路径</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow \text{路径} \rightarrow \text{物品}</annotation></semantics></math></span></span></p><ul><li><p><strong>Deep Retrieval</strong> 召回的本质是用 <strong>路径</strong> 作为用户和物品之间的中介。</p></li><li><p><strong>双塔模型</strong> 召回的本质是用 <strong>向量表征</strong> 作为用户和物品之间的中介。</p></li></ul><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户</mtext><mo>→</mo><mtext>路径</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \rightarrow \text{路径}</annotation></semantics></math></span></span></p><ul><li><p>给定用户特征
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="bold">x</mi></mrow><annotation encoding="application/x-tex">\mathbf{x}</annotation></semantics></math></span>
</span>，用神经网络预估用户对路径
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>=</mo><mo stretchy="false">[</mo><mi>a</mi><mo separator="true">,</mo><mi>b</mi><mo separator="true">,</mo><mi>c</mi><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">\text{path}=[a,b,c]</annotation></semantics></math></span>
</span>的兴趣，分数记
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\mathrm{path}\mid\mathbf{x})</annotation></semantics></math></span>
</span>。</p></li><li><p>用 <code>beam search</code> 寻找分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\mathrm{path}\mid\mathbf{x})</annotation></semantics></math></span>
</span>最高的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi></mrow><annotation encoding="application/x-tex">s</annotation></semantics></math></span>
</span>(beam size)条 path。</p></li></ul><p><strong><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>路径</mtext><mo>→</mo><mtext>物品</mtext></mrow><annotation encoding="application/x-tex">\text{路径} \rightarrow \text{物品}</annotation></semantics></math></span></span></strong></p><ul><li><p>利用索引
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>path</mtext><mo>→</mo><mtext>List(item)</mtext></mrow><annotation encoding="application/x-tex">\text{path} \rightarrow \text{List(item)}</annotation></semantics></math></span>
</span>召回每条路径上的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个物品。</p></li><li><p>一共召回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>s</mi><mo>×</mo><mi>n</mi></mrow><annotation encoding="application/x-tex">s \times n</annotation></semantics></math></span>
</span>个物品，对物品做初步排序，返回分数最高的若干物品。</p></li></ul><h4 id=训练-2 class=heading>训练<a href=#%e8%ae%ad%e7%bb%83-2 aria-labelledby=训练-2><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>同时学习 <strong>用户 —— 路径</strong> 和 <strong>物品 —— 路径</strong> 的关系：</p><p><strong>【用户 —— 路径】</strong></p><ul><li><p>一个物品被表征为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条路径：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mtext>path</mtext><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mtext>path</mtext><mi>j</mi></msub></mrow><annotation encoding="application/x-tex">\text{path}_1, \cdots, \text{path}_j</annotation></semantics></math></span>
</span>。</p></li><li><p>如果用户点击过物品，则更新神经网络参数，使分数增大。</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><munderover><mo>∑</mo><mrow><mi>j</mi><mo>=</mo><mn>1</mn></mrow><mi>J</mi></munderover><mi>p</mi><mrow><mo fence="true">(</mo><msub><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mi>j</mi></msub><mo>∣</mo><mi mathvariant="bold">x</mi><mo fence="true">)</mo></mrow></mrow><annotation encoding="application/x-tex">
  \sum_{j = 1}^Jp\left(\mathrm{path}_j\mid\mathbf{x}\right)
  </annotation></semantics></math></span></div></li></ul><p><strong>【物品 —— 路径】</strong></p><ul><li><p>如果用户对路径的兴趣分数
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>p</mi><mo stretchy="false">(</mo><mrow><mi mathvariant="normal">p</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">h</mi></mrow><mo>∣</mo><mi mathvariant="bold">x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">p(\mathrm{path}\mid\mathbf{x})</annotation></semantics></math></span>
</span>较高；且用户点击过物品 item。则 item 与 path 具有相关性。</p></li><li><p>寻找与 item 最相关的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>J</mi></mrow><annotation encoding="application/x-tex">J</annotation></semantics></math></span>
</span>条 path，且避免一条路径上物品过多。</p></li></ul><hr><p><strong>【补充】</strong></p><ol><li><p>双塔使用单向量召回，导致召回结果集中在单个 topic 上。字节做 deep retrieval 的目的是多兴趣召回（multi-interest）。deep retrieval 召回多条路径，每条路径是一个兴趣点，所以属于 multi-interest。</p></li><li><p>据说抖音已经下掉了 deep retrieval，因为有了更好的模型。</p></li><li><p>抖音实际在用的 multi-interest retrieval，
<a href=https://arxiv.org/abs/2402.02842 class=markdown-link>Trinity: Syncretizing Multi-/Long-tail/Long-term Interests All in One</a></p></li></ol><h2 id=其它召回通道 class=heading>其它召回通道<a href=#%e5%85%b6%e5%ae%83%e5%8f%ac%e5%9b%9e%e9%80%9a%e9%81%93 aria-labelledby=其它召回通道><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><h3 id=地理位置召回 class=heading>地理位置召回<a href=#%e5%9c%b0%e7%90%86%e4%bd%8d%e7%bd%ae%e5%8f%ac%e5%9b%9e aria-labelledby=地理位置召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=geohash-召回 class=heading><code>GeoHash</code> 召回<a href=#geohash-%e5%8f%ac%e5%9b%9e aria-labelledby=geohash-召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>用户可能对附近发生的事感兴趣。</p><p><code>GeoHash</code>：对经纬度的编码，地图上一个长方形区域。</p><p><strong>索引</strong>：<strong>
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>GeoHash </mtext><mo>→</mo><mtext> 优质笔记列表</mtext></mrow><annotation encoding="application/x-tex">\text{GeoHash} \ \rightarrow \ \text{优质笔记列表}</annotation></semantics></math></span>
</span></strong>（按时间倒排）：</p><ul><li><p>做召回的时候，给定用户的 <code>GeoHash </code>会取回这个区域内比较新的一些优质笔记.</p></li><li><p>这条召回通道没有个性化，召回纯粹只看地理位置，每次召回本地的一批优质笔记。</p><p>因为没有个性化，所以使用优质笔记。即使没有个性化，用户也很有可能会喜欢看。</p><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:1rem" src=pics/image-20250615231226086.png width=50% alt></center></li></ul><p>每个 <code>GeoHash </code>都表示地图上一个长方形的区域，每个 <code>GeoHash </code>后面都有一个笔记列表，意思是定位在这个地理位置的优质笔记，列表包含
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>篇优质笔记，按时间倒排，排在最前面的是最新的笔记。</p><p>如果用户允许获取用户定位，那么就根据用户定位的 <code>GeoHash </code>取回该地点最新发布的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>篇笔记。</p><p>由排序模型决定这些笔记中哪些符合用户的兴趣。</p><h4 id=同城召回 class=heading>同城召回<a href=#%e5%90%8c%e5%9f%8e%e5%8f%ac%e5%9b%9e aria-labelledby=同城召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><ul><li><p>用户可能对同城发生的事感兴趣。</p></li><li><p>索引：<strong>
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>城市 </mtext><mo>→</mo><mtext> 优质笔记列表</mtext></mrow><annotation encoding="application/x-tex">\text{城市} \ \rightarrow  \ \text{优质笔记列表}</annotation></semantics></math></span>
</span></strong>（按时间倒排）。</p></li><li><p>这条召回通道没有个性化。</p></li></ul><h3 id=作者召回 class=heading>作者召回<a href=#%e4%bd%9c%e8%80%85%e5%8f%ac%e5%9b%9e aria-labelledby=作者召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><h4 id=关注作者召回 class=heading>关注作者召回<a href=#%e5%85%b3%e6%b3%a8%e4%bd%9c%e8%80%85%e5%8f%ac%e5%9b%9e aria-labelledby=关注作者召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>用户对关注的作者发布的笔记感兴趣。</p><p><strong>索引</strong>：</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户  </mtext><mo>→</mo><mtext> 关注的作者</mtext></mrow><annotation encoding="application/x-tex">\text{用户 } \ \rightarrow  \ \text{关注的作者}</annotation></semantics></math></span></span></p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>作者 </mtext><mo>→</mo><mtext> 发布的笔记</mtext></mrow><annotation encoding="application/x-tex">\text{作者} \ \rightarrow  \ \text{发布的笔记}</annotation></semantics></math></span>
</span>（按照时间顺序倒排）</p></li></ul><p><strong>召回</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户  </mtext><mo>→</mo><mtext> 关注的作者 </mtext><mo>→</mo><mtext> 最新的笔记</mtext></mrow><annotation encoding="application/x-tex">\text{用户 } \ \rightarrow  \ \text{关注的作者} \ \rightarrow  \ \text{最新的笔记}</annotation></semantics></math></span></span></p><h4 id=有交互的作者召回 class=heading>有交互的作者召回<a href=#%e6%9c%89%e4%ba%a4%e4%ba%92%e7%9a%84%e4%bd%9c%e8%80%85%e5%8f%ac%e5%9b%9e aria-labelledby=有交互的作者召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>如果用户对某笔记感兴趣（点赞、收藏、转发)，那么用户可能对该作者的其他笔记感兴趣。</p><p>作者列表需要定期更新，最简单的策略就是保留最近交互的作者，删除一段时间没有交互的作者。</p><p><strong>索引</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户 </mtext><mo>→</mo><mtext> 有交互的作者</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \ \rightarrow  \ \text{有交互的作者}</annotation></semantics></math></span></span></p><p><strong>召回</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户 </mtext><mo>→</mo><mtext> 有交互的作者 </mtext><mo>→</mo><mtext> 最新的笔记</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \ \rightarrow  \ \text{有交互的作者} \ \rightarrow  \ \text{最新的笔记}</annotation></semantics></math></span></span></p><h4 id=相似作者召回 class=heading>相似作者召回<a href=#%e7%9b%b8%e4%bc%bc%e4%bd%9c%e8%80%85%e5%8f%ac%e5%9b%9e aria-labelledby=相似作者召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h4><p>如果用户喜欢某作者，那么用户喜欢相似的作者。</p><p><strong>索引</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>作者 </mtext><mo>→</mo><mtext> 相似作者</mtext></mrow><annotation encoding="application/x-tex">\text{作者} \ \rightarrow  \ \text{相似作者}</annotation></semantics></math></span>
</span>(
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个作者）</p><p>作者相似性的计算类似于 <code>Itemcf</code>，如果两个作者的粉丝有很大的重合，那么就判定两个作者相似。</p><p><strong>召回</strong>：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>用户 </mtext><mo>→</mo><mtext> 感兴趣的作者(n) </mtext><mo>→</mo><mtext> 相似作者(nk) </mtext><mo>→</mo><mtext> 最新的笔记(nk)</mtext></mrow><annotation encoding="application/x-tex">\text{用户} \ \rightarrow  \ \text{感兴趣的作者(n)}  \ \rightarrow  \ \text{相似作者(nk)} \ \rightarrow  \ \text{最新的笔记(nk)}</annotation></semantics></math></span></span></p><h3 id=缓存召回 class=heading>缓存召回<a href=#%e7%bc%93%e5%ad%98%e5%8f%ac%e5%9b%9e aria-labelledby=缓存召回><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p>复用前
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>次 <strong>推荐精排</strong> 的结果。</p><p><strong>背景</strong>：精排输出几百篇笔记，送入重排，重排做多样性抽样，选出几十篇。精排结果一大半没有曝光，被浪费。</p><p>精排前 50，但是没有曝光的，缓存起来，作为一条召回通道。缓存大小固定，需要 <strong>退场机制</strong>。</p><ul><li><p>一旦笔记成功曝光，就从缓存退场。</p></li><li><p>如果超出缓存大小，就移除 <strong>最先进入缓存</strong> 的笔记。</p></li><li><p>笔记最多被召回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span>
</span>次，达到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn></mrow><annotation encoding="application/x-tex">10</annotation></semantics></math></span>
</span>次就退场。</p></li><li><p>每篇笔记最多保存
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>天，达到
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>天就退场。</p></li></ul><hr><p><strong>【细化规则】</strong></p><p>假如想要扶持曝光比较低的笔记，那么可以根据笔记的曝光次数来设置规则，让低曝光的笔记在缓存里存更长的时间。</p><h3 id=总结-14 class=heading>总结<a href=#%e6%80%bb%e7%bb%93-14 aria-labelledby=总结-14><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>大类，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>条召回通道，工业界实际使用但重要性比不上 <code>Itemcf</code> 、<code>Swing</code>、双塔等召回通道。</p><ul><li><p>地理位置召回（用户对自己附近的人和事感兴趣）</p><ul><li><code>GeoHash</code> 召回。</li><li>同城召回。</li></ul></li><li><p>作者召回通道。</p><ul><li>关注的作者。</li><li>有交互的作。</li><li>相似的作者。</li></ul></li><li><p>缓存召回：把精排中排名高但是没有成功曝光的笔记缓存起来再多尝试几次。</p></li></ul><h2 id=曝光过滤--bloom-filter class=heading>曝光过滤 & Bloom Filter<a href=#%e6%9b%9d%e5%85%89%e8%bf%87%e6%bb%a4--bloom-filter aria-labelledby=曝光过滤--bloom-filter><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h2><p>曝光过滤通常是在召回阶段做，具体的方法就是用 <code>Bloom Filter</code></p><h3 id=曝光过滤问题 class=heading>曝光过滤问题<a href=#%e6%9b%9d%e5%85%89%e8%bf%87%e6%bb%a4%e9%97%ae%e9%a2%98 aria-labelledby=曝光过滤问题><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p>如果用户看过某个物品，则不再把该物品曝光给该用户。</p><p>对于每个用户，记录已经曝光给他的物品。（小红书只召回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个月以内的笔记，因此只需要记录每个用户最近
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个月的曝光历史。）</p><p>对于每个召回的物品，判断它是否已经给该用户曝光过，排除掉曾经曝光过的物品。</p><p>一位用户看过
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>个物品，本次召回
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span>
</span>个物品，如果暴力对比，需要
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>O</mi><mo stretchy="false">(</mo><mi>n</mi><mi>r</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">O(nr)</annotation></semantics></math></span>
</span>的时间。</p><h3 id=bloom-filter class=heading><code>Bloom Filter</code><a href=#bloom-filter aria-labelledby=bloom-filter><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><p><a href=https://dl.acm.org/doi/10.1145/362686.362692 class=markdown-link>Space/time trade-offs in hash coding with allowable errors</a></p><p><code>Bloom filter</code> 判断一个物品 ID 是否在已曝光的物品集合中。</p><ul><li><p>如果判断为 no，那么该物品一定不在集合中。</p></li><li><p>如果判断为 yes，那么该物品很可能在集合中。（可能误伤，错误判断未曝光物品为已曝光，将其过滤掉。)</p></li></ul><hr><p><code>Bloom filter</code> 是一种数据结构，把物品集合表征为一个
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>维二进制向量。</p><ul><li><strong>每个用户有一个曝光物品的集合，表征为一个向量</strong>，这个向量是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>维的，每个元素是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1 </annotation></semantics></math></span>
</span>bit, 取值为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>或
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>。总共需要
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>bit 的存储。</li><li><strong>Bloom filter 有
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个哈希函数</strong>，每个哈希函数把物品 ID 映射成介于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi><mo>−</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">m-1</annotation></semantics></math></span>
</span>之间的整数。</li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>和
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>都是需要设置的参数。</li></ul><hr><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615233955177.png width=50% alt></center><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">k=1</annotation></semantics></math></span>
</span>，只用一个哈希函数。</p><ul><li><p>初始的时候向量全
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，一组用户已经曝光过的物品为 ：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>1</mn></msub><mo separator="true">,</mo><mo>⋯</mo><mtext> </mtext><mo separator="true">,</mo><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>6</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_1,\cdots,  \mathrm{ID}_6</annotation></semantics></math></span>
</span>。</p><ul><li><p>哈希函数把物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_1</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>3</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_3</annotation></semantics></math></span>
</span>映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>个位置，把物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_4</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_5</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>6</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_6</annotation></semantics></math></span>
</span>映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>个位置，把物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_2</annotation></semantics></math></span>
</span>映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span>
</span>个位置。</p></li><li><p>映射的时候将原本该位置的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>改成
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。已经是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>时则不需要修改。</p></li><li><p>因此可以把这
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>个物品表征为一个向量，这个向量由
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>,
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>组成</p></li></ul></li><li><p>用户发起推荐请求之后召回很多物品。</p><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>7</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_7</annotation></semantics></math></span>
</span>被哈希函数映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>个位置，这里的元素是零，<code>Bloom Filter</code> 判断这个物品之前没有曝光。如果 <code>Bloom Filter</code> 认为没有曝光，那么这个物品肯定没有曝光。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>5</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_5</annotation></semantics></math></span>
</span>被哈希函数映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>个位置，这里的元素是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，<code>Bloom Filter</code> 认为这个物品已经曝光，正确。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>8</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_8</annotation></semantics></math></span>
</span>被哈希函数映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span>
</span>个位置，这里的元素是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，<code>Bloom Filter</code> 认为这个物品已经曝光，但这其实是个误判。<code>Bloom Filter</code> 有一定概率把未曝光的物品误判为已曝光，导致未曝光的物品被过滤掉，造成误伤。</p></li></ul></li></ul><hr><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615234037828.png width=50% alt></center><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">k=3</annotation></semantics></math></span>
</span>，用三个哈希函数。</p><ul><li><p>初始的时候二进制向量的元素全都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，用三个不同的哈希函数把物品 id 映射到三个位置上。</p><ul><li><p>三个哈希函数把物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>1</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_1</annotation></semantics></math></span>
</span>射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>个位置上，把这三个位上的元素都置为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。</p></li><li><p>三个哈希函数把物品
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_2</annotation></semantics></math></span>
</span>射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个位置上，把这三个位上的元素都置为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。</p></li><li><p>如果某个位置的元素本身就是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，则不用被修改。</p></li></ul></li><li><p>用户发起推荐请求之后召回很多物品。</p><ul><li><p>三个哈希函数把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>8</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_8</annotation></semantics></math></span>
</span>映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn></mrow><annotation encoding="application/x-tex">2</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn></mrow><annotation encoding="application/x-tex">3</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>个位置上，但第三个位置是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn></mrow><annotation encoding="application/x-tex">0</annotation></semantics></math></span>
</span>，说明这个物品未曝光。如果 <code>Bloom Filter</code> 认为没有曝光，那么这个物品肯定没有曝光。</p></li><li><p>三个哈希函数把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>4</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_4</annotation></semantics></math></span>
</span>映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>4</mn></mrow><annotation encoding="application/x-tex">4</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span>
</span>个位置上，由于三个位置全都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，<code>Bloom Filter</code> 认为这个物品已经曝光，正确。</p></li><li><p>三个哈希函数把
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">D</mi></mrow><mn>9</mn></msub></mrow><annotation encoding="application/x-tex">\mathrm{ID}_9</annotation></semantics></math></span>
</span>映射到第
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>6</mn></mrow><annotation encoding="application/x-tex">6</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>9</mn></mrow><annotation encoding="application/x-tex">9</annotation></semantics></math></span>
</span>、
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>个位置上，由于三个位置全都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，<code>Bloom Filter</code> 认为这个物品已经曝光，误判。</p></li></ul></li></ul><hr><p><strong>Bloom Filter 误伤的概率</strong>：</p><ul><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>：曝光物品集合大小。</li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>：二进制向量维度。</li><li><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>：哈希函数数量。</li></ul><p><strong>Bloom Filter 误伤的概率</strong> 为：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>δ</mi><mo>≈</mo><msup><mrow><mo fence="true">(</mo><mn>1</mn><mo>−</mo><mi>exp</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mo>−</mo><mfrac><mrow><mi>k</mi><mi>n</mi></mrow><mi>m</mi></mfrac><mo fence="true">)</mo></mrow><mo fence="true">)</mo></mrow><mi>k</mi></msup></mrow><annotation encoding="application/x-tex">
\delta\approx\left(1-\exp\left(-\frac{kn}m\right)\right)^k
</annotation></semantics></math></span></div><ul><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>越大，向量中的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>越多，误伤概率越大。（未曝光物品的
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个位置恰好都是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>的概率大。)</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>越大，向量越长，越不容易发生哈希碰撞，出现误伤的概率就越小，但是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span>
</span>越大需要的存储就越多。</p></li><li><p><span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>太大、太小都不好，
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>有最优取值。</p></li><li><p>设定可容忍的误伤概率为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>δ</mi></mrow><annotation encoding="application/x-tex">\delta</annotation></semantics></math></span>
</span>，那么最优参数为：</p><div class=mathjax-display><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>k</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1.44</mn><mo>⋅</mo><mi>ln</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><mi>δ</mi></mfrac><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr><mtr><mtd class ="mtr-glue"></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>m</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>2</mn><mi>n</mi><mo>⋅</mo><mi>ln</mi><mo>⁡</mo><mrow><mo fence="true">(</mo><mfrac><mn>1</mn><mi>δ</mi></mfrac><mo fence="true">)</mo></mrow></mrow></mstyle></mtd><mtd class ="mtr-glue"></mtd><mtd class ="mml-eqn-num"></mtd></mtr></mtable><annotation encoding="application/x-tex">
  \begin{align}
  k &amp;= 1.44\cdot\ln\left(\frac1\delta\right)\\\\
  m &amp;= 2n\cdot\ln\left(\frac1\delta\right)
  \end{align}
  </annotation></semantics></math></span></div></li></ul><h3 id=曝光过滤的链路 class=heading>曝光过滤的链路<a href=#%e6%9b%9d%e5%85%89%e8%bf%87%e6%bb%a4%e7%9a%84%e9%93%be%e8%b7%af aria-labelledby=曝光过滤的链路><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><center><img style="border-radius:.3125em;box-shadow:0 .2rem .4rem rgba(34,36,38,.12);margin:.5rem" src=pics/image-20250615235837745.png width=50% alt></center><ol><li><p>推荐系统的链路：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>多路召回</mtext><mo>→</mo><mtext>粗排精排重排</mtext><mo>→</mo><mtext>选出一批物品曝光给用户</mtext></mrow><annotation encoding="application/x-tex">\text{多路召回} \rightarrow \text{粗排精排重排} \rightarrow  \text{选出一批物品曝光给用户}</annotation></semantics></math></span>
</span>。</p></li><li><p>曝光过滤的链路：
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>记录曝光的物品</mtext><mo>→</mo><mtext>更新 Bloom Filter</mtext><mo>→</mo><mtext>用于过滤召回的物品</mtext></mrow><annotation encoding="application/x-tex">\text{记录曝光的物品} \rightarrow \text{更新 Bloom Filter} \rightarrow  \text{用于过滤召回的物品}</annotation></semantics></math></span>
</span>。</p><ul><li><p>app 的前端有埋点（橙色），所有曝光的物品都会被记录下来。</p></li><li><p>录表的速度要足够快否则可能会出问题。</p><p>用户推荐页面两次刷新也就间隔几分钟，快的话也就是一二十秒，在下一刷之前就要把本次曝光的结果写到 <code>Bloom Filter</code> 上。否则下一刷很可能会出重复的物品。</p></li><li><p>用实时流处理，比如把曝光物品写入 Kafka 消息队列，用 Flink 做实时计算。</p><p>Flink 实时读取 Kafka 消息队列，计算曝光物品的哈希值，把结果写到 <code>Bloom Filter</code> 的二进制向量上。</p><p>用这样的实时数据链路，在曝光发生几秒之后，这位用户的 <code>Bloom Filter</code> 就会被修改，之后就能避免重复曝光。</p></li><li><p>但实时流这部分也是最容易出问题的。如果挂掉了或者延迟特别大，那么用户上一刷看过的物品又会重复出现。</p></li></ul></li><li><p>曝光过滤具体用在召回完成之后。召回服务器请求曝光过滤服务，曝光过滤服务把这位用户的二进制向量发送给召回服务器。</p><p>在召回服务器上用 <code>Bloom Filter</code> 计算召回的物品的哈希值，再跟二进制向量做对比，把已经曝光的物品给过滤掉，剩余的物品都是未曝光的，发送给排序服务器。</p></li></ol><h3 id=bloom-filter-的缺点 class=heading><code>Bloom Filter</code> 的缺点<a href=#bloom-filter-%e7%9a%84%e7%bc%ba%e7%82%b9 aria-labelledby=bloom-filter-的缺点><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h3><ul><li><p><code>Bloom Filter</code> 把物品的集合表示成一个二进制向量。</p></li><li><p>每往集合中添加一个物品，只需要把向量
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span>
</span>个位置的元素置为
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>。（如果原本就是
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>，则不变。)</p></li><li><p><strong><code>Bloom filter</code> 只支持添加物品，不支持删除物品</strong>。从集合中移除物品，无法消除它对向量的影响。</p></li><li><p>每天都需要从物品集合中移除年龄大于
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span>
</span>个月的物品（超龄物品不可能被召回，没必要把它们记录在
<code>Bloom filter</code>，降低
<span class=mathjax-inline><span class=katex><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span>
</span>可以降低误伤率。）</p></li></ul><h1 id=reference class=heading>Reference<a href=#reference aria-labelledby=reference><svg class="svg-inline--fa fas fa-link anchor" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 640 512"><use href="#fas-link"/></svg></a></h1><p><a href=https://github.com/wangshusen/RecommenderSystem/ class=markdown-link>https://github.com/wangshusen/RecommenderSystem/</a></p></div><div class="row row-cols-2 mt-5 mb-3"><div class=col><a class=next href=/blogs/recommendersystem/rank/><svg class="svg-inline--fa fas fa-arrow-left" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 448 512"><use href="#fas-arrow-left"/></svg>&nbsp;RecommenderSystem-3-排序</a></div><div class="col text-end"><a class=previous href=/blogs/recommendersystem/basics/>RecommenderSystem-1-概要&nbsp;<svg class="svg-inline--fa fas fa-arrow-right" fill="currentcolor" aria-hidden="true" role="img" viewBox="0 0 448 512"><use href="#fas-arrow-right"/></svg></a></div></div><a href=# id=back-to-top class=back-to-top><span>▲</span>
</a><a href=# id=scroll-to-bottom class=back-to-top><span>▼</span>
</a><script>document.addEventListener("DOMContentLoaded",function(){var e=document.getElementById("back-to-top"),t=document.getElementById("scroll-to-bottom");e.addEventListener("click",function(e){e.preventDefault(),window.scrollTo({top:0,behavior:"smooth"})}),t.addEventListener("click",function(e){e.preventDefault(),window.scrollTo({top:document.body.scrollHeight,behavior:"smooth"})})})</script></div><div class="col col-md-3 col-lg-2 d-none d-md-block pt-5"><div class="toc toc-sidebar mb-5 my-md-0 mb-lg-5 p-3 text-body-secondary sticky-top"><strong class="d-block h6 my-2 pt-4">On this page:</strong><nav class=toc><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#基于物品的协同过滤itemcf>基于物品的协同过滤（ItemCF） </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#物品相似度>物品相似度 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#itemcf-召回的完整流程>ItemCF 召回的完整流程 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-2>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#swing-召回通道>Swing 召回通道 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#基于用户的协同过滤usercf>基于用户的协同过滤（UserCF） </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#用户的相似度>用户的相似度 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#usercf-召回的完整流程>UserCF 召回的完整流程 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-4>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#离散特征处理>离散特征处理 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#one-hot-编码>One-Hot 编码 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#embedding嵌入>Embedding(嵌入) </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#embedding-与-one-hot-编码-的关系>Embedding 与 One-Hot 编码 的关系 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-5>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#矩阵补充>矩阵补充 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#模型结构>模型结构 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#模型训练>模型训练 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#矩阵补充的缺点>矩阵补充的缺点 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#线上服务>线上服务 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-6>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#近似最近邻查找-approximate-nearest-neighbor-search>近似最近邻查找 （Approximate Nearest Neighbor Search） </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-7>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#双塔模型>双塔模型 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#模型和训练>模型和训练 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#正负样本>正负样本 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#线上召回和更新>线上召回和更新 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#双塔模型自监督学习>双塔模型+自监督学习 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#deep-retrieval>Deep Retrieval </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#索引-2>索引 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#预估模型>预估模型 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#线上召回-1>线上召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#训练-1>训练 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-13>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#其它召回通道>其它召回通道 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#地理位置召回>地理位置召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#作者召回>作者召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#缓存召回>缓存召回 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#总结-14>总结 </a><a class="toc-item toc-level-1" href=/blogs/recommendersystem/retrieval/#曝光过滤--bloom-filter>曝光过滤 & Bloom Filter </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#曝光过滤问题>曝光过滤问题 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#bloom-filter>Bloom Filter </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#曝光过滤的链路>曝光过滤的链路 </a><a class="toc-item toc-level-2" href=/blogs/recommendersystem/retrieval/#bloom-filter-的缺点>Bloom Filter 的缺点</a></nav></div></div></div></div><footer class="container-fluid footer text-center p-3"><div class="container-xxl text-center"><small>Copyright © 2025 EV's Blog All rights reserved.
|
Powered by
<a href=https://gethinode.com class="link-bg-footer markdown-link">Hinode</a>.</small></div><script src=https://eveydyw.github.io/js/image-zoom.min.3a7d43efcffd0a24c7162362607ea6a56ee3e3c19c0e260e0fbb41c0206fea83.js integrity="sha256-On1D78/9CiTHFiNiYH6mpW7j48GcDiYOD7tBwCBv6oM=" defer></script></footer></div><div id=toast-container class="toast-container position-fixed bottom-0 end-0 p-3"><div id=toast-copied-code-message class=toast role=alert aria-live=assertive aria-atomic=true><div class=toast-header><strong class=me-auto>EV's Blog</strong>
<button type=button class=btn-close data-bs-dismiss=toast aria-label=Close></button></div><div class=toast-body>Code copied to clipboard</div></div></div><svg xmlns:xlink="http://www.w3.org/1999/xlink" display="none"><symbol id="fas-ellipsis"><path d="M8 256a56 56 0 11112 0A56 56 0 118 256zm160 0a56 56 0 11112 0 56 56 0 11-112 0zm216-56a56 56 0 110 112 56 56 0 110-112z"/></symbol><symbol id="fas-sun"><path d="M361.5 1.2c5 2.1 8.6 6.6 9.6 11.9L391 121l107.9 19.8c5.3 1 9.8 4.6 11.9 9.6s1.5 10.7-1.6 15.2L446.9 256l62.3 90.3c3.1 4.5 3.7 10.2 1.6 15.2s-6.6 8.6-11.9 9.6L391 391 371.1 498.9c-1 5.3-4.6 9.8-9.6 11.9s-10.7 1.5-15.2-1.6L256 446.9l-90.3 62.3c-4.5 3.1-10.2 3.7-15.2 1.6s-8.6-6.6-9.6-11.9L121 391 13.1 371.1c-5.3-1-9.8-4.6-11.9-9.6s-1.5-10.7 1.6-15.2L65.1 256 2.8 165.7c-3.1-4.5-3.7-10.2-1.6-15.2s6.6-8.6 11.9-9.6L121 121 140.9 13.1c1-5.3 4.6-9.8 9.6-11.9s10.7-1.5 15.2 1.6L256 65.1 346.3 2.8c4.5-3.1 10.2-3.7 15.2-1.6zM160 256a96 96 0 11192 0 96 96 0 11-192 0zm224 0a128 128 0 10-256 0 128 128 0 10256 0z"/></symbol><symbol id="fas-moon"><path d="M223.5 32C1e2 32 0 132.3.0 256S1e2 480 223.5 480c60.6.0 115.5-24.2 155.8-63.4 5-4.9 6.3-12.5 3.1-18.7s-10.1-9.7-17-8.5c-9.8 1.7-19.8 2.6-30.1 2.6-96.9.0-175.5-78.8-175.5-176 0-65.8 36-123.1 89.3-153.3 6.1-3.5 9.2-10.5 7.7-17.3s-7.3-11.9-14.3-12.5c-6.3-.5-12.6-.8-19-.8z"/></symbol><symbol id="fas-angle-left"><path d="M41.4 233.4c-12.5 12.5-12.5 32.8.0 45.3l160 160c12.5 12.5 32.8 12.5 45.3.0s12.5-32.8.0-45.3L109.3 256 246.6 118.6c12.5-12.5 12.5-32.8.0-45.3s-32.8-12.5-45.3.0l-160 160z"/></symbol><symbol id="fas-sort"><path d="M137.4 41.4c12.5-12.5 32.8-12.5 45.3.0l128 128c9.2 9.2 11.9 22.9 6.9 34.9S301 224.1 288 224.1L32 224c-12.9.0-24.6-7.8-29.6-19.8s-2.2-25.7 6.9-34.9l128-128zm0 429.3-128-128c-9.2-9.2-11.9-22.9-6.9-34.9S19.1 288 32.1 288h256c12.9.0 24.6 7.8 29.6 19.8s2.2 25.7-6.9 34.9l-128 128c-12.5 12.5-32.8 12.5-45.3.0z"/></symbol><symbol id="fas-arrow-left"><path d="M9.4 233.4c-12.5 12.5-12.5 32.8.0 45.3l160 160c12.5 12.5 32.8 12.5 45.3.0s12.5-32.8.0-45.3L109.2 288H416c17.7.0 32-14.3 32-32s-14.3-32-32-32H109.3L214.6 118.6c12.5-12.5 12.5-32.8.0-45.3s-32.8-12.5-45.3.0l-160 160z"/></symbol><symbol id="fas-arrow-right"><path d="M438.6 278.6c12.5-12.5 12.5-32.8.0-45.3l-160-160c-12.5-12.5-32.8-12.5-45.3.0s-12.5 32.8.0 45.3L338.8 224H32c-17.7.0-32 14.3-32 32s14.3 32 32 32h306.7L233.4 393.4c-12.5 12.5-12.5 32.8.0 45.3s32.8 12.5 45.3.0l160-160z"/></symbol></svg>
<script src=/js/core.bundle-analytics.en.min.ceb6a67c169a28031391976dac91e1e2f460951862201b6249516a55d0fd6109.js data-category=analytics integrity="sha256-zramfBaaKAMTkZdtrJHh4vRglRhiIBtiSVFqVdD9YQk=" crossorigin=anonymous async></script><script src=/js/core.bundle.en.min.b2ac337ff8787d96cf35ffe28a30a119778a2736cb94d2f16606f72cda819f11.js integrity="sha256-sqwzf/h4fZbPNf/iijChGXeKJzbLlNLxZgb3LNqBnxE=" crossorigin=anonymous async></script></body></html>