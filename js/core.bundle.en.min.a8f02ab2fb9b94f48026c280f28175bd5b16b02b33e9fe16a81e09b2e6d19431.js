/*!
  * Bootstrap v5.3.3 (https://getbootstrap.com/)
  * Copyright 2011-2024 The Bootstrap Authors (https://github.com/twbs/bootstrap/graphs/contributors)
  * Licensed under MIT (https://github.com/twbs/bootstrap/blob/main/LICENSE)
  */const alert=document.getElementById("page-alert"),closeBtn=document.getElementById("page-alert-btn-close");if(alert!==null&&closeBtn!==null){const e=alert.getAttribute("data-page-alert-version")||"unknown",t=getSessionStorage(`page-alert-${e}`,null,"functional")!==null;t&&alert.classList.add("d-none"),closeBtn.addEventListener("click",()=>{setSessionStorage(`page-alert-${e}`,"seen","functional"),alert.classList.add("d-none")})}function reveal(){const e=document.querySelectorAll(".reveal");for(let t=0;t<e.length;t++){const n=window.innerHeight,s=e[t].getBoundingClientRect().top,o=150;s<n-o?(e[t].classList.add("active"),e[t].classList.remove("reveal")):e[t].classList.remove("active")}}window.addEventListener("scroll",reveal);const svgCopy='<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" width="16" height="16" fill="currentColor" class="bi bi-clipboard" viewBox="0 0 16 16"><path d="M4 1.5H3a2 2 0 0 0-2 2V14a2 2 0 0 0 2 2h10a2 2 0 0 0 2-2V3.5a2 2 0 0 0-2-2h-1v1h1a1 1 0 0 1 1 1V14a1 1 0 0 1-1 1H3a1 1 0 0 1-1-1V3.5a1 1 0 0 1 1-1h1v-1z"/><path d="M9.5 1a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-3a.5.5 0 0 1-.5-.5v-1a.5.5 0 0 1 .5-.5h3zm-3-1A1.5 1.5 0 0 0 5 1.5v1A1.5 1.5 0 0 0 6.5 4h3A1.5 1.5 0 0 0 11 2.5v-1A1.5 1.5 0 0 0 9.5 0h-3z"/></svg>',svgCheck='<svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true"><path fill-rule="evenodd" fill="rgb(63, 185, 80)" d="M13.78 4.22a.75.75 0 010 1.06l-7.25 7.25a.75.75 0 01-1.06 0L2.22 9.28a.75.75 0 011.06-1.06L6 10.94l6.72-6.72a.75.75 0 011.06 0z"></path></svg>',addCopyButtons=e=>{document.querySelectorAll("pre > code").forEach(t=>{const n=document.createElement("button");n.className="clipboard-button",n.setAttribute("data-toast-target","toast-copied-code-message"),n.setAttribute("aria-label","copy to clipboard"),n.type="button",n.innerHTML=svgCopy,n.addEventListener("click",()=>{const s=t.innerText.split(`
`).filter(Boolean).join(`
`);e.writeText(s).then(()=>{n.blur(),n.innerHTML=svgCheck,setTimeout(()=>n.innerHTML=svgCopy,2e3)},e=>n.innerHTML="Error")});const s=t.parentNode;s.parentNode.insertBefore(n,s)})};navigator&&navigator.clipboard&&addCopyButtons(navigator.clipboard),document.querySelectorAll("[data-clipboard]").forEach(e=>{const t=e.getAttribute("data-clipboard");e.addEventListener("click",()=>{navigator.clipboard.writeText(t)})});const url=new URL(window.location.href),menu=url.searchParams.get("menu"),child=url.searchParams.get("child"),menuItems=document.querySelectorAll('[data-nav="main"]');if(menu!==null){menuItems.forEach(e=>{e.classList.remove("active")});const e=document.querySelectorAll(`[data-nav-main="${menu}"]:not([data-nav-child])`);e.forEach(e=>{e.classList.add("active")});const t=document.querySelectorAll(`[data-nav-main="${menu}"][data-nav-child="${child}"]`);t.forEach(e=>{e.classList.add("active")})}(function(e,t){typeof exports=="object"&&typeof module!="undefined"?module.exports=t():typeof define=="function"&&define.amd?define(t):(e=typeof globalThis!="undefined"?globalThis:e||self,e.bootstrap=t())})(this,function(){"use strict";const C=new Map,pt={set(e,t,n){C.has(e)||C.set(e,new Map);const s=C.get(e);if(!s.has(t)&&s.size!==0){console.error(`Bootstrap doesn't allow more than one instance per element. Bound instance: ${Array.from(s.keys())[0]}.`);return}s.set(t,n)},get(e,t){return C.has(e)?C.get(e).get(t)||null:null},remove(e,t){if(!C.has(e))return;const n=C.get(e);n.delete(t),n.size===0&&C.delete(e)}},Jr=1e6,Xr=1e3,lt="transitionend",is=e=>(e&&window.CSS&&window.CSS.escape&&(e=e.replace(/#([^\s"#']+)/g,(e,t)=>`#${CSS.escape(t)}`)),e),Gr=e=>e==null?`${e}`:Object.prototype.toString.call(e).match(/\s([a-z]+)/i)[1].toLowerCase(),Yr=e=>{do e+=Math.floor(Math.random()*Jr);while(document.getElementById(e))return e},Pr=e=>{if(!e)return 0;let{transitionDuration:t,transitionDelay:n}=window.getComputedStyle(e);const s=Number.parseFloat(t),o=Number.parseFloat(n);return!s&&!o?0:(t=t.split(",")[0],n=n.split(",")[0],(Number.parseFloat(t)+Number.parseFloat(n))*Xr)},ns=e=>{e.dispatchEvent(new Event(lt))},g=e=>!!e&&typeof e=="object"&&(typeof e.jquery!="undefined"&&(e=e[0]),typeof e.nodeType!="undefined"),w=e=>g(e)?e.jquery?e[0]:e:typeof e=="string"&&e.length>0?document.querySelector(is(e)):null,R=e=>{if(!g(e)||e.getClientRects().length===0)return!1;const n=getComputedStyle(e).getPropertyValue("visibility")==="visible",t=e.closest("details:not([open])");if(!t)return n;if(t!==e){const n=e.closest("summary");if(n&&n.parentNode!==t)return!1;if(n===null)return!1}return n},y=e=>!e||e.nodeType!==Node.ELEMENT_NODE||!!e.classList.contains("disabled")||(typeof e.disabled!="undefined"?e.disabled:e.hasAttribute("disabled")&&e.getAttribute("disabled")!=="false"),es=e=>{if(!document.documentElement.attachShadow)return null;if(typeof e.getRootNode=="function"){const t=e.getRootNode();return t instanceof ShadowRoot?t:null}return e instanceof ShadowRoot?e:e.parentNode?es(e.parentNode):null},le=()=>{},oe=e=>{e.offsetHeight},Jn=()=>window.jQuery&&!document.body.hasAttribute("data-bs-no-jquery")?window.jQuery:null,Ue=[],Nr=e=>{document.readyState==="loading"?(Ue.length||document.addEventListener("DOMContentLoaded",()=>{for(const e of Ue)e()}),Ue.push(e)):e()},c=()=>document.documentElement.dir==="rtl",u=e=>{Nr(()=>{const t=Jn();if(t){const n=e.NAME,s=t.fn[n];t.fn[n]=e.jQueryInterface,t.fn[n].Constructor=e,t.fn[n].noConflict=()=>(t.fn[n]=s,e.jQueryInterface)}})},o=(e,t=[],n=e)=>typeof e=="function"?e(...t):n,Zn=(e,t,n=!0)=>{if(!n){o(e);return}const a=5,r=Pr(t)+a;let s=!1;const i=({target:n})=>{if(n!==t)return;s=!0,t.removeEventListener(lt,i),o(e)};t.addEventListener(lt,i),setTimeout(()=>{s||ns(t)},r)},$e=(e,t,n,s)=>{const i=e.length;let o=e.indexOf(t);return o===-1?!n&&s?e[i-1]:e[0]:(o+=n?1:-1,s&&(o=(o+i)%i),e[Math.max(0,Math.min(o,i-1))])},zr=/[^.]*(?=\..*)\.|.*/,Tr=/\..*/,Ar=/::\d+$/,De={};let qn=1;const Un={mouseenter:"mouseover",mouseleave:"mouseout"},Er=new Set(["click","dblclick","mouseup","mousedown","contextmenu","mousewheel","DOMMouseScroll","mouseover","mouseout","mousemove","selectstart","selectend","keydown","keypress","keyup","orientationchange","touchstart","touchmove","touchend","touchcancel","pointerdown","pointermove","pointerup","pointerleave","pointercancel","gesturestart","gesturechange","gestureend","focus","blur","change","reset","select","submit","focusin","focusout","load","unload","beforeunload","resize","move","DOMContentLoaded","readystatechange","error","abort","scroll"]);function Hn(e,t){return t&&`${t}::${qn++}`||e.uidEvent||qn++}function Fn(e){const t=Hn(e);return e.uidEvent=t,De[t]=De[t]||{},De[t]}function xr(t,n){return function s(o){return ht(o,{delegateTarget:t}),s.oneOff&&e.off(t,o.type,n),n.apply(t,[o])}}function Or(t,n,s){return function o(i){const a=t.querySelectorAll(n);for(let{target:r}=i;r&&r!==this;r=r.parentNode)for(const c of a){if(c!==r)continue;return ht(i,{delegateTarget:r}),o.oneOff&&e.off(t,i.type,n,s),s.apply(r,[i])}}}function Sn(e,t,n=null){return Object.values(e).find(e=>e.callable===t&&e.delegationSelector===n)}function An(e,t,n){const o=typeof t=="string",i=o?n:t||n;let s=xn(e);return Er.has(s)||(s=e),[o,i,s]}function Cn(e,t,n,s,o){if(typeof t!="string"||!e)return;let[r,i,c]=An(t,n,s);if(t in Un){const e=e=>function(t){if(!t.relatedTarget||t.relatedTarget!==t.delegateTarget&&!t.delegateTarget.contains(t.relatedTarget))return e.call(this,t)};i=e(i)}const d=Fn(e),u=d[c]||(d[c]={}),l=Sn(u,i,r?n:null);if(l){l.oneOff=l.oneOff&&o;return}const h=Hn(i,t.replace(zr,"")),a=r?Or(e,n,i):xr(e,i);a.delegationSelector=r?n:null,a.callable=i,a.oneOff=o,a.uidEvent=h,u[h]=a,e.addEventListener(c,a,r)}function dt(e,t,n,s,o){const i=Sn(t[n],s,o);if(!i)return;e.removeEventListener(n,i,Boolean(o)),delete t[n][i.uidEvent]}function wr(e,t,n,s){const o=t[n]||{};for(const[a,i]of Object.entries(o))a.includes(s)&&dt(e,t,n,i.callable,i.delegationSelector)}function xn(e){return e=e.replace(Tr,""),Un[e]||e}const e={on(e,t,n,s){Cn(e,t,n,s,!1)},one(e,t,n,s){Cn(e,t,n,s,!0)},off(e,t,n,s){if(typeof t!="string"||!e)return;const[c,a,i]=An(t,n,s),l=i!==t,o=Fn(e),r=o[i]||{},d=t.startsWith(".");if(typeof a!="undefined"){if(!Object.keys(r).length)return;dt(e,o,i,a,c?n:null);return}if(d)for(const n of Object.keys(o))wr(e,o,n,t.slice(1));for(const[s,n]of Object.entries(r)){const a=s.replace(Ar,"");(!l||t.includes(a))&&dt(e,o,i,n.callable,n.delegationSelector)}},trigger(e,t,n){if(typeof t!="string"||!e)return null;const i=Jn(),l=xn(t),d=t!==l;let s=null,a=!0,r=!0,c=!1;d&&i&&(s=i.Event(t,n),i(e).trigger(s),a=!s.isPropagationStopped(),r=!s.isImmediatePropagationStopped(),c=s.isDefaultPrevented());const o=ht(new Event(t,{bubbles:a,cancelable:!0}),n);return c&&o.preventDefault(),r&&e.dispatchEvent(o),o.defaultPrevented&&s&&s.preventDefault(),o}};function ht(e,t={}){for(const[n,s]of Object.entries(t))try{e[n]=s}catch{Object.defineProperty(e,n,{configurable:!0,get(){return s}})}return e}function On(e){if(e==="true")return!0;if(e==="false")return!1;if(e===Number(e).toString())return Number(e);if(e===""||e==="null")return null;if(typeof e!="string")return e;try{return JSON.parse(decodeURIComponent(e))}catch{return e}}function Le(e){return e.replace(/[A-Z]/g,e=>`-${e.toLowerCase()}`)}const v={setDataAttribute(e,t,n){e.setAttribute(`data-bs-${Le(t)}`,n)},removeDataAttribute(e,t){e.removeAttribute(`data-bs-${Le(t)}`)},getDataAttributes(e){if(!e)return{};const t={},n=Object.keys(e.dataset).filter(e=>e.startsWith("bs")&&!e.startsWith("bsConfig"));for(const o of n){let s=o.replace(/^bs/,"");s=s.charAt(0).toLowerCase()+s.slice(1,s.length),t[s]=On(e.dataset[o])}return t},getDataAttribute(e,t){return On(e.getAttribute(`data-bs-${Le(t)}`))}};class se{static get Default(){return{}}static get DefaultType(){return{}}static get NAME(){throw new Error('You have to implement the static method "NAME", for each component!')}_getConfig(e){return e=this._mergeConfigObj(e),e=this._configAfterMerge(e),this._typeCheckConfig(e),e}_configAfterMerge(e){return e}_mergeConfigObj(e,t){const n=g(t)?v.getDataAttribute(t,"config"):{};return{...this.constructor.Default,...typeof n=="object"?n:{},...g(t)?v.getDataAttributes(t):{},...typeof e=="object"?e:{}}}_typeCheckConfig(e,t=this.constructor.DefaultType){for(const[n,s]of Object.entries(t)){const o=e[n],i=g(o)?"element":Gr(o);if(!new RegExp(s).test(i))throw new TypeError(`${this.constructor.NAME.toUpperCase()}: Option "${n}" provided type "${i}" but expected type "${s}".`)}}}const _r="5.3.3";class h extends se{constructor(e,t){if(super(),e=w(e),!e)return;this._element=e,this._config=this._getConfig(t),pt.set(this._element,this.constructor.DATA_KEY,this)}dispose(){pt.remove(this._element,this.constructor.DATA_KEY),e.off(this._element,this.constructor.EVENT_KEY);for(const e of Object.getOwnPropertyNames(this))this[e]=null}_queueCallback(e,t,n=!0){Zn(e,t,n)}_getConfig(e){return e=this._mergeConfigObj(e,this._element),e=this._configAfterMerge(e),this._typeCheckConfig(e),e}static getInstance(e){return pt.get(w(e),this.DATA_KEY)}static getOrCreateInstance(e,t={}){return this.getInstance(e)||new this(e,typeof t=="object"?t:null)}static get VERSION(){return _r}static get DATA_KEY(){return`bs.${this.NAME}`}static get EVENT_KEY(){return`.${this.DATA_KEY}`}static eventName(e){return`${e}${this.EVENT_KEY}`}}const tt=e=>{let t=e.getAttribute("data-bs-target");if(!t||t==="#"){let n=e.getAttribute("href");if(!n||!n.includes("#")&&!n.startsWith("."))return null;n.includes("#")&&!n.startsWith("#")&&(n=`#${n.split("#")[1]}`),t=n&&n!=="#"?n.trim():null}return t?t.split(",").map(e=>is(e)).join(","):null},t={find(e,t=document.documentElement){return[].concat(...Element.prototype.querySelectorAll.call(t,e))},findOne(e,t=document.documentElement){return Element.prototype.querySelector.call(t,e)},children(e,t){return[].concat(...e.children).filter(e=>e.matches(t))},parents(e,t){const s=[];let n=e.parentNode.closest(t);for(;n;)s.push(n),n=n.parentNode.closest(t);return s},prev(e,t){let n=e.previousElementSibling;for(;n;){if(n.matches(t))return[n];n=n.previousElementSibling}return[]},next(e,t){let n=e.nextElementSibling;for(;n;){if(n.matches(t))return[n];n=n.nextElementSibling}return[]},focusableChildren(e){const t=["a","button","input","textarea","select","details","[tabindex]",'[contenteditable="true"]'].map(e=>`${e}:not([tabindex^="-"])`).join(",");return this.find(t,e).filter(e=>!y(e)&&R(e))},getSelectorFromElement(e){const n=tt(e);return n?t.findOne(n)?n:null:null},getElementFromSelector(e){const n=tt(e);return n?t.findOne(n):null},getMultipleElementsFromSelector(e){const n=tt(e);return n?t.find(n):[]}},_e=(n,s="hide")=>{const i=`click.dismiss${n.EVENT_KEY}`,o=n.NAME;e.on(document,i,`[data-bs-dismiss="${o}"]`,function(e){if(["A","AREA"].includes(this.tagName)&&e.preventDefault(),y(this))return;const i=t.getElementFromSelector(this)||this.closest(`.${o}`),a=n.getOrCreateInstance(i);a[s]()})},yr="alert",jr="bs.alert",jn=`.${jr}`,vr=`close${jn}`,cr=`closed${jn}`,ir="fade",Qa="show";class de extends h{static get NAME(){return yr}close(){const t=e.trigger(this._element,vr);if(t.defaultPrevented)return;this._element.classList.remove(Qa);const n=this._element.classList.contains(ir);this._queueCallback(()=>this._destroyElement(),this._element,n)}_destroyElement(){this._element.remove(),e.trigger(this._element,cr),this.dispose()}static jQueryInterface(e){return this.each(function(){const t=de.getOrCreateInstance(this);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e](this)})}}_e(de,"close"),u(de);const Ga="button",qa="bs.button",Wa=`.${qa}`,Ba=".data-api",Pa="active",fn='[data-bs-toggle="button"]',Ta=`click${Wa}${Ba}`;class fe extends h{static get NAME(){return Ga}toggle(){this._element.setAttribute("aria-pressed",this._element.classList.toggle(Pa))}static jQueryInterface(e){return this.each(function(){const t=fe.getOrCreateInstance(this);e==="toggle"&&t[e]()})}}e.on(document,Ta,fn,e=>{e.preventDefault();const t=e.target.closest(fn),n=fe.getOrCreateInstance(t);n.toggle()}),u(fe);const ga="swipe",P=".bs.swipe",pa=`touchstart${P}`,fa=`touchmove${P}`,ma=`touchend${P}`,ua=`pointerdown${P}`,la=`pointerup${P}`,Qi="touch",Gi="pen",Vi="pointer-event",Bi=40,Ri={endCallback:null,leftCallback:null,rightCallback:null},Ni={endCallback:"(function|null)",leftCallback:"(function|null)",rightCallback:"(function|null)"};class Re extends se{constructor(e,t){if(super(),this._element=e,!e||!Re.isSupported())return;this._config=this._getConfig(t),this._deltaX=0,this._supportPointerEvents=Boolean(window.PointerEvent),this._initEvents()}static get Default(){return Ri}static get DefaultType(){return Ni}static get NAME(){return ga}dispose(){e.off(this._element,P)}_start(e){if(!this._supportPointerEvents){this._deltaX=e.touches[0].clientX;return}this._eventIsPointerPenTouch(e)&&(this._deltaX=e.clientX)}_end(e){this._eventIsPointerPenTouch(e)&&(this._deltaX=e.clientX-this._deltaX),this._handleSwipe(),o(this._config.endCallback)}_move(e){this._deltaX=e.touches&&e.touches.length>1?0:e.touches[0].clientX-this._deltaX}_handleSwipe(){const e=Math.abs(this._deltaX);if(e<=Bi)return;const t=e/this._deltaX;if(this._deltaX=0,!t)return;o(t>0?this._config.rightCallback:this._config.leftCallback)}_initEvents(){this._supportPointerEvents?(e.on(this._element,ua,e=>this._start(e)),e.on(this._element,la,e=>this._end(e)),this._element.classList.add(Vi)):(e.on(this._element,pa,e=>this._start(e)),e.on(this._element,fa,e=>this._move(e)),e.on(this._element,ma,e=>this._end(e)))}_eventIsPointerPenTouch(e){return this._supportPointerEvents&&(e.pointerType===Gi||e.pointerType===Qi)}static isSupported(){return"ontouchstart"in document.documentElement||navigator.maxTouchPoints>0}}const Di="carousel",zi="bs.carousel",_=`.${zi}`,Kt=".data-api",Mi="ArrowLeft",Si="ArrowRight",Ei=500,ie="next",U="prev",K="left",ke="right",ji=`slide${_}`,Be=`slid${_}`,bi=`keydown${_}`,gi=`mouseenter${_}`,li=`mouseleave${_}`,ci=`dragstart${_}`,si=`load${_}${Kt}`,ei=`click${_}${Kt}`,Pt="carousel",Ce="active",Jo="slide",Zo="carousel-item-end",Qo="carousel-item-start",Xo="carousel-item-next",Go="carousel-item-prev",zt=".active",gt=".carousel-item",Ko=zt+gt,Bo=".carousel-item img",Po=".carousel-indicators",No="[data-bs-slide], [data-bs-slide-to]",Do='[data-bs-ride="carousel"]',To={[Mi]:ke,[Si]:K},Fo={interval:5e3,keyboard:!0,pause:"hover",ride:!1,touch:!0,wrap:!0},vo={interval:"(number|boolean)",keyboard:"boolean",pause:"(string|boolean)",ride:"(boolean|string)",touch:"boolean",wrap:"boolean"};class ee extends h{constructor(e,n){super(e,n),this._interval=null,this._activeElement=null,this._isSliding=!1,this.touchTimeout=null,this._swipeHelper=null,this._indicatorsElement=t.findOne(Po,this._element),this._addEventListeners(),this._config.ride===Pt&&this.cycle()}static get Default(){return Fo}static get DefaultType(){return vo}static get NAME(){return Di}next(){this._slide(ie)}nextWhenVisible(){!document.hidden&&R(this._element)&&this.next()}prev(){this._slide(U)}pause(){this._isSliding&&ns(this._element),this._clearInterval()}cycle(){this._clearInterval(),this._updateInterval(),this._interval=setInterval(()=>this.nextWhenVisible(),this._config.interval)}_maybeEnableCycle(){if(!this._config.ride)return;if(this._isSliding){e.one(this._element,Be,()=>this.cycle());return}this.cycle()}to(t){const n=this._getItems();if(t>n.length-1||t<0)return;if(this._isSliding){e.one(this._element,Be,()=>this.to(t));return}const s=this._getItemIndex(this._getActive());if(s===t)return;const o=t>s?ie:U;this._slide(o,n[t])}dispose(){this._swipeHelper&&this._swipeHelper.dispose(),super.dispose()}_configAfterMerge(e){return e.defaultInterval=e.interval,e}_addEventListeners(){this._config.keyboard&&e.on(this._element,bi,e=>this._keydown(e)),this._config.pause==="hover"&&(e.on(this._element,gi,()=>this.pause()),e.on(this._element,li,()=>this._maybeEnableCycle())),this._config.touch&&Re.isSupported()&&this._addTouchEventListeners()}_addTouchEventListeners(){for(const n of t.find(Bo,this._element))e.on(n,ci,e=>e.preventDefault());const n=()=>{if(this._config.pause!=="hover")return;this.pause(),this.touchTimeout&&clearTimeout(this.touchTimeout),this.touchTimeout=setTimeout(()=>this._maybeEnableCycle(),Ei+this._config.interval)},s={leftCallback:()=>this._slide(this._directionToOrder(K)),rightCallback:()=>this._slide(this._directionToOrder(ke)),endCallback:n};this._swipeHelper=new Re(this._element,s)}_keydown(e){if(/input|textarea/i.test(e.target.tagName))return;const t=To[e.key];t&&(e.preventDefault(),this._slide(this._directionToOrder(t)))}_getItemIndex(e){return this._getItems().indexOf(e)}_setActiveIndicatorElement(e){if(!this._indicatorsElement)return;const s=t.findOne(zt,this._indicatorsElement);s.classList.remove(Ce),s.removeAttribute("aria-current");const n=t.findOne(`[data-bs-slide-to="${e}"]`,this._indicatorsElement);n&&(n.classList.add(Ce),n.setAttribute("aria-current","true"))}_updateInterval(){const e=this._activeElement||this._getActive();if(!e)return;const t=Number.parseInt(e.getAttribute("data-bs-interval"),10);this._config.interval=t||this._config.defaultInterval}_slide(t,n=null){if(this._isSliding)return;const o=this._getActive(),a=t===ie,s=n||$e(this._getItems(),o,a,this._config.wrap);if(s===o)return;const c=this._getItemIndex(s),l=n=>e.trigger(this._element,n,{relatedTarget:s,direction:this._orderToDirection(t),from:this._getItemIndex(o),to:c}),d=l(ji);if(d.defaultPrevented)return;if(!o||!s)return;const u=Boolean(this._interval);this.pause(),this._isSliding=!0,this._setActiveIndicatorElement(c),this._activeElement=s;const i=a?Qo:Zo,r=a?Xo:Go;s.classList.add(r),oe(s),o.classList.add(i),s.classList.add(i);const h=()=>{s.classList.remove(i,r),s.classList.add(Ce),o.classList.remove(Ce,r,i),this._isSliding=!1,l(Be)};this._queueCallback(h,o,this._isAnimated()),u&&this.cycle()}_isAnimated(){return this._element.classList.contains(Jo)}_getActive(){return t.findOne(Ko,this._element)}_getItems(){return t.find(gt,this._element)}_clearInterval(){this._interval&&(clearInterval(this._interval),this._interval=null)}_directionToOrder(e){return c()?e===K?U:ie:e===K?ie:U}_orderToDirection(e){return c()?e===U?K:ke:e===U?ke:K}static jQueryInterface(e){return this.each(function(){const t=ee.getOrCreateInstance(this,e);if(typeof e=="number"){t.to(e);return}if(typeof e=="string"){if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e]()}})}}e.on(document,ei,No,function(e){const s=t.getElementFromSelector(this);if(!s||!s.classList.contains(Pt))return;e.preventDefault();const n=ee.getOrCreateInstance(s),o=this.getAttribute("data-bs-slide-to");if(o){n.to(o),n._maybeEnableCycle();return}if(v.getDataAttribute(this,"slide")==="next"){n.next(),n._maybeEnableCycle();return}n.prev(),n._maybeEnableCycle()}),e.on(window,si,()=>{const e=t.find(Do);for(const t of e)ee.getOrCreateInstance(t)}),u(ee);const rs="collapse",po="bs.collapse",J=`.${po}`,co=".data-api",ao=`show${J}`,io=`shown${J}`,Js=`hide${J}`,Qs=`hidden${J}`,Gs=`click${J}${co}`,ct="show",L="collapse",pe="collapsing",Ys="collapsed",Ks=`:scope .${L} .${L}`,Us="collapse-horizontal",Ws="width",$s="height",Vs=".collapse.show, .collapse.collapsing",nt='[data-bs-toggle="collapse"]',Bs={parent:null,toggle:!0},Is={parent:"(null|element)",toggle:"boolean"};class te extends h{constructor(e,n){super(e,n),this._isTransitioning=!1,this._triggerArray=[];const s=t.find(nt);for(const e of s){const n=t.getSelectorFromElement(e),o=t.find(n).filter(e=>e===this._element);n!==null&&o.length&&this._triggerArray.push(e)}this._initializeChildren(),this._config.parent||this._addAriaAndCollapsedClass(this._triggerArray,this._isShown()),this._config.toggle&&this.toggle()}static get Default(){return Bs}static get DefaultType(){return Is}static get NAME(){return rs}toggle(){this._isShown()?this.hide():this.show()}show(){if(this._isTransitioning||this._isShown())return;let n=[];if(this._config.parent&&(n=this._getFirstLevelChildren(Vs).filter(e=>e!==this._element).map(e=>te.getOrCreateInstance(e,{toggle:!1}))),n.length&&n[0]._isTransitioning)return;const s=e.trigger(this._element,ao);if(s.defaultPrevented)return;for(const e of n)e.hide();const t=this._getDimension();this._element.classList.remove(L),this._element.classList.add(pe),this._element.style[t]=0,this._addAriaAndCollapsedClass(this._triggerArray,!0),this._isTransitioning=!0;const o=()=>{this._isTransitioning=!1,this._element.classList.remove(pe),this._element.classList.add(L,ct),this._element.style[t]="",e.trigger(this._element,io)},i=t[0].toUpperCase()+t.slice(1),a=`scroll${i}`;this._queueCallback(o,this._element,!0),this._element.style[t]=`${this._element[a]}px`}hide(){if(this._isTransitioning||!this._isShown())return;const s=e.trigger(this._element,Js);if(s.defaultPrevented)return;const n=this._getDimension();this._element.style[n]=`${this._element.getBoundingClientRect()[n]}px`,oe(this._element),this._element.classList.add(pe),this._element.classList.remove(L,ct);for(const e of this._triggerArray){const n=t.getElementFromSelector(e);n&&!this._isShown(n)&&this._addAriaAndCollapsedClass([e],!1)}this._isTransitioning=!0;const o=()=>{this._isTransitioning=!1,this._element.classList.remove(pe),this._element.classList.add(L),e.trigger(this._element,Qs)};this._element.style[n]="",this._queueCallback(o,this._element,!0)}_isShown(e=this._element){return e.classList.contains(ct)}_configAfterMerge(e){return e.toggle=Boolean(e.toggle),e.parent=w(e.parent),e}_getDimension(){return this._element.classList.contains(Us)?Ws:$s}_initializeChildren(){if(!this._config.parent)return;const e=this._getFirstLevelChildren(nt);for(const n of e){const s=t.getElementFromSelector(n);s&&this._addAriaAndCollapsedClass([n],this._isShown(s))}}_getFirstLevelChildren(e){const n=t.find(Ks,this._config.parent);return t.find(e,this._config.parent).filter(e=>!n.includes(e))}_addAriaAndCollapsedClass(e,t){if(!e.length)return;for(const n of e)n.classList.toggle(Ys,!t),n.setAttribute("aria-expanded",t)}static jQueryInterface(e){const t={};return typeof e=="string"&&/show|hide/.test(e)&&(t.toggle=!1),this.each(function(){const n=te.getOrCreateInstance(this,t);if(typeof e=="string"){if(typeof n[e]=="undefined")throw new TypeError(`No method named "${e}"`);n[e]()}})}}e.on(document,Gs,nt,function(e){(e.target.tagName==="A"||e.delegateTarget&&e.delegateTarget.tagName==="A")&&e.preventDefault();for(const e of t.getMultipleElementsFromSelector(this))te.getOrCreateInstance(e,{toggle:!1}).toggle()}),u(te);var k,A,Q,Nn,In,ae,Yn,Xn,ot,Tt,Ft,St,At,je,s="top",a="bottom",i="right",n="left",Ee="auto",Y=[s,a,i,n],T="start",q="end",Vt="clippingParents",Ve="viewport",I="popper",Ut="reference",Te=Y.reduce(function(e,t){return e.concat([t+"-"+T,t+"-"+q])},[]),Xe=[].concat(Y,[Ee]).reduce(function(e,t){return e.concat([t,t+"-"+T,t+"-"+q])},[]),Yt="beforeRead",Gt="read",Xt="afterRead",Qt="beforeMain",Zt="main",Jt="afterMain",en="beforeWrite",tn="write",nn="afterWrite",sn=[Yt,Gt,Xt,Qt,Zt,Jt,en,tn,nn];function f(e){return e?(e.nodeName||"").toLowerCase():null}function r(e){if(e==null)return window;if(e.toString()!=="[object Window]"){var t=e.ownerDocument;return t?t.defaultView||window:window}return e}function D(e){var t=r(e).Element;return e instanceof t||e instanceof Element}function l(e){var t=r(e).HTMLElement;return e instanceof t||e instanceof HTMLElement}function Me(e){if(typeof ShadowRoot=="undefined")return!1;var t=r(e).ShadowRoot;return e instanceof t||e instanceof ShadowRoot}function Hs(e){var t=e.state;Object.keys(t.elements).forEach(function(e){var o=t.styles[e]||{},s=t.attributes[e]||{},n=t.elements[e];if(!l(n)||!f(n))return;Object.assign(n.style,o),Object.keys(s).forEach(function(e){var t=s[e];t===!1?n.removeAttribute(e):n.setAttribute(e,t===!0?"":t)})})}function Ps(e){var t=e.state,n={popper:{position:t.options.strategy,left:"0",top:"0",margin:"0"},arrow:{position:"absolute"},reference:{}};return Object.assign(t.elements.popper.style,n.popper),t.styles=n,t.elements.arrow&&Object.assign(t.elements.arrow.style,n.arrow),function(){Object.keys(t.elements).forEach(function(e){var s=t.elements[e],o=t.attributes[e]||{},i=Object.keys(t.styles.hasOwnProperty(e)?t.styles[e]:n[e]),a=i.reduce(function(e,t){return e[t]="",e},{});if(!l(s)||!f(s))return;Object.assign(s.style,a),Object.keys(o).forEach(function(e){s.removeAttribute(e)})})}}const st={name:"applyStyles",enabled:!0,phase:"write",fn:Hs,effect:Ps,requires:["computeStyles"]};function p(e){return e.split("-")[0]}k=Math.max,Q=Math.min,A=Math.round;function et(){var e=navigator.userAgentData;return e!=null&&e.brands&&Array.isArray(e.brands)?e.brands.map(function(e){return e.brand+"/"+e.version}).join(" "):navigator.userAgent}function bn(){return!/^((?!chrome|android).)*safari/i.test(et())}function X(e,t,n){t===void 0&&(t=!1),n===void 0&&(n=!1),s=e.getBoundingClientRect(),o=1,i=1,t&&l(e)&&(o=e.offsetWidth>0?A(s.width)/e.offsetWidth||1:1,i=e.offsetHeight>0?A(s.height)/e.offsetHeight||1:1);var s,o,i,f=D(e)?r(e):window,a=f.visualViewport,u=!bn()&&n,c=(s.left+(u&&a?a.offsetLeft:0))/o,d=(s.top+(u&&a?a.offsetTop:0))/i,h=s.width/o,m=s.height/i;return{width:h,height:m,top:d,right:c+h,bottom:d+m,left:c,x:c,y:d}}function ut(e){var t=X(e),n=e.offsetWidth,s=e.offsetHeight;return Math.abs(t.width-n)<=1&&(n=t.width),Math.abs(t.height-s)<=1&&(s=t.height),{x:e.offsetLeft,y:e.offsetTop,width:n,height:s}}function _n(e,t){var n,s=t.getRootNode&&t.getRootNode();if(e.contains(t))return!0;if(s&&Me(s)){n=t;do{if(n&&e.isSameNode(n))return!0;n=n.parentNode||n.host}while(n)}return!1}function j(e){return r(e).getComputedStyle(e)}function Rs(e){return["table","td","th"].indexOf(f(e))>=0}function E(e){return((D(e)?e.ownerDocument:e.document)||window.document).documentElement}function ge(e){return f(e)==="html"?e:e.assignedSlot||e.parentNode||(Me(e)?e.host:null)||E(e)}function En(e){return!l(e)||j(e).position==="fixed"?null:e.offsetParent}function As(e){var t,n,o,s=/firefox/i.test(et()),i=/Trident/i.test(et());if(i&&l(e)&&(o=j(e),o.position==="fixed"))return null;for(t=ge(e),Me(t)&&(t=t.host);l(t)&&["html","body"].indexOf(f(t))<0;){if(n=j(t),n.transform!=="none"||n.perspective!=="none"||n.contain==="paint"||["transform","perspective"].indexOf(n.willChange)!==-1||s&&n.willChange==="filter"||s&&n.filter&&n.filter!=="none")return t;t=t.parentNode}return null}function ce(e){for(var n=r(e),t=En(e);t&&Rs(t)&&j(t).position==="static";)t=En(t);return t&&(f(t)==="html"||f(t)==="body"&&j(t).position==="static")?n:t||As(e)||n}function Qe(e){return["top","bottom"].indexOf(e)>=0?"x":"y"}function re(e,t,n){return k(e,Q(t,n))}function Cs(e,t,n){var s=re(e,t,n);return s>n?n:s}function Tn(){return{top:0,right:0,bottom:0,left:0}}function zn(e){return Object.assign({},Tn(),e)}function Dn(e,t){return t.reduce(function(t,n){return t[n]=e,t},{})}Nn=function(t,n){return t=typeof t=="function"?t(Object.assign({},n.rects,{placement:n.placement})):t,zn(typeof t!="number"?t:Dn(t,Y))};function Os(e){var r,c,d,u,f,g,v,b,j,y,_,O,x,C,E,t=e.state,S=e.name,A=e.options,h=t.elements.arrow,m=t.modifiersData.popperOffsets,w=p(t.placement),o=Qe(w),k=[n,i].indexOf(w)>=0,l=k?"height":"width";if(!h||!m)return;g=Nn(A.padding,t),v=ut(h),b=o==="y"?s:n,j=o==="y"?a:i,y=t.rects.reference[l]+t.rects.reference[o]-m[o]-t.rects.popper[l],_=m[o]-t.rects.reference[o],c=ce(h),f=c?o==="y"?c.clientHeight||0:c.clientWidth||0:0,O=y/2-_/2,x=g[b],C=f-v[l]-g[j],u=f/2-v[l]/2+O,d=re(x,u,C),E=o,t.modifiersData[S]=(r={},r[E]=d,r.centerOffset=d-u,r)}function ys(e){var n=e.state,o=e.options,s=o.element,t=s===void 0?"[data-popper-arrow]":s;if(t==null)return;if(typeof t=="string"&&(t=n.elements.popper.querySelector(t),!t))return;if(!_n(n.elements.popper,t))return;n.elements.arrow=t}const Pn={name:"arrow",enabled:!0,phase:"main",fn:Os,effect:ys,requires:["popperOffsets"],requiresIfExists:["preventOverflow"]};function V(e){return e.split("-")[1]}In={top:"auto",right:"auto",bottom:"auto",left:"auto"};function bs(e,t){var s=e.x,o=e.y,n=t.devicePixelRatio||1;return{x:A(s*n)/n||0,y:A(o*n)/n||0}}function Vn(e){var c,u,h,p,g,b,y,T,z,f=e.popper,N=e.popperRect,d=e.placement,A=e.variation,m=e.offsets,x=e.position,v=e.gpuAcceleration,S=e.adaptive,_=e.roundOffsets,M=e.isFixed,L=m.x,t=L===void 0?0:L,D=m.y,o=D===void 0?0:D,C=typeof _=="function"?_({x:t,y:o}):{x:t,y:o},t=C.x,o=C.y,F=m.hasOwnProperty("x"),k=m.hasOwnProperty("y"),w=n,O=s,l=window;return S&&(c=ce(f),g="clientHeight",y="clientWidth",c===r(f)&&(c=E(f),j(c).position!=="static"&&x==="absolute"&&(g="scrollHeight",y="scrollWidth")),c=c,(d===s||(d===n||d===i)&&A===q)&&(O=a,T=M&&c===l&&l.visualViewport?l.visualViewport.height:c[g],o-=T-N.height,o*=v?1:-1),(d===n||(d===s||d===a)&&A===q)&&(w=i,z=M&&c===l&&l.visualViewport?l.visualViewport.width:c[y],t-=z-N.width,t*=v?1:-1)),p=Object.assign({position:x},S&&In),b=_===!0?bs({x:t,y:o},r(f)):{x:t,y:o},t=b.x,o=b.y,v?Object.assign({},p,(h={},h[O]=k?"0":"",h[w]=F?"0":"",h.transform=(l.devicePixelRatio||1)<=1?"translate("+t+"px, "+o+"px)":"translate3d("+t+"px, "+o+"px, 0)",h)):Object.assign({},p,(u={},u[O]=k?o+"px":"",u[w]=F?t+"px":"",u.transform="",u))}function vs(e){var t=e.state,n=e.options,s=n.gpuAcceleration,c=s===void 0||s,o=n.adaptive,l=o===void 0||o,i=n.roundOffsets,a=i===void 0||i,r={placement:p(t.placement),variation:V(t.placement),popper:t.elements.popper,popperRect:t.rects.popper,gpuAcceleration:c,isFixed:t.options.strategy==="fixed"};t.modifiersData.popperOffsets!=null&&(t.styles.popper=Object.assign({},t.styles.popper,Vn(Object.assign({},r,{offsets:t.modifiersData.popperOffsets,position:t.options.strategy,adaptive:l,roundOffsets:a})))),t.modifiersData.arrow!=null&&(t.styles.arrow=Object.assign({},t.styles.arrow,Vn(Object.assign({},r,{offsets:t.modifiersData.arrow,position:"absolute",adaptive:!1,roundOffsets:a})))),t.attributes.popper=Object.assign({},t.attributes.popper,{"data-popper-placement":t.placement})}const Fe={name:"computeStyles",enabled:!0,phase:"beforeWrite",fn:vs,data:{}};ae={passive:!0};function gs(e){var n=e.state,t=e.instance,s=e.options,o=s.scroll,i=o===void 0||o,a=s.resize,c=a===void 0||a,l=r(n.elements.popper),d=[].concat(n.scrollParents.reference,n.scrollParents.popper);return i&&d.forEach(function(e){e.addEventListener("scroll",t.update,ae)}),c&&l.addEventListener("resize",t.update,ae),function(){i&&d.forEach(function(e){e.removeEventListener("scroll",t.update,ae)}),c&&l.removeEventListener("resize",t.update,ae)}}const ze={name:"eventListeners",enabled:!0,phase:"write",fn:function(){},effect:gs,data:{}};Yn={left:"right",right:"left",bottom:"top",top:"bottom"};function Ae(e){return e.replace(/left|right|bottom|top/g,function(e){return Yn[e]})}Xn={start:"end",end:"start"};function Qn(e){return e.replace(/start|end/g,function(e){return Xn[e]})}function We(e){var t=r(e),n=t.pageXOffset,s=t.pageYOffset;return{scrollLeft:n,scrollTop:s}}function Ke(e){return X(E(e)).left+We(e).scrollLeft}function hs(e,t){var s,d=r(e),o=E(e),n=d.visualViewport,i=o.clientWidth,a=o.clientHeight,c=0,l=0;return n&&(i=n.width,a=n.height,s=bn(),(s||!s&&t==="fixed")&&(c=n.offsetLeft,l=n.offsetTop)),{width:i,height:a,x:c+Ke(e),y:l}}function us(e){var s,n=E(e),o=We(e),t=(s=e.ownerDocument)==null?void 0:s.body,i=k(n.scrollWidth,n.clientWidth,t?t.scrollWidth:0,t?t.clientWidth:0),r=k(n.scrollHeight,n.clientHeight,t?t.scrollHeight:0,t?t.clientHeight:0),a=-o.scrollLeft+Ke(e),c=-o.scrollTop;return j(t||n).direction==="rtl"&&(a+=k(n.clientWidth,t?t.clientWidth:0)-i),{width:i,height:r,x:a,y:c}}function Je(e){var t=j(e),n=t.overflow,s=t.overflowX,o=t.overflowY;return/auto|scroll|overlay|hidden/.test(n+o+s)}function ss(e){return["html","body","#document"].indexOf(f(e))>=0?e.ownerDocument.body:l(e)&&Je(e)?e:ss(ge(e))}function ne(e,t){t===void 0&&(t=[]);var s,n=ss(e),o=n===((s=e.ownerDocument)==null?void 0:s.body),i=r(n),a=o?[i].concat(i.visualViewport||[],Je(n)?n:[]):n,c=t.concat(a);return o?c:c.concat(ne(ge(a)))}function rt(e){return Object.assign({},e,{left:e.x,top:e.y,right:e.x+e.width,bottom:e.y+e.height})}function Fi(e,t){var n=X(e,!1,t==="fixed");return n.top=n.top+e.clientTop,n.left=n.left+e.clientLeft,n.bottom=n.top+e.clientHeight,n.right=n.left+e.clientWidth,n.width=e.clientWidth,n.height=e.clientHeight,n.x=n.left,n.y=n.top,n}function Mt(e,t,n){return t===Ve?rt(hs(e,n)):D(t)?Fi(t,n):rt(us(E(e)))}function ls(e){var n=ne(ge(e)),s=["absolute","fixed"].indexOf(j(e).position)>=0,t=s&&l(e)?ce(e):e;return D(t)?n.filter(function(e){return D(e)&&_n(e,t)&&f(e)!=="body"}):[]}function ds(e,t,n,s){var a=t==="clippingParents"?ls(e):[].concat(t),i=[].concat(a,[n]),r=i[0],o=i.reduce(function(t,n){var o=Mt(e,n,s);return t.top=k(o.top,t.top),t.right=Q(o.right,t.right),t.bottom=Q(o.bottom,t.bottom),t.left=k(o.left,t.left),t},Mt(e,r,s));return o.width=o.right-o.left,o.height=o.bottom-o.top,o.x=o.left,o.y=o.top,o}function ts(e){var o,r,l,t=e.reference,c=e.element,d=e.placement,u=d?p(d):null,f=d?V(d):null,h=t.x+t.width/2-c.width/2,m=t.y+t.height/2-c.height/2;switch(u){case s:o={x:h,y:t.y-c.height};break;case a:o={x:h,y:t.y+t.height};break;case i:o={x:t.x+t.width,y:m};break;case n:o={x:t.x-c.width,y:m};break;default:o={x:t.x,y:t.y}}if(r=u?Qe(u):null,r!=null)switch(l=r==="y"?"height":"width",f){case T:o[r]=o[r]-(t[l]/2-c[l]/2);break;case q:o[r]=o[r]+(t[l]/2-c[l]/2);break}return o}function N(e,t){t===void 0&&(t={});var _,n=t,v=n.placement,j=v===void 0?e.placement:v,f=n.strategy,T=f===void 0?e.strategy:f,p=n.boundary,C=p===void 0?Vt:p,O=n.rootBoundary,F=O===void 0?Ve:O,x=n.elementContext,c=x===void 0?I:x,m=n.altBoundary,M=m!==void 0&&m,b=n.padding,d=b===void 0?0:b,o=zn(typeof d!="number"?d:Dn(d,Y)),S=c===I?Ut:I,w=e.rects.popper,h=e.elements[M?S:c],r=ds(D(h)?h:h.contextElement||E(e.elements.popper),C,F,T),y=X(e.elements.reference),k=ts({reference:y,element:w,strategy:"absolute",placement:j}),A=rt(Object.assign({},w,k)),l=c===I?A:y,u={top:r.top-l.top+o.top,bottom:l.bottom-r.bottom+o.bottom,left:r.left-l.left+o.left,right:l.right-r.right+o.right},g=e.modifiersData.offset;return c===I&&g&&(_=g[j],Object.keys(u).forEach(function(e){var t=[i,a].indexOf(e)>=0?1:-1,n=[s,a].indexOf(e)>=0?"y":"x";u[e]+=_[n]*t})),u}function ms(e,t){t===void 0&&(t={});var s,n=t,c=n.placement,l=n.boundary,d=n.rootBoundary,u=n.padding,h=n.flipVariations,i=n.allowedAutoPlacements,m=i===void 0?Xe:i,a=V(c),r=a?h?Te:Te.filter(function(e){return V(e)===a}):Y,o=r.filter(function(e){return m.indexOf(e)>=0});return o.length===0&&(o=r),s=o.reduce(function(t,n){return t[n]=N(e,{placement:n,boundary:l,rootBoundary:d,padding:u})[p(n)],t},{}),Object.keys(s).sort(function(e,t){return s[e]-s[t]})}function fs(e){if(p(e)===Ee)return[];var t=Ae(e);return[Qn(e),t,Qn(t)]}function ps(e){var t=e.state,o=e.options,C=e.name;if(t.modifiersData[C]._skip)return;for(var r,c,l,u,h,g,v,y,_,x,E,k,z,M=o.mainAxis,I=M===void 0||M,D=o.altAxis,P=D===void 0||D,R=o.fallbackPlacements,L=o.padding,w=o.boundary,O=o.rootBoundary,B=o.altBoundary,F=o.flipVariations,j=F===void 0||F,$=o.allowedAutoPlacements,d=t.options.placement,K=p(d),H=K===d,q=R||(H||!j?[Ae(d)]:fs(d)),f=[d].concat(q).reduce(function(e,n){return e.concat(p(n)===Ee?ms(t,{placement:n,boundary:w,rootBoundary:O,padding:L,flipVariations:j,allowedAutoPlacements:$}):n)},[]),U=t.rects.reference,W=t.rects.popper,A=new Map,S=!0,m=f[0],b=0;b<f.length;b++){if(r=f[b],v=p(r),g=V(r)===T,y=[s,a].indexOf(v)>=0,_=y?"width":"height",h=N(t,{placement:r,boundary:w,rootBoundary:O,altBoundary:B,padding:L}),l=y?g?i:n:g?a:s,U[_]>W[_]&&(l=Ae(l)),z=Ae(l),c=[],I&&c.push(h[v]<=0),P&&c.push(h[l]<=0,h[z]<=0),c.every(function(e){return e})){m=r,S=!1;break}A.set(r,c)}if(S)for(k=j?3:1,E=function(t){var n=f.find(function(e){var n=A.get(e);if(n)return n.slice(0,t).every(function(e){return e})});if(n)return m=n,"break"},u=k;u>0;u--)if(x=E(u),x==="break")break;t.placement!==m&&(t.modifiersData[C]._skip=!0,t.placement=m,t.reset=!0)}const Kn={name:"flip",enabled:!0,phase:"main",fn:ps,requiresIfExists:["offset"],data:{_skip:!1}};function $n(e,t,n){return n===void 0&&(n={x:0,y:0}),{top:e.top-t.height-n.y,right:e.right-t.width+n.x,bottom:e.bottom-t.height+n.y,left:e.left-t.width-n.x}}function Bn(e){return[s,i,a,n].some(function(t){return e[t]>=0})}function js(e){var t=e.state,a=e.name,r=t.rects.reference,c=t.rects.popper,l=t.modifiersData.preventOverflow,d=N(t,{elementContext:"reference"}),u=N(t,{altBoundary:!0}),n=$n(d,r),s=$n(u,c,l),o=Bn(n),i=Bn(s);t.modifiersData[a]={referenceClippingOffsets:n,popperEscapeOffsets:s,isReferenceHidden:o,hasPopperEscaped:i},t.attributes.popper=Object.assign({},t.attributes.popper,{"data-popper-reference-hidden":o,"data-popper-escaped":i})}const Rn={name:"hide",enabled:!0,phase:"main",requiresIfExists:["preventOverflow"],fn:js};function _s(e,t,o){var c=p(e),d=[n,s].indexOf(c)>=0?-1:1,l=typeof o=="function"?o(Object.assign({},t,{placement:e})):o,a=l[0],r=l[1],a=a||0,r=(r||0)*d;return[n,i].indexOf(c)>=0?{x:r,y:a}:{x:a,y:r}}function ws(e){var t=e.state,i=e.options,a=e.name,n=i.offset,r=n===void 0?[0,0]:n,s=Xe.reduce(function(e,n){return e[n]=_s(n,t.rects,r),e},{}),o=s[t.placement],c=o.x,l=o.y;t.modifiersData.popperOffsets!=null&&(t.modifiersData.popperOffsets.x+=c,t.modifiersData.popperOffsets.y+=l),t.modifiersData[a]=s}const Ln={name:"offset",enabled:!0,phase:"main",requires:["popperOffsets"],fn:ws};function xs(e){var t=e.state,n=e.name;t.modifiersData[n]=ts({reference:t.rects.reference,element:t.rects.popper,strategy:"absolute",placement:t.placement})}const He={name:"popperOffsets",enabled:!0,phase:"read",fn:xs,data:{}};function Es(e){return e==="x"?"y":"x"}function ks(e){var fe,r,h,P,H,$,W,U,Y,Z,J,ue,v,E,K,q,te,ne,x,oe,B,ae,le,G,me,c,f,w,A,M,F,z,D,R,I,X,t=e.state,l=e.options,be=e.name,pe=l.mainAxis,ge=pe===void 0||pe,se=l.altAxis,we=se!==void 0&&se,_e=l.boundary,ye=l.rootBoundary,ve=l.altBoundary,je=l.padding,de=l.tether,d=de===void 0||de,ie=l.tetherOffset,S=ie===void 0?0:ie,O=N(t,{boundary:_e,rootBoundary:ye,padding:je,altBoundary:ve}),ee=p(t.placement),C=V(t.placement),he=!C,o=Qe(ee),j=Es(o),b=t.modifiersData.popperOffsets,u=t.rects.reference,g=t.rects.popper,_=typeof S=="function"?S(Object.assign({},t.rects,{placement:t.placement})):S,m=typeof _=="number"?{mainAxis:_,altAxis:_}:Object.assign({mainAxis:0,altAxis:0},_),y=t.modifiersData.offset?t.modifiersData.offset[t.placement]:null,L={x:0,y:0};if(!b)return;ge&&(P=o==="y"?s:n,H=o==="y"?a:i,r=o==="y"?"height":"width",h=b[o],$=h+O[P],W=h-O[H],U=d?-g[r]/2:0,J=C===T?u[r]:g[r],Z=C===T?-g[r]:-u[r],Y=t.elements.arrow,ue=d&&Y?ut(Y):{width:0,height:0},E=t.modifiersData["arrow#persistent"]?t.modifiersData["arrow#persistent"].padding:Tn(),q=E[P],K=E[H],v=re(0,u[r],ue[r]),te=he?u[r]/2-U-v-q-m.mainAxis:J-v-q-m.mainAxis,ne=he?-u[r]/2+U+v+K+m.mainAxis:Z+v+K+m.mainAxis,x=t.elements.arrow&&ce(t.elements.arrow),oe=x?o==="y"?x.clientTop||0:x.clientLeft||0:0,B=(fe=y?.[o])!=null?fe:0,ae=h+te-B-oe,le=h+ne-B,I=re(d?Q($,ae):$,h,d?k(W,le):W),b[o]=I,L[o]=I-h),we&&(G=o==="x"?s:n,me=o==="x"?a:i,c=b[j],f=j==="y"?"height":"width",R=c+O[G],D=c-O[me],w=[s,n].indexOf(ee)!==-1,z=(X=y?.[j])!=null?X:0,F=w?R:c-u[f]-g[f]-z+m.altAxis,M=w?c+u[f]+g[f]-z-m.altAxis:D,A=d&&w?Cs(F,c,M):re(d?F:R,c,d?M:D),b[j]=A,L[j]=A-c),t.modifiersData[be]=L}const kn={name:"preventOverflow",enabled:!0,phase:"main",fn:ks,requiresIfExists:["offset"]};function Ss(e){return{scrollLeft:e.scrollLeft,scrollTop:e.scrollTop}}function Ms(e){return e===r(e)||!l(e)?We(e):Ss(e)}function Fs(e){var t=e.getBoundingClientRect(),n=A(t.width)/e.offsetWidth||1,s=A(t.height)/e.offsetHeight||1;return n!==1||s!==1}function Ts(e,t,n){n===void 0&&(n=!1);var r=l(t),c=l(t)&&Fs(t),i=E(t),o=X(e,c,n),a={scrollLeft:0,scrollTop:0},s={x:0,y:0};return(r||!r&&!n)&&((f(t)!=="body"||Je(i))&&(a=Ms(t)),l(t)?(s=X(t,!0),s.x+=t.clientLeft,s.y+=t.clientTop):i&&(s.x=Ke(i))),{x:o.left+a.scrollLeft-s.x,y:o.top+a.scrollTop-s.y,width:o.width,height:o.height}}function zs(e){var n=new Map,t=new Set,s=[];e.forEach(function(e){n.set(e.name,e)});function o(e){t.add(e.name);var i=[].concat(e.requires||[],e.requiresIfExists||[]);i.forEach(function(e){if(!t.has(e)){var s=n.get(e);s&&o(s)}}),s.push(e)}return e.forEach(function(e){t.has(e.name)||o(e)}),s}function Ds(e){var t=zs(e);return sn.reduce(function(e,n){return e.concat(t.filter(function(e){return e.phase===n}))},[])}function Ns(e){var t;return function(){return t||(t=new Promise(function(n){Promise.resolve().then(function(){t=void 0,n(e())})})),t}}function Ls(e){var t=e.reduce(function(e,t){var n=e[t.name];return e[t.name]=n?Object.assign({},n,t,{options:Object.assign({},n.options,t.options),data:Object.assign({},n.data,t.data)}):t,e},{});return Object.keys(t).map(function(e){return t[e]})}ot={placement:"bottom",modifiers:[],strategy:"absolute"};function un(){for(var t=arguments.length,n=new Array(t),e=0;e<t;e++)n[e]=arguments[e];return!n.some(function(e){return!e||typeof e.getBoundingClientRect!="function"})}function we(e){e===void 0&&(e={});var n=e,s=n.defaultModifiers,i=s===void 0?[]:s,o=n.defaultOptions,t=o===void 0?ot:o;return function(n,s,o){o===void 0&&(o=t);var a={placement:"bottom",orderedModifiers:[],options:Object.assign({},ot,t),modifiersData:{},elements:{reference:n,popper:s},attributes:{},styles:{}},c=[],l=!1,r={state:a,setOptions:function(o){var c,l=typeof o=="function"?o(a.options):o;return d(),a.options=Object.assign({},t,a.options,l),a.scrollParents={reference:D(n)?ne(n):n.contextElement?ne(n.contextElement):[],popper:ne(s)},c=Ds(Ls([].concat(i,a.options.modifiers))),a.orderedModifiers=c.filter(function(e){return e.enabled}),u(),r.update()},forceUpdate:function(){if(l)return;var o=a.elements,i=o.reference,n=o.popper;if(!un(i,n))return;a.rects={reference:Ts(i,ce(n),a.options.strategy==="fixed"),popper:ut(n)},a.reset=!1,a.placement=a.options.placement,a.orderedModifiers.forEach(function(e){return a.modifiersData[e.name]=Object.assign({},e.data)});for(t=0;t<a.orderedModifiers.length;t++){if(a.reset===!0){a.reset=!1,t=-1;continue}var t,s=a.orderedModifiers[t],c=s.fn,d=s.options,u=d===void 0?{}:d,h=s.name;typeof c=="function"&&(a=c({state:a,options:u,name:h,instance:r})||a)}},update:Ns(function(){return new Promise(function(e){r.forceUpdate(),e(a)})}),destroy:function(){d(),l=!0}};if(!un(n,s))return r;r.setOptions(o).then(function(e){!l&&o.onFirstUpdate&&o.onFirstUpdate(e)});function u(){a.orderedModifiers.forEach(function(e){var s,o,i=e.name,t=e.options,l=t===void 0?{}:t,n=e.effect;typeof n=="function"&&(s=n({state:a,name:i,instance:r,options:l}),o=function(){},c.push(s||o))})}function d(){c.forEach(function(e){return e()}),c=[]}return r}}Tt=we(),Ft=[ze,He,Fe,st],St=we({defaultModifiers:Ft}),At=[ze,He,Fe,st,Ln,Kn,kn,Pn,Rn],je=we({defaultModifiers:At});const Et=Object.freeze(Object.defineProperty({__proto__:null,afterMain:Jt,afterRead:Xt,afterWrite:nn,applyStyles:st,arrow:Pn,auto:Ee,basePlacements:Y,beforeMain:Qt,beforeRead:Yt,beforeWrite:en,bottom:a,clippingParents:Vt,computeStyles:Fe,createPopper:je,createPopperBase:Tt,createPopperLite:St,detectOverflow:N,end:q,eventListeners:ze,flip:Kn,hide:Rn,left:n,main:Zt,modifierPhases:sn,offset:Ln,placements:Xe,popper:I,popperGenerator:we,popperOffsets:He,preventOverflow:kn,read:Gt,reference:Ut,right:i,start:T,top:s,variationPlacements:Te,viewport:Ve,write:tn},Symbol.toStringTag,{value:"Module"})),Ct="dropdown",qs="bs.dropdown",F=`.${qs}`,it=".data-api",Xs="Escape",jt="Tab",Zs="ArrowUp",bt="ArrowDown",eo=2,to=`hide${F}`,no=`hidden${F}`,so=`show${F}`,oo=`shown${F}`,vt=`click${F}${it}`,yt=`keydown${F}${it}`,ro=`keyup${F}${it}`,G="show",lo="dropup",uo="dropend",ho="dropstart",mo="dropup-center",fo="dropdown-center",z='[data-bs-toggle="dropdown"]:not(.disabled):not(:disabled)',go=`${z}.${G}`,me=".dropdown-menu",bo=".navbar",jo=".navbar-nav",yo=".dropdown-menu .dropdown-item:not(.disabled):not(:disabled)",_o=c()?"top-end":"top-start",wo=c()?"top-start":"top-end",Oo=c()?"bottom-end":"bottom-start",xo=c()?"bottom-start":"bottom-end",Co=c()?"left-start":"right-start",Eo=c()?"right-start":"left-start",ko="top",Ao="bottom",So={autoClose:!0,boundary:"clippingParents",display:"dynamic",offset:[0,2],popperConfig:null,reference:"toggle"},Mo={autoClose:"(boolean|string)",boundary:"(string|element)",display:"string",offset:"(array|string|function)",popperConfig:"(null|object|function)",reference:"(string|element|object)"};class m extends h{constructor(e,n){super(e,n),this._popper=null,this._parent=this._element.parentNode,this._menu=t.next(this._element,me)[0]||t.prev(this._element,me)[0]||t.findOne(me,this._parent),this._inNavbar=this._detectNavbar()}static get Default(){return So}static get DefaultType(){return Mo}static get NAME(){return Ct}toggle(){return this._isShown()?this.hide():this.show()}show(){if(y(this._element)||this._isShown())return;const t={relatedTarget:this._element},n=e.trigger(this._element,so,t);if(n.defaultPrevented)return;if(this._createPopper(),"ontouchstart"in document.documentElement&&!this._parent.closest(jo))for(const t of[].concat(...document.body.children))e.on(t,"mouseover",le);this._element.focus(),this._element.setAttribute("aria-expanded",!0),this._menu.classList.add(G),this._element.classList.add(G),e.trigger(this._element,oo,t)}hide(){if(y(this._element)||!this._isShown())return;const e={relatedTarget:this._element};this._completeHide(e)}dispose(){this._popper&&this._popper.destroy(),super.dispose()}update(){this._inNavbar=this._detectNavbar(),this._popper&&this._popper.update()}_completeHide(t){const n=e.trigger(this._element,to,t);if(n.defaultPrevented)return;if("ontouchstart"in document.documentElement)for(const t of[].concat(...document.body.children))e.off(t,"mouseover",le);this._popper&&this._popper.destroy(),this._menu.classList.remove(G),this._element.classList.remove(G),this._element.setAttribute("aria-expanded","false"),v.removeDataAttribute(this._menu,"popper"),e.trigger(this._element,no,t)}_getConfig(e){if(e=super._getConfig(e),typeof e.reference=="object"&&!g(e.reference)&&typeof e.reference.getBoundingClientRect!="function")throw new TypeError(`${Ct.toUpperCase()}: Option "reference" provided type "object" without a required "getBoundingClientRect" method.`);return e}_createPopper(){if(typeof Et=="undefined")throw new TypeError("Bootstrap's dropdowns require Popper (https://popper.js.org)");let e=this._element;this._config.reference==="parent"?e=this._parent:g(this._config.reference)?e=w(this._config.reference):typeof this._config.reference=="object"&&(e=this._config.reference);const t=this._getPopperConfig();this._popper=je(e,this._menu,t)}_isShown(){return this._menu.classList.contains(G)}_getPlacement(){const e=this._parent;if(e.classList.contains(uo))return Co;if(e.classList.contains(ho))return Eo;if(e.classList.contains(mo))return ko;if(e.classList.contains(fo))return Ao;const t=getComputedStyle(this._menu).getPropertyValue("--bs-position").trim()==="end";return e.classList.contains(lo)?t?wo:_o:t?xo:Oo}_detectNavbar(){return this._element.closest(bo)!==null}_getOffset(){const{offset:e}=this._config;return typeof e=="string"?e.split(",").map(e=>Number.parseInt(e,10)):typeof e=="function"?t=>e(t,this._element):e}_getPopperConfig(){const e={placement:this._getPlacement(),modifiers:[{name:"preventOverflow",options:{boundary:this._config.boundary}},{name:"offset",options:{offset:this._getOffset()}}]};return(this._inNavbar||this._config.display==="static")&&(v.setDataAttribute(this._menu,"popper","static"),e.modifiers=[{name:"applyStyles",enabled:!1}]),{...e,...o(this._config.popperConfig,[e])}}_selectMenuItem({key:e,target:n}){const s=t.find(yo,this._menu).filter(e=>R(e));if(!s.length)return;$e(s,n,e===bt,!s.includes(n)).focus()}static jQueryInterface(e){return this.each(function(){const t=m.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e]()})}static clearMenus(e){if(e.button===eo||e.type==="keyup"&&e.key!==jt)return;const n=t.find(go);for(const a of n){const t=m.getInstance(a);if(!t||t._config.autoClose===!1)continue;const s=e.composedPath(),o=s.includes(t._menu);if(s.includes(t._element)||t._config.autoClose==="inside"&&!o||t._config.autoClose==="outside"&&o)continue;if(t._menu.contains(e.target)&&(e.type==="keyup"&&e.key===jt||/input|select|option|textarea|form/i.test(e.target.tagName)))continue;const i={relatedTarget:t._element};e.type==="click"&&(i.clickEvent=e),t._completeHide(i)}}static dataApiKeydownHandler(e){const a=/input|textarea/i.test(e.target.tagName),s=e.key===Xs,o=[Zs,bt].includes(e.key);if(!o&&!s)return;if(a&&!s)return;e.preventDefault();const i=this.matches(z)?this:t.prev(this,z)[0]||t.next(this,z)[0]||t.findOne(z,e.delegateTarget.parentNode),n=m.getOrCreateInstance(i);if(o){e.stopPropagation(),n.show(),n._selectMenuItem(e);return}n._isShown()&&(e.stopPropagation(),n.hide(),i.focus())}}e.on(document,yt,z,m.dataApiKeydownHandler),e.on(document,yt,me,m.dataApiKeydownHandler),e.on(document,vt,m.clearMenus),e.on(document,ro,m.clearMenus),e.on(document,vt,z,function(e){e.preventDefault(),m.getOrCreateInstance(this).toggle()}),u(m);const _t="backdrop",zo="fade",wt="show",Ot=`mousedown.bs.${_t}`,Lo={className:"modal-backdrop",clickCallback:null,isAnimated:!1,isVisible:!0,rootElement:"body"},Ro={className:"string",clickCallback:"(function|null)",isAnimated:"boolean",isVisible:"boolean",rootElement:"(element|string)"};class xt extends se{constructor(e){super(),this._config=this._getConfig(e),this._isAppended=!1,this._element=null}static get Default(){return Lo}static get DefaultType(){return Ro}static get NAME(){return _t}show(e){if(!this._config.isVisible){o(e);return}this._append();const t=this._getElement();this._config.isAnimated&&oe(t),t.classList.add(wt),this._emulateAnimation(()=>{o(e)})}hide(e){if(!this._config.isVisible){o(e);return}this._getElement().classList.remove(wt),this._emulateAnimation(()=>{this.dispose(),o(e)})}dispose(){if(!this._isAppended)return;e.off(this._element,Ot),this._element.remove(),this._isAppended=!1}_getElement(){if(!this._element){const e=document.createElement("div");e.className=this._config.className,this._config.isAnimated&&e.classList.add(zo),this._element=e}return this._element}_configAfterMerge(e){return e.rootElement=w(e.rootElement),e}_append(){if(this._isAppended)return;const t=this._getElement();this._config.rootElement.append(t),e.on(t,Ot,()=>{o(this._config.clickCallback)}),this._isAppended=!0}_emulateAnimation(e){Zn(e,this._getElement(),this._config.isAnimated)}}const Ho="focustrap",Io="bs.focustrap",be=`.${Io}`,Vo=`focusin${be}`,$o=`keydown.tab${be}`,Wo="Tab",Uo="forward",kt="backward",qo={autofocus:!0,trapElement:null},Yo={autofocus:"boolean",trapElement:"element"};class Dt extends se{constructor(e){super(),this._config=this._getConfig(e),this._isActive=!1,this._lastTabNavDirection=null}static get Default(){return qo}static get DefaultType(){return Yo}static get NAME(){return Ho}activate(){if(this._isActive)return;this._config.autofocus&&this._config.trapElement.focus(),e.off(document,be),e.on(document,Vo,e=>this._handleFocusin(e)),e.on(document,$o,e=>this._handleKeydown(e)),this._isActive=!0}deactivate(){if(!this._isActive)return;this._isActive=!1,e.off(document,be)}_handleFocusin(e){const{trapElement:n}=this._config;if(e.target===document||e.target===n||n.contains(e.target))return;const s=t.focusableChildren(n);s.length===0?n.focus():this._lastTabNavDirection===kt?s[s.length-1].focus():s[0].focus()}_handleKeydown(e){if(e.key!==Wo)return;this._lastTabNavDirection=e.shiftKey?kt:Uo}}const Nt=".fixed-top, .fixed-bottom, .is-fixed, .sticky-top",Lt=".sticky-top",Oe="padding-right",Rt="margin-right";class qe{constructor(){this._element=document.body}getWidth(){const e=document.documentElement.clientWidth;return Math.abs(window.innerWidth-e)}hide(){const e=this.getWidth();this._disableOverFlow(),this._setElementAttributes(this._element,Oe,t=>t+e),this._setElementAttributes(Nt,Oe,t=>t+e),this._setElementAttributes(Lt,Rt,t=>t-e)}reset(){this._resetElementAttributes(this._element,"overflow"),this._resetElementAttributes(this._element,Oe),this._resetElementAttributes(Nt,Oe),this._resetElementAttributes(Lt,Rt)}isOverflowing(){return this.getWidth()>0}_disableOverFlow(){this._saveInitialAttribute(this._element,"overflow"),this._element.style.overflow="hidden"}_setElementAttributes(e,t,n){const s=this.getWidth(),o=e=>{if(e!==this._element&&window.innerWidth>e.clientWidth+s)return;this._saveInitialAttribute(e,t);const o=window.getComputedStyle(e).getPropertyValue(t);e.style.setProperty(t,`${n(Number.parseFloat(o))}px`)};this._applyManipulationCallback(e,o)}_saveInitialAttribute(e,t){const n=e.style.getPropertyValue(t);n&&v.setDataAttribute(e,t,n)}_resetElementAttributes(e,t){const n=e=>{const n=v.getDataAttribute(e,t);if(n===null){e.style.removeProperty(t);return}v.removeDataAttribute(e,t),e.style.setProperty(t,n)};this._applyManipulationCallback(e,n)}_applyManipulationCallback(e,n){if(g(e)){n(e);return}for(const s of t.find(e,this._element))n(s)}}const ti="modal",ni="bs.modal",d=`.${ni}`,oi=".data-api",ii="Escape",ai=`hide${d}`,ri=`hidePrevented${d}`,Ht=`hidden${d}`,It=`show${d}`,di=`shown${d}`,ui=`resize${d}`,hi=`click.dismiss${d}`,mi=`mousedown.dismiss${d}`,fi=`keydown.dismiss${d}`,pi=`click${d}${oi}`,Bt="modal-open",vi="fade",$t="show",Se="modal-static",yi=".modal.show",_i=".modal-dialog",wi=".modal-body",Oi='[data-bs-toggle="modal"]',xi={backdrop:!0,focus:!0,keyboard:!0},Ci={backdrop:"(boolean|string)",focus:"boolean",keyboard:"boolean"};class $ extends h{constructor(e,n){super(e,n),this._dialog=t.findOne(_i,this._element),this._backdrop=this._initializeBackDrop(),this._focustrap=this._initializeFocusTrap(),this._isShown=!1,this._isTransitioning=!1,this._scrollBar=new qe,this._addEventListeners()}static get Default(){return xi}static get DefaultType(){return Ci}static get NAME(){return ti}toggle(e){return this._isShown?this.hide():this.show(e)}show(t){if(this._isShown||this._isTransitioning)return;const n=e.trigger(this._element,It,{relatedTarget:t});if(n.defaultPrevented)return;this._isShown=!0,this._isTransitioning=!0,this._scrollBar.hide(),document.body.classList.add(Bt),this._adjustDialog(),this._backdrop.show(()=>this._showElement(t))}hide(){if(!this._isShown||this._isTransitioning)return;const t=e.trigger(this._element,ai);if(t.defaultPrevented)return;this._isShown=!1,this._isTransitioning=!0,this._focustrap.deactivate(),this._element.classList.remove($t),this._queueCallback(()=>this._hideModal(),this._element,this._isAnimated())}dispose(){e.off(window,d),e.off(this._dialog,d),this._backdrop.dispose(),this._focustrap.deactivate(),super.dispose()}handleUpdate(){this._adjustDialog()}_initializeBackDrop(){return new xt({isVisible:Boolean(this._config.backdrop),isAnimated:this._isAnimated()})}_initializeFocusTrap(){return new Dt({trapElement:this._element})}_showElement(n){document.body.contains(this._element)||document.body.append(this._element),this._element.style.display="block",this._element.removeAttribute("aria-hidden"),this._element.setAttribute("aria-modal",!0),this._element.setAttribute("role","dialog"),this._element.scrollTop=0;const s=t.findOne(wi,this._dialog);s&&(s.scrollTop=0),oe(this._element),this._element.classList.add($t);const o=()=>{this._config.focus&&this._focustrap.activate(),this._isTransitioning=!1,e.trigger(this._element,di,{relatedTarget:n})};this._queueCallback(o,this._dialog,this._isAnimated())}_addEventListeners(){e.on(this._element,fi,e=>{if(e.key!==ii)return;if(this._config.keyboard){this.hide();return}this._triggerBackdropTransition()}),e.on(window,ui,()=>{this._isShown&&!this._isTransitioning&&this._adjustDialog()}),e.on(this._element,mi,t=>{e.one(this._element,hi,e=>{if(this._element!==t.target||this._element!==e.target)return;if(this._config.backdrop==="static"){this._triggerBackdropTransition();return}this._config.backdrop&&this.hide()})})}_hideModal(){this._element.style.display="none",this._element.setAttribute("aria-hidden",!0),this._element.removeAttribute("aria-modal"),this._element.removeAttribute("role"),this._isTransitioning=!1,this._backdrop.hide(()=>{document.body.classList.remove(Bt),this._resetAdjustments(),this._scrollBar.reset(),e.trigger(this._element,Ht)})}_isAnimated(){return this._element.classList.contains(vi)}_triggerBackdropTransition(){const n=e.trigger(this._element,ri);if(n.defaultPrevented)return;const s=this._element.scrollHeight>document.documentElement.clientHeight,t=this._element.style.overflowY;if(t==="hidden"||this._element.classList.contains(Se))return;s||(this._element.style.overflowY="hidden"),this._element.classList.add(Se),this._queueCallback(()=>{this._element.classList.remove(Se),this._queueCallback(()=>{this._element.style.overflowY=t},this._dialog)},this._dialog),this._element.focus()}_adjustDialog(){const t=this._element.scrollHeight>document.documentElement.clientHeight,e=this._scrollBar.getWidth(),n=e>0;if(n&&!t){const t=c()?"paddingLeft":"paddingRight";this._element.style[t]=`${e}px`}if(!n&&t){const t=c()?"paddingRight":"paddingLeft";this._element.style[t]=`${e}px`}}_resetAdjustments(){this._element.style.paddingLeft="",this._element.style.paddingRight=""}static jQueryInterface(e,t){return this.each(function(){const n=$.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof n[e]=="undefined")throw new TypeError(`No method named "${e}"`);n[e](t)})}}e.on(document,pi,Oi,function(n){const s=t.getElementFromSelector(this);["A","AREA"].includes(this.tagName)&&n.preventDefault(),e.one(s,It,t=>{if(t.defaultPrevented)return;e.one(s,Ht,()=>{R(this)&&this.focus()})});const o=t.findOne(yi);o&&$.getInstance(o).hide();const i=$.getOrCreateInstance(s);i.toggle(this)}),_e($),u($);const ki="offcanvas",Ai="bs.offcanvas",b=`.${Ai}`,Wt=".data-api",cs=`load${b}${Wt}`,Ti="Escape",qt="show",on="showing",an="hiding",Li="offcanvas-backdrop",rn=".offcanvas.show",Pi=`show${b}`,Hi=`shown${b}`,Ii=`hide${b}`,cn=`hidePrevented${b}`,ln=`hidden${b}`,$i=`resize${b}`,Wi=`click${b}${Wt}`,Ui=`keydown.dismiss${b}`,Ki='[data-bs-toggle="offcanvas"]',qi={backdrop:!0,keyboard:!0,scroll:!1},Yi={backdrop:"(boolean|string)",keyboard:"boolean",scroll:"boolean"};class O extends h{constructor(e,t){super(e,t),this._isShown=!1,this._backdrop=this._initializeBackDrop(),this._focustrap=this._initializeFocusTrap(),this._addEventListeners()}static get Default(){return qi}static get DefaultType(){return Yi}static get NAME(){return ki}toggle(e){return this._isShown?this.hide():this.show(e)}show(t){if(this._isShown)return;const n=e.trigger(this._element,Pi,{relatedTarget:t});if(n.defaultPrevented)return;this._isShown=!0,this._backdrop.show(),this._config.scroll||(new qe).hide(),this._element.setAttribute("aria-modal",!0),this._element.setAttribute("role","dialog"),this._element.classList.add(on);const s=()=>{(!this._config.scroll||this._config.backdrop)&&this._focustrap.activate(),this._element.classList.add(qt),this._element.classList.remove(on),e.trigger(this._element,Hi,{relatedTarget:t})};this._queueCallback(s,this._element,!0)}hide(){if(!this._isShown)return;const t=e.trigger(this._element,Ii);if(t.defaultPrevented)return;this._focustrap.deactivate(),this._element.blur(),this._isShown=!1,this._element.classList.add(an),this._backdrop.hide();const n=()=>{this._element.classList.remove(qt,an),this._element.removeAttribute("aria-modal"),this._element.removeAttribute("role"),this._config.scroll||(new qe).reset(),e.trigger(this._element,ln)};this._queueCallback(n,this._element,!0)}dispose(){this._backdrop.dispose(),this._focustrap.deactivate(),super.dispose()}_initializeBackDrop(){const n=()=>{if(this._config.backdrop==="static"){e.trigger(this._element,cn);return}this.hide()},t=Boolean(this._config.backdrop);return new xt({className:Li,isVisible:t,isAnimated:!0,rootElement:this._element.parentNode,clickCallback:t?n:null})}_initializeFocusTrap(){return new Dt({trapElement:this._element})}_addEventListeners(){e.on(this._element,Ui,t=>{if(t.key!==Ti)return;if(this._config.keyboard){this.hide();return}e.trigger(this._element,cn)})}static jQueryInterface(e){return this.each(function(){const t=O.getOrCreateInstance(this,e);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e](this)})}}e.on(document,Wi,Ki,function(n){const s=t.getElementFromSelector(this);if(["A","AREA"].includes(this.tagName)&&n.preventDefault(),y(this))return;e.one(s,ln,()=>{R(this)&&this.focus()});const o=t.findOne(rn);o&&o!==s&&O.getInstance(o).hide();const i=O.getOrCreateInstance(s);i.toggle(this)}),e.on(window,cs,()=>{for(const e of t.find(rn))O.getOrCreateInstance(e).show()}),e.on(window,$i,()=>{for(const e of t.find("[aria-modal][class*=show][class*=offcanvas-]"))getComputedStyle(e).position!=="fixed"&&O.getOrCreateInstance(e).hide()}),_e(O),u(O);const Xi=/^aria-[\w-]*$/i,dn={"*":["class","dir","id","lang","role",Xi],a:["target","href","title","rel"],area:[],b:[],br:[],col:[],code:[],dd:[],div:[],dl:[],dt:[],em:[],hr:[],h1:[],h2:[],h3:[],h4:[],h5:[],h6:[],i:[],img:["src","srcset","alt","title","width","height"],li:[],ol:[],p:[],pre:[],s:[],small:[],span:[],sub:[],sup:[],strong:[],u:[],ul:[]},Zi=new Set(["background","cite","href","itemtype","longdesc","poster","src","xlink:href"]),Ji=/^(?!javascript:)(?:[a-z0-9+.-]+:|[^&:/?#]*(?:[/?#]|$))/i,ea=(e,t)=>{const n=e.nodeName.toLowerCase();return t.includes(n)?!Zi.has(n)||Boolean(Ji.test(e.nodeValue)):t.filter(e=>e instanceof RegExp).some(e=>e.test(n))};function ta(e,t,n){if(!e.length)return e;if(n&&typeof n=="function")return n(e);const o=new window.DOMParser,s=o.parseFromString(e,"text/html"),i=[].concat(...s.body.querySelectorAll("*"));for(const e of i){const n=e.nodeName.toLowerCase();if(!Object.keys(t).includes(n)){e.remove();continue}const s=[].concat(...e.attributes),o=[].concat(t["*"]||[],t[n]||[]);for(const t of s)ea(t,o)||e.removeAttribute(t.nodeName)}return s.body.innerHTML}const na="TemplateFactory",sa={allowList:dn,content:{},extraClass:"",html:!1,sanitize:!0,sanitizeFn:null,template:"<div></div>"},oa={allowList:"object",content:"object",extraClass:"(string|function)",html:"boolean",sanitize:"boolean",sanitizeFn:"(null|function)",template:"string"},ia={entry:"(string|element|function|null)",selector:"(string|element)"};class aa extends se{constructor(e){super(),this._config=this._getConfig(e)}static get Default(){return sa}static get DefaultType(){return oa}static get NAME(){return na}getContent(){return Object.values(this._config.content).map(e=>this._resolvePossibleFunction(e)).filter(Boolean)}hasContent(){return this.getContent().length>0}changeContent(e){return this._checkContent(e),this._config.content={...this._config.content,...e},this}toHtml(){const e=document.createElement("div");e.innerHTML=this._maybeSanitize(this._config.template);for(const[t,n]of Object.entries(this._config.content))this._setContent(e,n,t);const t=e.children[0],n=this._resolvePossibleFunction(this._config.extraClass);return n&&t.classList.add(...n.split(" ")),t}_typeCheckConfig(e){super._typeCheckConfig(e),this._checkContent(e.content)}_checkContent(e){for(const[t,n]of Object.entries(e))super._typeCheckConfig({selector:t,entry:n},ia)}_setContent(e,n,s){const o=t.findOne(s,e);if(!o)return;if(n=this._resolvePossibleFunction(n),!n){o.remove();return}if(g(n)){this._putElementInTemplate(w(n),o);return}if(this._config.html){o.innerHTML=this._maybeSanitize(n);return}o.textContent=n}_maybeSanitize(e){return this._config.sanitize?ta(e,this._config.allowList,this._config.sanitizeFn):e}_resolvePossibleFunction(e){return o(e,[this])}_putElementInTemplate(e,t){if(this._config.html){t.innerHTML="",t.append(e);return}t.textContent=e.textContent}}const ra="tooltip",ca=new Set(["sanitize","allowList","sanitizeFn"]),Ze="fade",da="modal",ye="show",ha=".tooltip-inner",hn=`.${da}`,mn="hide.bs.modal",Z="hover",at="focus",va="click",ba="manual",ja="hide",ya="hidden",_a="show",wa="shown",Oa="inserted",xa="click",Ca="focusin",Ea="focusout",ka="mouseenter",Aa="mouseleave",Sa={AUTO:"auto",TOP:"top",RIGHT:c()?"left":"right",BOTTOM:"bottom",LEFT:c()?"right":"left"},Ma={allowList:dn,animation:!0,boundary:"clippingParents",container:!1,customClass:"",delay:0,fallbackPlacements:["top","right","bottom","left"],html:!1,offset:[0,6],placement:"top",popperConfig:null,sanitize:!0,sanitizeFn:null,selector:!1,template:'<div class="tooltip" role="tooltip"><div class="tooltip-arrow"></div><div class="tooltip-inner"></div></div>',title:"",trigger:"hover focus"},Fa={allowList:"object",animation:"boolean",boundary:"(string|element)",container:"(string|element|boolean)",customClass:"(string|function)",delay:"(number|object)",fallbackPlacements:"array",html:"boolean",offset:"(array|string|function)",placement:"(string|function)",popperConfig:"(null|object|function)",sanitize:"boolean",sanitizeFn:"(null|function)",selector:"(string|boolean)",template:"string",title:"(string|element|function)",trigger:"string"};class H extends h{constructor(e,t){if(typeof Et=="undefined")throw new TypeError("Bootstrap's tooltips require Popper (https://popper.js.org)");super(e,t),this._isEnabled=!0,this._timeout=0,this._isHovered=null,this._activeTrigger={},this._popper=null,this._templateFactory=null,this._newContent=null,this.tip=null,this._setListeners(),this._config.selector||this._fixTitle()}static get Default(){return Ma}static get DefaultType(){return Fa}static get NAME(){return ra}enable(){this._isEnabled=!0}disable(){this._isEnabled=!1}toggleEnabled(){this._isEnabled=!this._isEnabled}toggle(){if(!this._isEnabled)return;if(this._activeTrigger.click=!this._activeTrigger.click,this._isShown()){this._leave();return}this._enter()}dispose(){clearTimeout(this._timeout),e.off(this._element.closest(hn),mn,this._hideModalHandler),this._element.getAttribute("data-bs-original-title")&&this._element.setAttribute("title",this._element.getAttribute("data-bs-original-title")),this._disposePopper(),super.dispose()}show(){if(this._element.style.display==="none")throw new Error("Please use show on visible elements");if(!this._isWithContent()||!this._isEnabled)return;const n=e.trigger(this._element,this.constructor.eventName(_a)),s=es(this._element),o=(s||this._element.ownerDocument.documentElement).contains(this._element);if(n.defaultPrevented||!o)return;this._disposePopper();const t=this._getTipElement();this._element.setAttribute("aria-describedby",t.getAttribute("id"));const{container:i}=this._config;if(this._element.ownerDocument.documentElement.contains(this.tip)||(i.append(t),e.trigger(this._element,this.constructor.eventName(Oa))),this._popper=this._createPopper(t),t.classList.add(ye),"ontouchstart"in document.documentElement)for(const t of[].concat(...document.body.children))e.on(t,"mouseover",le);const a=()=>{e.trigger(this._element,this.constructor.eventName(wa)),this._isHovered===!1&&this._leave(),this._isHovered=!1};this._queueCallback(a,this.tip,this._isAnimated())}hide(){if(!this._isShown())return;const t=e.trigger(this._element,this.constructor.eventName(ja));if(t.defaultPrevented)return;const n=this._getTipElement();if(n.classList.remove(ye),"ontouchstart"in document.documentElement)for(const t of[].concat(...document.body.children))e.off(t,"mouseover",le);this._activeTrigger[va]=!1,this._activeTrigger[at]=!1,this._activeTrigger[Z]=!1,this._isHovered=null;const s=()=>{if(this._isWithActiveTrigger())return;this._isHovered||this._disposePopper(),this._element.removeAttribute("aria-describedby"),e.trigger(this._element,this.constructor.eventName(ya))};this._queueCallback(s,this.tip,this._isAnimated())}update(){this._popper&&this._popper.update()}_isWithContent(){return Boolean(this._getTitle())}_getTipElement(){return this.tip||(this.tip=this._createTipElement(this._newContent||this._getContentForTemplate())),this.tip}_createTipElement(e){const t=this._getTemplateFactory(e).toHtml();if(!t)return null;t.classList.remove(Ze,ye),t.classList.add(`bs-${this.constructor.NAME}-auto`);const n=Yr(this.constructor.NAME).toString();return t.setAttribute("id",n),this._isAnimated()&&t.classList.add(Ze),t}setContent(e){this._newContent=e,this._isShown()&&(this._disposePopper(),this.show())}_getTemplateFactory(e){return this._templateFactory?this._templateFactory.changeContent(e):this._templateFactory=new aa({...this._config,content:e,extraClass:this._resolvePossibleFunction(this._config.customClass)}),this._templateFactory}_getContentForTemplate(){return{[ha]:this._getTitle()}}_getTitle(){return this._resolvePossibleFunction(this._config.title)||this._element.getAttribute("data-bs-original-title")}_initializeOnDelegatedTarget(e){return this.constructor.getOrCreateInstance(e.delegateTarget,this._getDelegateConfig())}_isAnimated(){return this._config.animation||this.tip&&this.tip.classList.contains(Ze)}_isShown(){return this.tip&&this.tip.classList.contains(ye)}_createPopper(e){const t=o(this._config.placement,[this,e,this._element]),n=Sa[t.toUpperCase()];return je(this._element,e,this._getPopperConfig(n))}_getOffset(){const{offset:e}=this._config;return typeof e=="string"?e.split(",").map(e=>Number.parseInt(e,10)):typeof e=="function"?t=>e(t,this._element):e}_resolvePossibleFunction(e){return o(e,[this._element])}_getPopperConfig(e){const t={placement:e,modifiers:[{name:"flip",options:{fallbackPlacements:this._config.fallbackPlacements}},{name:"offset",options:{offset:this._getOffset()}},{name:"preventOverflow",options:{boundary:this._config.boundary}},{name:"arrow",options:{element:`.${this.constructor.NAME}-arrow`}},{name:"preSetPlacement",enabled:!0,phase:"beforeMain",fn:e=>{this._getTipElement().setAttribute("data-popper-placement",e.state.placement)}}]};return{...t,...o(this._config.popperConfig,[t])}}_setListeners(){const t=this._config.trigger.split(" ");for(const n of t)if(n==="click")e.on(this._element,this.constructor.eventName(xa),this._config.selector,e=>{const t=this._initializeOnDelegatedTarget(e);t.toggle()});else if(n!==ba){const t=n===Z?this.constructor.eventName(ka):this.constructor.eventName(Ca),s=n===Z?this.constructor.eventName(Aa):this.constructor.eventName(Ea);e.on(this._element,t,this._config.selector,e=>{const t=this._initializeOnDelegatedTarget(e);t._activeTrigger[e.type==="focusin"?at:Z]=!0,t._enter()}),e.on(this._element,s,this._config.selector,e=>{const t=this._initializeOnDelegatedTarget(e);t._activeTrigger[e.type==="focusout"?at:Z]=t._element.contains(e.relatedTarget),t._leave()})}this._hideModalHandler=()=>{this._element&&this.hide()},e.on(this._element.closest(hn),mn,this._hideModalHandler)}_fixTitle(){const e=this._element.getAttribute("title");if(!e)return;!this._element.getAttribute("aria-label")&&!this._element.textContent.trim()&&this._element.setAttribute("aria-label",e),this._element.setAttribute("data-bs-original-title",e),this._element.removeAttribute("title")}_enter(){if(this._isShown()||this._isHovered){this._isHovered=!0;return}this._isHovered=!0,this._setTimeout(()=>{this._isHovered&&this.show()},this._config.delay.show)}_leave(){if(this._isWithActiveTrigger())return;this._isHovered=!1,this._setTimeout(()=>{this._isHovered||this.hide()},this._config.delay.hide)}_setTimeout(e,t){clearTimeout(this._timeout),this._timeout=setTimeout(e,t)}_isWithActiveTrigger(){return Object.values(this._activeTrigger).includes(!0)}_getConfig(e){const t=v.getDataAttributes(this._element);for(const e of Object.keys(t))ca.has(e)&&delete t[e];return e={...t,...typeof e=="object"&&e?e:{}},e=this._mergeConfigObj(e),e=this._configAfterMerge(e),this._typeCheckConfig(e),e}_configAfterMerge(e){return e.container=e.container===!1?document.body:w(e.container),typeof e.delay=="number"&&(e.delay={show:e.delay,hide:e.delay}),typeof e.title=="number"&&(e.title=e.title.toString()),typeof e.content=="number"&&(e.content=e.content.toString()),e}_getDelegateConfig(){const e={};for(const[t,n]of Object.entries(this._config))this.constructor.Default[t]!==n&&(e[t]=n);return e.selector=!1,e.trigger="manual",e}_disposePopper(){this._popper&&(this._popper.destroy(),this._popper=null),this.tip&&(this.tip.remove(),this.tip=null)}static jQueryInterface(e){return this.each(function(){const t=H.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e]()})}}u(H);const za="popover",Da=".popover-header",Na=".popover-body",La={...H.Default,content:"",offset:[0,8],placement:"right",template:'<div class="popover" role="tooltip"><div class="popover-arrow"></div><h3 class="popover-header"></h3><div class="popover-body"></div></div>',trigger:"click"},Ra={...H.DefaultType,content:"(null|string|element|function)"};class mt extends H{static get Default(){return La}static get DefaultType(){return Ra}static get NAME(){return za}_isWithContent(){return this._getTitle()||this._getContent()}_getContentForTemplate(){return{[Da]:this._getTitle(),[Na]:this._getContent()}}_getContent(){return this._resolvePossibleFunction(this._config.content)}static jQueryInterface(e){return this.each(function(){const t=mt.getOrCreateInstance(this,e);if(typeof e!="string")return;if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e]()})}}u(mt);const Ha="scrollspy",Ia="bs.scrollspy",Ie=`.${Ia}`,Va=".data-api",$a=`activate${Ie}`,pn=`click${Ie}`,Ua=`load${Ie}${Va}`,Ka="dropdown-item",W="active",Ya='[data-bs-spy="scroll"]',Ge="[href]",Xa=".nav, .list-group",gn=".nav-link",Za=".nav-item",Ja=".list-group-item",er=`${gn}, ${Za} > ${gn}, ${Ja}`,tr=".dropdown",nr=".dropdown-toggle",sr={offset:null,rootMargin:"0px 0px -25%",smoothScroll:!1,target:null,threshold:[.1,.5,1]},or={offset:"(number|null)",rootMargin:"string",smoothScroll:"boolean",target:"element",threshold:"array"};class xe extends h{constructor(e,t){super(e,t),this._targetLinks=new Map,this._observableSections=new Map,this._rootElement=getComputedStyle(this._element).overflowY==="visible"?null:this._element,this._activeTarget=null,this._observer=null,this._previousScrollData={visibleEntryTop:0,parentScrollTop:0},this.refresh()}static get Default(){return sr}static get DefaultType(){return or}static get NAME(){return Ha}refresh(){this._initializeTargetsAndObservables(),this._maybeEnableSmoothScroll(),this._observer?this._observer.disconnect():this._observer=this._getNewObserver();for(const e of this._observableSections.values())this._observer.observe(e)}dispose(){this._observer.disconnect(),super.dispose()}_configAfterMerge(e){return e.target=w(e.target)||document.body,e.rootMargin=e.offset?`${e.offset}px 0px -30%`:e.rootMargin,typeof e.threshold=="string"&&(e.threshold=e.threshold.split(",").map(e=>Number.parseFloat(e))),e}_maybeEnableSmoothScroll(){if(!this._config.smoothScroll)return;e.off(this._config.target,pn),e.on(this._config.target,pn,Ge,e=>{const t=this._observableSections.get(e.target.hash);if(t){e.preventDefault();const n=this._rootElement||window,s=t.offsetTop-this._element.offsetTop;if(n.scrollTo){n.scrollTo({top:s,behavior:"smooth"});return}n.scrollTop=s}})}_getNewObserver(){const e={root:this._rootElement,threshold:this._config.threshold,rootMargin:this._config.rootMargin};return new IntersectionObserver(e=>this._observerCallback(e),e)}_observerCallback(e){const n=e=>this._targetLinks.get(`#${e.target.id}`),s=e=>{this._previousScrollData.visibleEntryTop=e.target.offsetTop,this._process(n(e))},t=(this._rootElement||document.documentElement).scrollTop,o=t>=this._previousScrollData.parentScrollTop;this._previousScrollData.parentScrollTop=t;for(const i of e){if(!i.isIntersecting){this._activeTarget=null,this._clearActiveClass(n(i));continue}const a=i.target.offsetTop>=this._previousScrollData.visibleEntryTop;if(o&&a){if(s(i),!t)return;continue}!o&&!a&&s(i)}}_initializeTargetsAndObservables(){this._targetLinks=new Map,this._observableSections=new Map;const e=t.find(Ge,this._config.target);for(const n of e){if(!n.hash||y(n))continue;const s=t.findOne(decodeURI(n.hash),this._element);R(s)&&(this._targetLinks.set(decodeURI(n.hash),n),this._observableSections.set(n.hash,s))}}_process(t){if(this._activeTarget===t)return;this._clearActiveClass(this._config.target),this._activeTarget=t,t.classList.add(W),this._activateParents(t),e.trigger(this._element,$a,{relatedTarget:t})}_activateParents(e){if(e.classList.contains(Ka)){t.findOne(nr,e.closest(tr)).classList.add(W);return}for(const n of t.parents(e,Xa))for(const e of t.prev(n,er))e.classList.add(W)}_clearActiveClass(e){e.classList.remove(W);const n=t.find(`${Ge}.${W}`,e);for(const e of n)e.classList.remove(W)}static jQueryInterface(e){return this.each(function(){const t=xe.getOrCreateInstance(this,e);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e]()})}}e.on(window,Ua,()=>{for(const e of t.find(Ya))xe.getOrCreateInstance(e)}),u(xe);const ar="tab",rr="bs.tab",M=`.${rr}`,lr=`hide${M}`,dr=`hidden${M}`,ur=`show${M}`,hr=`shown${M}`,mr=`click${M}`,fr=`keydown${M}`,pr=`load${M}`,gr="ArrowLeft",vn="ArrowRight",br="ArrowUp",yn="ArrowDown",ft="Home",wn="End",S="active",Mn="fade",Ye="show",Cr="dropdown",Wn=".dropdown-toggle",kr=".dropdown-menu",Ne=`:not(${Wn})`,Sr='.list-group, .nav, [role="tablist"]',Mr=".nav-item, .list-group-item",Fr=`.nav-link${Ne}, .list-group-item${Ne}, [role="tab"]${Ne}`,Gn='[data-bs-toggle="tab"], [data-bs-toggle="pill"], [data-bs-toggle="list"]',Pe=`${Fr}, ${Gn}`,Dr=`.${S}[data-bs-toggle="tab"], .${S}[data-bs-toggle="pill"], .${S}[data-bs-toggle="list"]`;class B extends h{constructor(t){if(super(t),this._parent=this._element.closest(Sr),!this._parent)return;this._setInitialAttributes(this._parent,this._getChildren()),e.on(this._element,fr,e=>this._keydown(e))}static get NAME(){return ar}show(){const t=this._element;if(this._elemIsActive(t))return;const n=this._getActiveElem(),s=n?e.trigger(n,lr,{relatedTarget:t}):null,o=e.trigger(t,ur,{relatedTarget:n});if(o.defaultPrevented||s&&s.defaultPrevented)return;this._deactivate(n,t),this._activate(t,n)}_activate(n,s){if(!n)return;n.classList.add(S),this._activate(t.getElementFromSelector(n));const o=()=>{if(n.getAttribute("role")!=="tab"){n.classList.add(Ye);return}n.removeAttribute("tabindex"),n.setAttribute("aria-selected",!0),this._toggleDropDown(n,!0),e.trigger(n,hr,{relatedTarget:s})};this._queueCallback(o,n,n.classList.contains(Mn))}_deactivate(n,s){if(!n)return;n.classList.remove(S),n.blur(),this._deactivate(t.getElementFromSelector(n));const o=()=>{if(n.getAttribute("role")!=="tab"){n.classList.remove(Ye);return}n.setAttribute("aria-selected",!1),n.setAttribute("tabindex","-1"),this._toggleDropDown(n,!1),e.trigger(n,dr,{relatedTarget:s})};this._queueCallback(o,n,n.classList.contains(Mn))}_keydown(e){if(![gr,vn,br,yn,ft,wn].includes(e.key))return;e.stopPropagation(),e.preventDefault();const n=this._getChildren().filter(e=>!y(e));let t;if([ft,wn].includes(e.key))t=n[e.key===ft?0:n.length-1];else{const s=[vn,yn].includes(e.key);t=$e(n,e.target,s,!0)}t&&(t.focus({preventScroll:!0}),B.getOrCreateInstance(t).show())}_getChildren(){return t.find(Pe,this._parent)}_getActiveElem(){return this._getChildren().find(e=>this._elemIsActive(e))||null}_setInitialAttributes(e,t){this._setAttributeIfNotExists(e,"role","tablist");for(const e of t)this._setInitialAttributesOnChild(e)}_setInitialAttributesOnChild(e){e=this._getInnerElement(e);const t=this._elemIsActive(e),n=this._getOuterElement(e);e.setAttribute("aria-selected",t),n!==e&&this._setAttributeIfNotExists(n,"role","presentation"),t||e.setAttribute("tabindex","-1"),this._setAttributeIfNotExists(e,"role","tab"),this._setInitialAttributesOnTargetPanel(e)}_setInitialAttributesOnTargetPanel(e){const n=t.getElementFromSelector(e);if(!n)return;this._setAttributeIfNotExists(n,"role","tabpanel"),e.id&&this._setAttributeIfNotExists(n,"aria-labelledby",`${e.id}`)}_toggleDropDown(e,n){const s=this._getOuterElement(e);if(!s.classList.contains(Cr))return;const o=(e,o)=>{const i=t.findOne(e,s);i&&i.classList.toggle(o,n)};o(Wn,S),o(kr,Ye),s.setAttribute("aria-expanded",n)}_setAttributeIfNotExists(e,t,n){e.hasAttribute(t)||e.setAttribute(t,n)}_elemIsActive(e){return e.classList.contains(S)}_getInnerElement(e){return e.matches(Pe)?e:t.findOne(Pe,e)}_getOuterElement(e){return e.closest(Mr)||e}static jQueryInterface(e){return this.each(function(){const t=B.getOrCreateInstance(this);if(typeof e!="string")return;if(t[e]===void 0||e.startsWith("_")||e==="constructor")throw new TypeError(`No method named "${e}"`);t[e]()})}}e.on(document,mr,Gn,function(e){if(["A","AREA"].includes(this.tagName)&&e.preventDefault(),y(this))return;B.getOrCreateInstance(this).show()}),e.on(window,pr,()=>{for(const e of t.find(Dr))B.getOrCreateInstance(e)}),u(B);const Lr="toast",Rr="bs.toast",x=`.${Rr}`,Hr=`mouseover${x}`,Ir=`mouseout${x}`,Br=`focusin${x}`,Vr=`focusout${x}`,$r=`hide${x}`,Wr=`hidden${x}`,Ur=`show${x}`,Kr=`shown${x}`,qr="fade",os="hide",ve="show",he="showing",Qr={animation:"boolean",autohide:"boolean",delay:"number"},Zr={animation:!0,autohide:!0,delay:5e3};class ue extends h{constructor(e,t){super(e,t),this._timeout=null,this._hasMouseInteraction=!1,this._hasKeyboardInteraction=!1,this._setListeners()}static get Default(){return Zr}static get DefaultType(){return Qr}static get NAME(){return Lr}show(){const t=e.trigger(this._element,Ur);if(t.defaultPrevented)return;this._clearTimeout(),this._config.animation&&this._element.classList.add(qr);const n=()=>{this._element.classList.remove(he),e.trigger(this._element,Kr),this._maybeScheduleHide()};this._element.classList.remove(os),oe(this._element),this._element.classList.add(ve,he),this._queueCallback(n,this._element,this._config.animation)}hide(){if(!this.isShown())return;const t=e.trigger(this._element,$r);if(t.defaultPrevented)return;const n=()=>{this._element.classList.add(os),this._element.classList.remove(he,ve),e.trigger(this._element,Wr)};this._element.classList.add(he),this._queueCallback(n,this._element,this._config.animation)}dispose(){this._clearTimeout(),this.isShown()&&this._element.classList.remove(ve),super.dispose()}isShown(){return this._element.classList.contains(ve)}_maybeScheduleHide(){if(!this._config.autohide)return;if(this._hasMouseInteraction||this._hasKeyboardInteraction)return;this._timeout=setTimeout(()=>{this.hide()},this._config.delay)}_onInteraction(e,t){switch(e.type){case"mouseover":case"mouseout":{this._hasMouseInteraction=t;break}case"focusin":case"focusout":{this._hasKeyboardInteraction=t;break}}if(t){this._clearTimeout();return}const n=e.relatedTarget;if(this._element===n||this._element.contains(n))return;this._maybeScheduleHide()}_setListeners(){e.on(this._element,Hr,e=>this._onInteraction(e,!0)),e.on(this._element,Ir,e=>this._onInteraction(e,!1)),e.on(this._element,Br,e=>this._onInteraction(e,!0)),e.on(this._element,Vr,e=>this._onInteraction(e,!1))}_clearTimeout(){clearTimeout(this._timeout),this._timeout=null}static jQueryInterface(e){return this.each(function(){const t=ue.getOrCreateInstance(this,e);if(typeof e=="string"){if(typeof t[e]=="undefined")throw new TypeError(`No method named "${e}"`);t[e](this)}})}}_e(ue),u(ue);const ec={Alert:de,Button:fe,Carousel:ee,Collapse:te,Dropdown:m,Modal:$,Offcanvas:O,Popover:mt,ScrollSpy:xe,Tab:B,Toast:ue,Tooltip:H};return ec}),function e(t){"use strict";try{module&&(t=module)}catch{}t._factory=e;function g(e){return"undefined"==typeof e||e}function M(e){const t=Array(e);for(let s=0;s<e;s++)t[s]=n();return t}function n(){return Object.create(null)}function re(e,t){return t.length-e.length}function i(e){return"string"==typeof e}function a(e){return"object"==typeof e}function x(e){return"function"==typeof e}function U(e,t){var n=Q;if(e&&(t&&(e=f(e,t)),this.H&&(e=f(e,this.H)),this.J&&1<e.length&&(e=f(e,this.J)),n||""===n)){if(t=e.split(n),this.filter){e=this.filter,n=t.length;const s=[];for(let o=0,a=0;o<n;o++){const i=t[o];i&&!e[i]&&(s[a++]=i)}e=s}else e=t;return e}return e}const Q=/[\p{Z}\p{S}\p{P}\p{C}]+/u,J=/[\u0300-\u036f]/g;function V(e,t){const a=Object.keys(e),r=a.length,n=[];let s="",i=0;for(let l=0,c,d;l<r;l++)c=a[l],(d=e[c])?(n[i++]=o(t?"(?!\\b)"+c+"(\\b|_)":c),n[i++]=d):s+=(s?"|":"")+c;return s&&(n[i++]=o(t?"(?!\\b)("+s+")(\\b|_)":"("+s+")"),n[i]=""),n}function f(e,t){for(let n=0,s=t.length;n<s&&(e=e.replace(t[n],t[n+1]),e);n+=2);return e}function o(e){return new RegExp(e,"g")}function B(e){let t="",n="";for(let s=0,i=e.length,o;s<i;s++)(o=e[s])!==n&&(t+=n=o);return t}var s,L,I,W,Y,ie={encode:P,F:!1,G:""};function P(e){return U.call(this,(""+e).toLowerCase(),!1)}const N={},r={};function T(e){m(e,"add"),m(e,"append"),m(e,"search"),m(e,"update"),m(e,"remove")}function m(e,t){e[t+"Async"]=function(){const s=this,e=arguments;var n=e[e.length-1];let o;return x(n)&&(o=n,delete e[e.length-1]),n=new Promise(function(n){setTimeout(function(){s.async=!0;const o=s[t].apply(s,e);s.async=!1,n(o)})}),o?(n.then(o),this):n}}function F(e,t,s,o){const l=e.length;let a=[],i,c,r=0;o&&(o=[]);for(let d=l-1;0<=d;d--){const h=e[d],f=h.length,u=n();let m=!i;for(let e=0;e<f;e++){const n=h[e],p=n.length;if(p)for(let f=0,h,e;f<p;f++)if(e=n[f],i){{if(i[e]){if(!d)if(s)s--;else if(a[r++]=e,r===t)return a;(d||o)&&(u[e]=1),m=!0}if(o&&(h=(c[e]||0)+1,c[e]=h,h<l)){const t=o[h-2]||(o[h-2]=[]);t[t.length]=e}}}else u[e]=1}if(o)i||(c=u);else if(!m)return[];i=u}if(o)for(let e=o.length-1,n,c;0<=e;e--){n=o[e],c=n.length;for(let o=0,e;o<c;o++)if(e=n[o],!i[e]){if(s)s--;else if(a[r++]=e,r===t)return a;i[e]=1}}return a}function ce(e,t){const o=n(),i=n(),s=[];for(let t=0;t<e.length;t++)o[e[t]]=1;for(let e=0,n;e<t.length;e++){n=t[e];for(let t=0,e;t<n.length;t++)e=n[t],o[e]&&!i[e]&&(i[e]=1,s[s.length]=e)}return s}function j(e){this.l=!0!==e&&e,this.cache=n(),this.h=[]}function S(e,t,n){a(e)&&(e=e.query);let s=this.cache.get(e);return s||(s=this.search(e,t,n),this.cache.set(e,s)),s}j.prototype.set=function(e,t){if(!this.cache[e]){var n=this.h.length;n===this.l?delete this.cache[this.h[n-1]]:n++;for(--n;0<n;n--)this.h[n]=this.h[n-1];this.h[0]=e}this.cache[e]=t},j.prototype.get=function(e){const t=this.cache[e];if(this.l&&t&&(e=this.h.indexOf(e))){const t=this.h[e-1];this.h[e-1]=this.h[e],this.h[e]=t}return t};const ee={memory:{charset:"latin:extra",D:3,B:4,m:!1},performance:{D:3,B:3,s:!1,context:{depth:2,D:1}},match:{charset:"latin:extra",G:"reverse"},score:{charset:"latin:advanced",D:20,B:3,context:{depth:3,D:9}},default:{}};function A(e,t,n,s,o,i,a,r){setTimeout(function(){const c=e(n?n+"."+s:s,JSON.stringify(a));c&&c.then?c.then(function(){t.export(e,t,n,o,i+1,r)}):t.export(e,t,n,o,i+1,r)})}function c(e,t){if(!(this instanceof c))return new c(e);if(e){i(e)?e=ee[e]:(s=e.preset)&&(e=Object.assign({},s[s],e)),s=e.charset;var s,o=e.lang;i(s)&&(-1===s.indexOf(":")&&(s+=":default"),s=r[s]),i(o)&&(o=N[o])}else e={};let a,l,d=e.context||{};if(this.encode=e.encode||s&&s.encode||P,this.register=t||n(),this.D=a=e.resolution||9,this.G=t=s&&s.G||e.tokenize||"strict",this.depth="strict"===t&&d.depth,this.l=g(d.bidirectional),this.s=l=g(e.optimize),this.m=g(e.fastupdate),this.B=e.minlength||1,this.C=e.boost,this.map=l?M(a):n(),this.A=a=d.resolution||1,this.h=l?M(a):n(),this.F=s&&s.F||e.rtl,this.H=(t=e.matcher||o&&o.H)&&V(t,!1),this.J=(t=e.stemmer||o&&o.J)&&V(t,!0),s=t=e.filter||o&&o.filter){s=t,o=n();for(let e=0,t=s.length;e<t;e++)o[s[e]]=1;s=o}this.filter=s,this.cache=(t=e.cache)&&new j(t)}s=c.prototype,s.append=function(e,t){return this.add(e,t,!0)},s.add=function(e,t,s,o){if(t&&(e||0===e)){if(!o&&!s&&this.register[e])return this.update(e,t);if(t=this.encode(t),o=t.length){const f=n(),d=n(),m=this.depth,u=this.D;for(let g=0;g<o;g++){let p=t[this.F?o-1-g:g];if(r=p.length,p&&r>=this.B&&(m||!d[p])){var i,r,l,a=b(u,o,g),c="";switch(this.G){case"full":if(2<r){for(a=0;a<r;a++)for(i=r;i>a;i--)i-a>=this.B&&(l=b(u,o,g,r,a),c=p.substring(a,i),h(this,d,c,l,e,s));break}case"reverse":if(1<r){for(i=r-1;0<i;i--)c=p[i]+c,c.length>=this.B&&h(this,d,c,b(u,o,g,r,i),e,s);c=""}case"forward":if(1<r){for(i=0;i<r;i++)c+=p[i],c.length>=this.B&&h(this,d,c,a,e,s);break}default:if(this.C&&(a=Math.min(a/this.C(t,p,g)|0,u-1)),h(this,d,p,a,e,s),m&&1<o&&g<o-1)for(r=n(),c=this.A,a=p,i=Math.min(m+1,o-g),r[a]=1,l=1;l<i;l++)if((p=t[this.F?o-1-g-l:g+l])&&p.length>=this.B&&!r[p]){r[p]=1;const t=this.l&&p>a;h(this,f,t?a:p,b(c+(o/2>c?0:1),o,g,i-1,l-1),e,s,t?p:a)}}}}this.m||(this.register[e]=1)}}return this};function b(e,t,n,s,o){return n&&1<e?t+(s||0)<=e?n+(o||0):(e-1)/(t+(s||0))*(n+(o||0))+1|0:0}function h(e,t,s,o,i,a,r){let c=r?e.h:e.map;(!t[s]||r&&!t[s][r])&&(e.s&&(c=c[o]),r?(t=t[s]||(t[s]=n()),t[r]=1,c=c[r]||(c[r]=n())):t[s]=1,c=c[s]||(c[s]=[]),e.s||(c=c[o]||(c[o]=[])),a&&c.includes(i)||(c[c.length]=i,e.m&&(e=e.register[i]||(e.register[i]=[]),e[e.length]=c)))}s.search=function(e,t,s){s||(!t&&a(e)?(s=e,e=s.query):a(t)&&(s=t));let i=[],o,r,d=0;if(s){e=s.query||e,t=s.limit,d=s.offset||0;var l,c=s.context;r=s.suggest}if(e&&(e=this.encode(""+e),o=e.length,1<o)){s=n(),l=[];for(let n=0,a=0,t;n<o;n++)if((t=e[n])&&t.length>=this.B&&!s[t])if(this.s||r||this.map[t])l[a++]=t,s[t]=1;else return i;e=l,o=e.length}if(!o)return i;t||(t=100),c=this.depth&&1<o&&!1!==c,s=0;let u;c?(u=e[0],s=1):1<o&&e.sort(re);for(let n,a;s<o;s++){if(a=e[s],c?(n=E(this,i,r,t,d,2===o,a,u),r&&!1===n&&i.length||(u=a)):n=E(this,i,r,t,d,1===o,a),n)return n;if(r&&s===o-1){if(l=i.length,!l){if(c){c=0,s=-1;continue}return i}if(1===l)return z(i[0],t,d)}}return F(i,t,d,r)};function E(e,t,n,s,o,i,a,r){let l=[],c=r?e.h:e.map;if(e.s||(c=D(c,a,r,e.l)),c){let n=0;const d=Math.min(c.length,r?e.A:e.D);for(let u=0,m=0,t,h;u<d;u++)if((t=c[u])&&(e.s&&(t=D(t,a,r,e.l)),o&&t&&i&&(h=t.length,h<=o?(o-=h,t=null):(t=t.slice(o),o=0)),t&&(l[n++]=t,i&&(m+=t.length,m>=s))))break;if(n){if(i)return z(l,s,0);t[t.length]=l;return}}return!n&&l}function z(e,t,n){return e=1===e.length?e[0]:[].concat.apply([],e),n||e.length>t?e.slice(n,n+t):e}function D(e,t,n,s){return n?(s=s&&t>n,e=(e=e[s?t:n])&&e[s?n:t]):e=e[t],e}s.contain=function(e){return!!this.register[e]},s.update=function(e,t){return this.remove(e).add(e,t)},s.remove=function(e,t){const n=this.register[e];if(n){if(this.m)for(let t=0,s;t<n.length;t++)s=n[t],s.splice(s.indexOf(e),1);else p(this.map,e,this.D,this.s),this.depth&&p(this.h,e,this.A,this.s);if(t||delete this.register[e],this.cache){t=this.cache;for(let n=0,o,s;n<t.h.length;n++)s=t.h[n],o=t.cache[s],o.includes(e)&&(t.h.splice(n--,1),delete t.cache[s])}}return this};function p(e,t,n,s,o){let i=0;if(e.constructor===Array)if(o)t=e.indexOf(t),-1!==t?1<e.length&&(e.splice(t,1),i++):i++;else{o=Math.min(e.length,n);for(let a=0,r;a<o;a++)(r=e[a])&&(i=p(r,t,n,s,o),s||i||delete e[a])}else for(let a in e)(i=p(e[a],t,n,s,o))||delete e[a];return i}s.searchCache=S,s.export=function(e,t,s,o,i,a){let l=!0;"undefined"==typeof a&&(l=new Promise(e=>{a=e}));let c,r;switch(i||(i=0)){case 0:if(c="reg",this.m){r=n();for(let e in this.register)r[e]=1}else r=this.register;break;case 1:c="cfg",r={doc:0,opt:this.s?1:0};break;case 2:c="map",r=this.map;break;case 3:c="ctx",r=this.h;break;default:"undefined"==typeof s&&a&&a();return}return A(e,t||this,s,c,o,i,r,a),l},s.import=function(e,t){if(t)switch(i(t)&&(t=JSON.parse(t)),e){case"cfg":this.s=!!t.opt;break;case"reg":this.m=!1,this.register=t;break;case"map":this.map=t;break;case"ctx":this.h=t}},T(c.prototype);function oe(e){e=e.data;var n,s=t._index;const o=e.args;switch(n=e.task,n){case"init":n=e.options||{},e=e.factory,s=n.encode,n.cache=!1,s&&0===s.indexOf("function")&&(n.encode=Function("return "+s)()),e?(Function("return "+e)()(t),t._index=new t.FlexSearch.Index(n),delete t.FlexSearch):t._index=new c(n);break;default:e=e.id,s=s[n].apply(s,o),postMessage("search"===n?{id:e,msg:s}:{id:e})}}let R=0;function l(e){if(!(this instanceof l))return new l(e);var s;e?x(s=e.encode)&&(e.encode=s.toString()):e={},(s=(t||window)._factory)&&(s=s.toString());const i="undefined"==typeof window&&t.exports,o=this;this.o=G(s,i,e.worker),this.h=n(),this.o&&(i?this.o.on("message",function(e){o.h[e.id](e.msg),delete o.h[e.id]}):this.o.onmessage=function(e){e=e.data,o.h[e.id](e.msg),delete o.h[e.id]},this.o.postMessage({task:"init",factory:s,options:e}))}u("add"),u("append"),u("search"),u("update"),u("remove");function u(e){l.prototype[e]=l.prototype[e+"Async"]=function(){const o=this,t=[].slice.call(arguments);var n=t[t.length-1];let s;return x(n)&&(s=n,t.splice(t.length-1,1)),n=new Promise(function(n){setTimeout(function(){o.h[++R]=n,o.o.postMessage({task:e,id:R,args:t})})}),s?(n.then(s),this):n}}function G(e,t,n){let s;try{s=t?new(require("worker_threads").Worker)(__dirname+"/node/node.js"):e?new Worker(URL.createObjectURL(new Blob(["onmessage="+oe.toString()],{type:"text/javascript"}))):new Worker(i(n)?n:"worker/worker.js",{type:"module"})}catch{}return s}function d(e){if(!(this instanceof d))return new d(e);var t,s=e.document||e.doc||e;this.K=[],this.h=[],this.A=[],this.register=n(),this.key=(t=s.key||s.id)&&v(t,this.A)||"id",this.m=g(e.fastupdate),this.C=(t=s.store)&&!0!==t&&[],this.store=t&&n(),this.I=(t=s.tag)&&v(t,this.A),this.l=t&&n(),this.cache=(t=e.cache)&&new j(t),e.cache=!1,this.o=e.worker,this.async=!1,t=n();let o=s.index||s.field||s;i(o)&&(o=[o]);for(let r=0,n,s;r<o.length;r++)n=o[r],i(n)||(s=n,n=n.field),s=a(s)?Object.assign({},e,s):e,this.o&&(t[n]=new l(s),t[n].o||(this.o=!1)),this.o||(t[n]=new c(s,this.register)),this.K[r]=v(n,this.A),this.h[r]=n;if(this.C)for(e=s.store,i(e)&&(e=[e]),s=0;s<e.length;s++)this.C[s]=v(e[s],this.A);this.index=t}function v(e,t){const n=e.split(":");let s=0;for(let o=0;o<n.length;o++)e=n[o],0<=e.indexOf("[]")&&(e=e.substring(0,e.length-2))&&(t[s]=!0),e&&(n[s++]=e);return s<n.length&&(n.length=s),1<s?n:n[0]}function C(e,t){if(i(t))e=e[t];else for(let n=0;e&&n<t.length;n++)e=e[t[n]];return e}function w(e,t,s,o,i){if(e=e[i],o===s.length-1)t[i]=e;else if(e)if(e.constructor===Array)for(t=t[i]=Array(e.length),i=0;i<e.length;i++)w(e,t,s,o,i);else t=t[i]||(t[i]=n()),i=s[++o],w(e,t,s,o,i)}function O(e,t,n,s,o,i,a,r){if(e=e[a])if(s===t.length-1){if(e.constructor===Array){if(n[s]){for(t=0;t<e.length;t++)o.add(i,e[t],!0,!0);return}e=e.join(" ")}o.add(i,e,r,!0)}else if(e.constructor===Array)for(a=0;a<e.length;a++)O(e,t,n,s,o,i,a,r);else a=t[++s],O(e,t,n,s,o,i,a,r)}s=d.prototype,s.add=function(e,t,s){if(a(e)&&(t=e,e=C(t,this.key)),t&&(e||0===e)){if(!s&&this.register[e])return this.update(e,t);for(let o=0,n,a;o<this.h.length;o++)a=this.h[o],n=this.K[o],i(n)&&(n=[n]),O(t,n,this.A,0,this.index[a],e,n[0],s);if(this.I){let o=C(t,this.I),a=n();i(o)&&(o=[o]);for(let i=0,t,n;i<o.length;i++)if(t=o[i],!a[t]&&(a[t]=1,n=this.l[t]||(this.l[t]=[]),!s||!n.includes(e))&&(n[n.length]=e,this.m)){const t=this.register[e]||(this.register[e]=[]);t[t.length]=n}}if(this.store&&(!s||!this.store[e])){let s;if(this.C){s=n();for(let n=0,e;n<this.C.length;n++)e=this.C[n],i(e)?s[e]=t[e]:w(t,s,e,0,e[0])}this.store[e]=s||t}}return this},s.append=function(e,t){return this.add(e,t,!0)},s.update=function(e,t){return this.remove(e).add(e,t)},s.remove=function(e){if(a(e)&&(e=C(e,this.key)),this.register[e]){for(var t=0;t<this.h.length&&(this.index[this.h[t]].remove(e,!this.o),!this.m);t++);if(this.I&&!this.m)for(let n in this.l){t=this.l[n];const s=t.indexOf(e);-1!==s&&(1<t.length?t.splice(s,1):delete this.l[n])}this.store&&delete this.store[e],delete this.register[e]}return this},s.search=function(e,t,n,s){n||(!t&&a(e)?(n=e,e=""):a(t)&&(n=t,t=0));let c=[],m=[],f,d,r,o,l,p,u=0;if(n)if(n.constructor===Array)r=n,n=null;else{if(e=n.query||e,r=(f=n.pluck)||n.index||n.field,o=n.tag,d=this.store&&n.enrich,l="and"===n.bool,t=n.limit||t||100,p=n.offset||0,o&&(i(o)&&(o=[o]),!e)){for(let e=0,n;e<o.length;e++)(n=te.call(this,o[e],t,p,d))&&(c[c.length]=n,u++);return u?c:[]}i(r)&&(r=[r])}r||(r=this.h),l=l&&(1<r.length||o&&1<o.length);const h=!s&&(this.o||this.async)&&[];for(let v=0,a,f,b;v<r.length;v++){let g;if(f=r[v],i(f)||(g=f,f=g.field,e=g.query||e,t=g.limit||t,d=g.enrich||d),h)h[v]=this.index[f].searchAsync(e,t,g||n);else{if(s?a=s[v]:a=this.index[f].search(e,t,g||n),b=a&&a.length,o&&b){const e=[];let n=0;l&&(e[0]=[a]);for(let s=0,i,t;s<o.length;s++)(i=o[s],b=(t=this.l[i])&&t.length)&&(n++,e[e.length]=l?[t]:t);n&&(a=l?F(e,t||100,p||0):ce(a,e),b=a.length)}if(b)m[u]=f,c[u++]=a;else if(l)return[]}}if(h){const s=this;return new Promise(function(o){Promise.all(h).then(function(i){o(s.search(e,t,n,i))})})}if(!u)return[];if(f&&(!d||!this.store))return c[0];for(let t=0,e;t<m.length;t++){if(e=c[t],e.length&&d&&(e=q.call(this,e)),f)return e;c[t]={field:m[t],result:e}}return c};function te(e,t,n,s){let o=this.l[e],i=o&&o.length-n;if(i&&0<i)return(i>t||n)&&(o=o.slice(n,n+t)),s&&(o=q.call(this,o)),{tag:e,result:o}}function q(e){const t=Array(e.length);for(let n=0,s;n<e.length;n++)s=e[n],t[n]={id:s,doc:this.store[s]};return t}s.contain=function(e){return!!this.register[e]},s.get=function(e){return this.store[e]},s.set=function(e,t){return this.store[e]=t,this},s.searchCache=S,s.export=function(e,t,n,s,o,i){let a;if("undefined"==typeof i&&(a=new Promise(e=>{i=e})),o||(o=0),s||(s=0),s<this.h.length){const n=this.h[s],a=this.index[n];t=this,setTimeout(function(){a.export(e,t,o?n:"",s,o++,i)||(s++,o=1,t.export(e,t,n,s,o,i))})}else{let t,a;switch(o){case 1:t="tag",a=this.l,n=null;break;case 2:t="store",a=this.store,n=null;break;default:i();return}A(e,this,n,t,s,o,a,i)}return a},s.import=function(e,t){if(t)switch(i(t)&&(t=JSON.parse(t)),e){case"tag":this.l=t;break;case"reg":this.m=!1,this.register=t;for(let e=0,n;e<this.h.length;e++)n=this.index[this.h[e]],n.register=t,n.m=!1;break;case"store":this.store=t;break;default:e=e.split(".");const n=e[0];e=e[1],n&&e&&this.index[n].import(e,t)}},T(d.prototype),Y={encode:K,F:!1,G:""};const X=[o("[]"),"a",o("[]"),"e",o("[]"),"i",o("[]"),"o",o("[]"),"u",o("[]"),"y",o(""),"n",o("[c]"),"k",o(""),"s",o(" & ")," and "];function K(e){var t=e=""+e;return t.normalize&&(t=t.normalize("NFD").replace(J,"")),U.call(this,t.toLowerCase(),!e.normalize&&X)}W={encode:k,F:!1,G:"strict"};const Z=/[^a-z0-9]+/,$={b:"p",v:"f",w:"f",z:"s",x:"s","":"s",d:"t",n:"m",c:"k",g:"k",j:"k",q:"k",i:"e",y:"e",u:"o"};function k(e){e=K.call(this,e).join(" ");const t=[];if(e){const n=e.split(Z),s=n.length;for(let i=0,o,a=0;i<s;i++)if((e=n[i])&&(!this.filter||!this.filter[e])){o=e[0];let n=$[o]||o,s=n;for(let i=1;i<e.length;i++){o=e[i];const t=$[o]||o;t&&t!==s&&(n+=t,s=t)}t[a++]=n}}return t}I={encode:H,F:!1,G:""};const ne=[o("ae"),"a",o("oe"),"o",o("sh"),"s",o("th"),"t",o("ph"),"f",o("pf"),"f",o("(?![aeo])h(?![aeo])"),"",o("(?!^[aeo])h(?!^[aeo])"),""];function H(e,t){return e&&(e=k.call(this,e).join(" "),2<e.length&&(e=f(e,ne)),t||(1<e.length&&(e=B(e)),e&&(e=e.split(" ")))),e||[]}L={encode:ae,F:!1,G:""};const se=o("(?!\\b)[aeo]");function ae(e){return e&&(e=H.call(this,e,!0),1<e.length&&(e=e.replace(se,"")),1<e.length&&(e=B(e)),e&&(e=e.split(" "))),e||[]}r["latin:default"]=ie,r["latin:simple"]=Y,r["latin:balance"]=W,r["latin:advanced"]=I,r["latin:extra"]=L;const _={Index:c,Document:d,Worker:l,registerCharset:function(e,t){r[e]=t},registerLanguage:function(e,t){N[e]=t}};let y;(y=t.define)&&y.amd?y([],function(){return _}):t.exports?t.exports=_:t.FlexSearch=_}(this);const search=document.querySelector(".search-input"),suggestions=document.querySelector(".search-suggestions"),background=document.querySelector(".search-background");var index=new FlexSearch.Document({tokenize:"forward",cache:100,document:{id:"id",tag:"tag",store:["href","title","description"],index:["title","description","content"]}});function initIndex(){index.add({id:0,tag:"en",href:"/blogs/agents/",title:"Agents ",description:"Agents  MetaGPT/ChatDEV/AutoGen",content:`LLM Powered Autonomous Agents
 LLM  agent , LLM agent 3

: Agent
: Agent


in-context learning
context, prompt
Agent

Agent API.
agent
agentagentagent
MetaGPT MetaGPT 
MetaGPT ProductManager, Architect, ProjectManager, Engineer, QA Engineer

  Software Company

Company hire
Agent AgentAgentQA
 Agent 
Init actions agent  actions
Watch agent action actionagent
Example
 actions  prd  boss 
Invest

Start project

Run
 Company hire  Agent 
Product ManagerRequirement Analysis ArchitectArchitectural Design Project Manager  System Design EngineerCoding  QA EngineerTesting Agent  %% width=60% flowchart TD Agent["Agent"] --> LLM["LLM"] Agent["Agent"] --> Setting["Setting
(Agent)"] Agent --> States["States
[[index, action]]"] Agent --> Actions["Actions
[action]"] Agent --> RoleContext["RoleContext:
(Agent)"] 
LLM Agent
SettingAgent 
name profile goal constraints desc Statesaction  agent 
Actionsagentactions
WriteCode WriteCodeReview WritePRD WriteDesign WriteTasks   agent  actionprd 
RoleContext
agent
Environment
Memory
Index: agent: message Storage: [message] Long term Memory
MemoryStorage (FaissStore) State int agent  actions list action
Todo Agent  action
WatchAgent  actions
News Agent 
Agent %% width=60% graph LR Watch["watch
()"] --> Observe["observe"] Observe --> Think["think
(set state)"] Think --> Act["act"] Act --> Publish["publish message"] Watch
 RoleContext  watchagentaction
 agent  RoleContext  agent  actionagent action  action  agent 
 RoleContext 
RoleContext
observe
 news  think
 news  state  state  Todo list
act
 Todo list LLM  responsemessage memory
publish message
 message memory
Example
     QA ChatDev ChatDev 
ChatDev phase, 
ChatDEV  phase-level  chat-level
phase-level  44  Designing Coding Testing Documenting
chat-level   atomic chats agents  instruction-followingchatagents

 ChatChain

agent
Start Chatting
Phase
%% width=20% graph LR Phase["Phase"] --> Assistant["Assistant role"] Phase --> User["User role"] Phase --> Prompt["Phase prompt"] Phase --> Name["Phase name"] DemandAnalysis LanguageChoose Coding ArtDesign ArtIntegration CodeComplete CodeReviewComment CodeReviewModification CodeReviewHuman TestErrorSummary TestModification EnvironmentDoc Manual Chat Role specialization 
agent
Memory stream 
agent
Self-reflection 
assistant
%% width=30% graph LR subgraph Interaction User((User Role)) <--> Assistant((Assistant Role)) end Interaction -->|seminar conclusion| C[RES] Phase promptphaseprompt config 
Assistant role / User role :  Chat Agent 
system messageAssistant agent  User agent terminal signal  
self reflection seminar conclusion  Agent  System message System 
Content : prompt Chatdev prompt+role prompt Meta dict Assistant_role Chatdev prompt Task User role Role: system Role name: Agent name Agent LLM 
Model config / backendLLM 
Stored messages: Agent
ChatDev  agent Role name /Role type
Chief Executive Officer Chief Product Officer Counselor Chief Technology Officer Chief Human Resource Officer Programmer Code Reviewer Software Test Engineer Chief Creative Officer AutoGen AutoGen Agent LLMAgent
AutoGen AgentLLM
AutoGenLLMAgentAgentAgent
AutoGen Conversable Agent Conversable Agent  33  Agent
Assistant Agent  UserProxy Agent
Assistant Agent: LLM UserProxy Agent:  Group Chat Manager
 group chatagentagent
Agent 
System message agent prompt Llm config LLM  Max consecutive auto reply  Human input mode AssistantneverUser Proxy always flowchart LR A[Agent] --> B[Conversable Agent] B --> C[Assistant Agent] B --> D[User Proxy Agent] B --> E[Group Chat Manager] AutoGenAutoGen
Example
AutoGen 2 agents chatting META TESLA  2 agents Reference LLM Powered Autonomous Agents MetaGPT: Meta Programming for A Multi-Agent Collaborative Framework ChatDev: Communicative Agents for Software Development AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation`}).add({id:1,tag:"en",href:"/blogs/flashattention/",title:"FlashAttention",description:"FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness",content:`Background Structure of GPU Memory  GPU memory  CPU memory  level   
HBM GPU memory  high bandwidth memory (HBM)
A100  HBM  4040 GB~ 8080 GB HBM bandwidth 1.51.5  2.02.0 TB/s SRAM memory  SRAM
 192KB108192 \\textKB \\times 108 (streaming multi-processors)  bandwidth  1919 TB/s  HBM  HBM  bottleneck
 GPU  threads (kernel)  operation  HBM  SRAM  output  HBM 
 operation  memory  operations  compute-bound  memory-bound
Compute-bound  operation HBM    channel  convolution Memory-bound memory  element-wise (eg, activation, dropout) reduction (eg, sum, softmax, batch norm, layer norm)  memory-bound Attention  Attention  NN  kk hidden size dd : head dimension 
 XRNk\\mathbf X\\in \\mathbbR^N\\times k  WQ\\mathbf W^Q  WK\\mathbf W^K  WV\\mathbf W^V Rkd\\in \\mathbbR^k\\times d  Q\\mathbf Q  K\\mathbf K  V\\mathbf V RNd\\in \\mathbbR^N\\times d   O(3Nkd)O(3Nkd)  
 Q\\mathbf Q  K\\mathbf K  QKRNN\\mathbf Q \\mathbf K^\\top\\in \\mathbbR^N\\times N  O(NNd)O(NNd)  Softmax: : O(N2)O(N^2) 
 Softmax  V\\mathbf V   O(N2d)O(N^2d)   NdN \\gg d GPT2 N=1024N=1024  d=64d=64  O(N2d)O(N^2d) FlashAttention Tiling and Recomputation FlashAttention  GPU  I/O 
 SRAM   HBM    Softmax 
 Attention Softmax  V\\mathbf V  Q\\mathbf Q  K\\mathbf K   Softmax  V\\mathbf V   FlashAttention    Softmax 
Tiling ()- NNN \\times N softmax/scores  Recomputation () Tiling  Theorem 1
FlashAttention  O(N2d)O(N^2d) FLOPs  O=softmax(QK)VO=\\mathrmsoftmax(\\mathbf Q \\mathbf K^\\top)\\mathbf V  O(N)O(N) 
: Q,K,V\\mathbf Q,\\mathbf K,\\mathbf V RNd\\in \\mathbbR^N\\times d HBMGPU  SRAM   MM : O\\mathbf O   block size block  Bc=[M4d]B_c =[\\fracM4d] block  Br=min([M4d],d)B_r = \\min \\big([\\fracM4d], d \\big) min\\min  BcBr&gt;M4B_c \\times B_r &gt; \\fracM4 ,  44  SRAM
HBM  O=[0]NdRNd\\mathbf O = \\beginbmatrix0\\endbmatrix_N \\times d \\in \\mathbbR^N\\times d  O\\mathbf O  00  l=[0]NRN\\mathbf l = \\beginbmatrix0\\endbmatrix_N\\in \\mathbbR^N  NN  l\\mathbf l  NN  m=[]NRN\\mathbf m= \\beginbmatrix- \\infty\\endbmatrix_N \\in \\mathbbR^N  m\\mathbf m   NN  -\\infty  max\\max   Q\\mathbf Q  K\\mathbf K  V\\mathbf V  Q\\mathbf Q  Tr=[NBr]T_r = [\\fracNB_r]  Q1,,QTr\\mathbf Q_1, \\cdots , \\mathbf Q_T_r  QiRBrd\\mathbf Q_i\\in \\mathbbR^B_r\\times d Qi=(Qi11Qi12Qi1dQi21Qi22Qi2dQiBr1QiBr2QiBrd) \\mathbf Q_i =\\beginpmatrix Q_i_11 &amp; Q_i_12 &amp; \\ldots &amp; Q_i_1d \\\\ Q_i_21 &amp; Q_i_22 &amp; \\ldots &amp; Q_i_2d\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ Q_i_B_r1 &amp; Q_i_B_r2 &amp; \\ldots &amp; Q_i_B_rd\\\\ \\endpmatrix  K\\mathbf K  Tc=[NBc]T_c = [\\fracNB_c]  K1,,KTc\\mathbf K_1, \\cdots , \\mathbf K_T_c  KjRBcd\\mathbf K_j\\in \\mathbbR^B_c\\times d KjT=(K1j1K1j2K1jBcK2j1K2j2K2jBcKdj1Kdj2KdjBc) \\mathbf K_j^T =\\beginpmatrix K_1j_1 &amp; K_1j_2 &amp; \\ldots &amp; K_1j_B_c \\\\ K_2j_1 &amp; K_2j_2&amp; \\ldots &amp; K_2j_B_c\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ K_dj_1 &amp; K_dj_2 &amp; \\ldots &amp; K_dj_B_c\\\\ \\endpmatrix  V\\mathbf V  Tc=[NBc]T_c = [\\fracNB_c]  V1,,VTc\\mathbf V_1, \\cdots , \\mathbf V_T_c  VjRBcd\\mathbf V_j\\in \\mathbbR^B_c\\times d Vj=(Vj11Vj12Vj1dVj21Vj22Vj2dVjBc1VjBc2VjBcd) \\mathbf V_j =\\beginpmatrix V_j_11 &amp; V_j_12 &amp; \\ldots &amp; V_j_1d \\\\ V_j_21 &amp; V_j_22&amp; \\ldots &amp; V_j_2d\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ V_j_B_c1 &amp; V_j_B_c2 &amp; \\ldots &amp; V_j_B_cd\\\\ \\endpmatrix  O\\mathbf O  l\\mathbf l  m\\mathbf m  O\\mathbf O  Tr=[MBr]T_r = [\\fracMB_r]  O1,,OTr\\mathbf O_1, \\cdots , \\mathbf O_T_r  OiRBrd\\mathbf O_i\\in \\mathbbR^B_r\\times d  l\\mathbf l  Tr=[MBr]T_r = [\\fracMB_r]  l1,,lTr\\mathbf l_1, \\cdots , \\mathbf l_T_r  liRBr\\mathbf l_i\\in \\mathbbR^B_r l=(l1lilTr),li=(li1liBr) \\mathbf l =\\beginpmatrix \\mathbf l_1\\\\ \\vdots \\\\ \\mathbf l_i \\\\ \\vdots \\\\ \\mathbf l_T_r\\\\ \\endpmatrix , \\quad \\mathbf l_i = \\beginpmatrix l_i_1\\\\ \\vdots \\\\ l_i_B_r\\\\ \\endpmatrix  m\\mathbf m  Tr=[MBr]T_r = [\\fracMB_r]  m1,,mTr\\mathbf m_1, \\cdots , \\mathbf m_T_r  miRBrm_i\\in \\mathbbR^B_r m=(m1mimTr),mi=(mi1miBr) \\mathbf m =\\beginpmatrix \\mathbf m_1\\\\ \\vdots \\\\ \\mathbf m_i \\\\ \\vdots \\\\ \\mathbf m_T_r\\\\ \\endpmatrix , \\quad \\mathbf m_i = \\beginpmatrix m_i_1\\\\ \\vdots \\\\ m_i_B_r\\\\ \\endpmatrix  for j=1j = 1 to TcT_c do 
 Kj\\mathbf K_j  Vj\\mathbf V_j  HBM  SRAM
for i=1i = 1 to TrT_r do 
 Qi\\mathbf Q_i  Oi\\mathbf O_i  li\\mathbf l_i  mi\\mathbf m_i  HBM  SRAM
  m~i\\mathbf \\tildem_i  l~i\\mathbf\\tildel_i Sij=QiKjTRBrBc\\mathbf S_ij = \\mathbfQ_i\\mathbfK_j^T \\in \\mathbbR^B_r\\times B_c Sij=(Si1j1Si1j2Si1jBcSi2j1Si2j2Si2jBcSiBrj1SiBrj2SiBrjBc) \\mathbf S_ij =\\beginpmatrix S_i_1j_1 &amp; S_i_1j_2&amp; \\ldots &amp; S_i_1j_B_c\\\\ S_i_2j_1 &amp; S_i_2j_2 &amp; \\ldots &amp; S_i_2j_B_c\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ S_i_B_rj_1 &amp; S_i_B_rj_2 &amp; \\ldots &amp; S_i_B_rj_B_c\\\\ \\endpmatrix  Sinjm=Qin1K1jm+Qin2K2jm++QindKdjmS_i_nj_m = Q_i_n1K_1j_m + Q_i_n2K_2j_m + \\ldots + Q_i_ndK_dj_m m~ij=rowmax(Sij)RBr\\mathbf\\tildem_ij = \\mathrmrowmax (\\mathbf S_ij) \\in \\mathbbR^B_r : m~ij\\mathbf\\tildem_ij  m~ij=(m~i1jm~i2jm~iBrj) \\mathbf\\tildem_ij =\\beginpmatrix \\tildem_i_1j\\\\ \\tildem_i_2j \\\\ \\vdots \\\\ \\tildem_i_B_rj\\\\ \\endpmatrix  m~ikj=max[Sikj1Sikj2SikjBc]\\tildem_i_kj = \\max \\Big\\ \\big[\\beginmatrix S_i_kj_1 &amp; S_i_kj_2&amp; \\ldots &amp; S_i_kj_B_c\\endmatrix \\big] \\Big\\ P~ij=exp(Sijm~ij)RBrBc\\mathbf\\tildeP_ij =\\exp(S_ij - \\tildem_ij) \\in \\mathbbR^B_r \\times B_c  P~ij\\mathbf \\tildeP_ij  Sij\\mathbf S_ij  ii  m~ij\\mathbf\\tildem_ij ( jj  jj  P~ij=exp((Si1j1m~i1jSi1j2m~i1jSi1jBcm~i1jSi2j1m~i2jSi2j2m~i2jSi2jBcm~i2jSiBrj1m~iBrjSiBrj2m~iBrjSiBrjBcm~iBrj))=exp((P~i1j1P~i1j2P~i1jBcP~i2j1P~i2j2P~i2jBcP~iBrj1P~iBrj2P~iBrjBc)) \\mathbf \\tildeP_ij =\\exp \\big( \\beginpmatrix S_i_1j_1-\\tildem_i_1j&amp; S_i_1j_2-\\tildem_i_1j &amp; \\ldots &amp; S_i_1j_B_c-\\tildem_i_1j\\\\ S_i_2j_1-\\tildem_i_2j &amp; S_i_2j_2-\\tildem_i_2j &amp; \\ldots &amp; S_i_2j_B_c-\\tildem_i_2j\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ S_i_B_rj_1-\\tildem_i_B_rj &amp; S_i_B_rj_2-\\tildem_i_B_rj &amp; \\ldots &amp; S_i_B_rj_B_c-\\tildem_i_B_rj\\\\ \\endpmatrix \\big) = \\exp\\big( \\beginpmatrix \\tildeP_i_1j_1 &amp; \\tildeP_i_1j_2&amp; \\ldots &amp; \\tildeP_i_1j_B_c\\\\ \\tildeP_i_2j_1 &amp; \\tildeP_i_2j_2 &amp; \\ldots &amp; \\tildeP_i_2j_B_c\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ \\tildeP_i_B_rj_1 &amp; \\tildeP_i_B_rj_2 &amp; \\ldots &amp; \\tildeP_i_B_rj_B_c\\\\ \\endpmatrix \\big) l~ij=rowsum(P~ij)RBr\\mathbf\\tildel_ij = \\mathrmrowsum (\\tilde P_ij) \\in \\mathbbR^B_r  l~ij\\mathbf\\tildel_ij  P~ij\\mathbf\\tildeP_ij  l~ij=(l~i1jl~i2jl~iBrj) \\mathbf\\tildel_ij =\\beginpmatrix \\tildel_i_1j\\\\ \\tildel_i_2j \\\\ \\vdots \\\\ \\tildel_i_B_rj\\\\ \\endpmatrix  l~ikj=jn[j1,jBc]P~ikjn\\tildel_i_kj = \\sum_j_n \\in[j_1, j_B_c] \\tilde P_i_kj_n  mi\\mathbf m_i  li\\mathbf l_i 
minew=mij=max(mij1,m~ij)RBr\\mathbf m^\\mathrm new_i = \\mathbf m_ij=\\max(\\mathbf m_ij-1, \\mathbf\\tildem_ij ) \\in \\mathbbR^B_r   jj  jj 
minew=mij=(max[mi1j1,m~i1j]max[miBrj1,m~iBrj]) \\mathbf m_i^\\textnew = \\mathbf m_ij= \\beginpmatrix \\max\\big[m_i_1j-1  ,&amp;\\tildem_i_1j\\big]\\\\ \\vdots \\\\ \\max\\big [m_i_B_rj-1  ,&amp;\\tildem_i_B_rj\\big]\\\\ \\endpmatrix linew=lij=emiminewlij1+em~ijminewl~ijRBr\\mathbf l^\\mathrm new_i = \\mathbf l_ij = e^\\mathbf m_i-\\mathbf m^\\mathrm new_i \\mathbf l_ij-1 + e^\\mathbf\\tilde m_ij-\\mathbf m^\\mathrm new_i\\mathbf \\tilde l_ij \\in \\mathbbR^B_r  jj  jj 
 Odiag(linew)1(3)(diag(li)emiminewOi(1)+em~iminewP~ijVij(2))\\mathbf O\\leftarrow \\underbrace\\mathrmdiag(\\mathbf l^\\mathrm new_i)^-1_(3) \\bigg(\\underbrace\\mathrmdiag(\\mathbf l_i)e^\\mathbf m_i-\\mathbf m^\\mathrm new_i\\mathbf O_i_(1) + \\underbracee^\\mathbf\\tilde m_i-\\mathbf m^\\mathrm new_i \\mathbf\\tilde P_ij\\mathbf V_ij_(2)\\bigg)  HBM  P~ijVijRBrd\\mathbf\\tildeP_ij \\mathbfV_ij \\in \\mathbbR^B_r\\times d (1) Oin\\mathbf O_i_n  softmax li\\mathbf l_i  PV\\mathbf P\\mathbf V ,  emiminewe^\\mathbf m_i-\\mathbf m^\\mathrm new_i  PV\\mathbf P\\mathbf V (2)  em~iminewP~ijVije^\\mathbf \\tilde m_i-\\mathbf m^\\mathrm new_i \\mathbf\\tilde P_ij\\mathbf V_ij  PV\\mathbf P \\mathbf V (3) (1)+(2)  PV\\mathbf P \\mathbf V  linew\\mathbf l_i^\\textnew  O\\mathbf O  lilinew\\mathbf l_i \\leftarrow \\mathbf l^\\mathrmnew_i  miminew\\mathbf m_i \\leftarrow \\mathbf m^\\mathrmnew_i  HBM 
:
li=[li1liBr]RBr l_i = \\big[ \\beginmatrix l_i_1 &amp;\\cdots &amp; l_i_B_r \\endmatrix\\big]\\in \\mathbbR^B_r diag(li)=(li1000li2000liBr) \\beginequation \\mathrmdiag(l_i)= \\left( \\beginarraycccc l_i_1 &amp; 0 &amp; \\ldots &amp; 0 \\\\ 0 &amp; l_i_2 &amp; \\ldots &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ 0 &amp; 0 &amp; \\ldots &amp; l_i_B_r \\\\ \\endarray \\right) \\endequation (l1000l2000lBr)(Oi11Oi12Oi1dOi21Oi22Oi2dOiBr1OiBr2OiBrd)=(l1Oi11l1Oi12l1Oi1dl2Oi21l2Oi22l2Oi2dlBrOiBr1lBrOiBr2lBrOiBrd) \\beginpmatrix l_1 &amp; 0 &amp; \\ldots &amp; 0 \\\\ 0 &amp; l_2 &amp; \\ldots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ 0 &amp; 0 &amp; \\ldots &amp; l_B_r\\\\ \\endpmatrix \\times \\ \\beginpmatrix O_i_11 &amp; O_i_12 &amp; \\ldots &amp; O_i_1d \\\\ O_i_21 &amp; O_i_22 &amp; \\ldots &amp; O_i2d\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ O_i_B_r1 &amp; O_i_B_r2 &amp; \\ldots &amp; O_i_B_rd\\\\ \\endpmatrix= \\ \\beginpmatrix l_1 \\times O_i_11 &amp; l_1 \\times O_i_12 &amp; \\ldots &amp; l_1 \\times O_i_1d\\\\ l_2 \\times O_i_21 &amp; l_2 \\times O_i_22 &amp; \\ldots &amp; l_2 \\times O_i2d\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ l_B_r \\times O_i_B_r1 &amp; l_B_r \\times O_i_B_r2 &amp; \\ldots &amp; l_B_r \\times O_i_B_rd \\endpmatrix (l1000l2000lBr)1=(1l10001l20001lBr) \\beginpmatrix l_1 &amp; 0 &amp; \\ldots &amp; 0 \\\\ 0 &amp; l_2 &amp; \\ldots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ 0 &amp; 0 &amp; \\ldots &amp; l_B_r\\\\ \\endpmatrix^-1 = \\beginpmatrix \\frac1l_1 &amp; 0 &amp; \\ldots &amp; 0 \\\\ 0 &amp; \\frac1l_2 &amp; \\ldots &amp; 0\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ 0 &amp; 0 &amp; \\ldots &amp; \\frac1l_B_r\\\\ \\endpmatrix  Softmax 
 XRBX\\in \\mathbbR^B  softmax 
softmax(X):=f(x)l(x)m(x):=maxixif(x):=[ex1m(x)exBm(x)]l(x):=if(x)i \\beginalign \\mathrm softmax(X):&amp;= \\fracf(x)l(x) \\\\ \\\\ m(x): &amp;= \\max_i x_i\\\\ \\\\ f(x): &amp;=\\big [e^x_1-m(x) \\quad \\dots \\quad e^x_B-m(x)\\big]\\\\ \\\\ l(x): &amp;= \\sum_i f(x)_i \\\\ \\endalign   X(1),X(2)RBX^(1), X^(2) \\in \\mathbbR^B   X=[X(1),X(2)]R2BX = [X^(1), X^(2)] \\in \\mathbbR^2B  softmax 
softmax(X):=f(x)l(x)m(x):=m([x(1),x(2)])=max(m(x(1)),m(x(2)))f(x):=[ex(1)m(x)ex(2)m(x)]=[em(x(1))m(x)+x(1)m(x(1))em(x(2))m(x)+x(2)m(x(2))]=[em(x(1))m(x)f(x(1))em(x(2))m(x)f(x(2))]l(x):=if(x)i=em(x(1))m(x)l(x(1))+em(x(2))m(x)l(x(2)) \\beginalign \\mathrmsoftmax(X) &amp;:= \\fracf(x)l(x) \\\\ \\\\ m(x) &amp;:= m([x^(1), x^(2)]) = \\max \\big(m(x^(1)), m(x^(2))) \\\\ \\\\ f(x) &amp;:= \\beginbmatrix e^x^(1) - m(x) &amp; e^x^(2) - m(x) \\endbmatrix \\\\ &amp;= \\beginbmatrix e^m(x^(1)) - m(x) + x^(1) - m(x^(1)) &amp; e^m(x^(2)) - m(x) + x^(2) - m(x^(2)) \\endbmatrix \\\\ &amp;= \\beginbmatrix e^m(x^(1)) - m(x) f(x^(1)) &amp; e^m(x^(2)) - m(x) f(x^(2)) \\endbmatrix \\\\ \\\\ l(x) &amp;:= \\sum_i f(x)_i \\\\ &amp;= e^m(x^(1)) - m(x) l(x^(1)) + e^m(x^(2)) - m(x) l(x^(2)) \\endalign Example1
x=[1,3,2,4]x=[1,3,2,4] x(1)=[1,3]x^(1)=[1,3] m(x(1))=3m(x^(1))=3 f(x(1))=[e2,1]f(x^(1))=[e^-2,1] l(x(1))=(e2+1)l(x^(1))=(e^-2+1) softmax(x(1))=f(x(1))l(x(1))=[e2e2+1,1e2+1]\\mathrmsoftmax (x^(1)) = \\fracf(x^(1))l(x^(1))=[\\frace^-2e^-2+1, \\frac1e^-2+1] x(2)=[2,4]x^(2)=[2,4] m(x(2))=4m(x^(2))=4 f(x(2))=[e2,1]f(x^(2))=[e^-2,1] l(x(2))=(e2+1)l(x^(2))=(e^-2+1) softmax(x(2))=f(x(2))l(x(2))=[e2e2+1,1e2+1]\\mathrmsoftmax (x^(2)) = \\fracf(x^(2))l(x^(2))=[\\frace^-2e^-2+1, \\frac1e^-2+1]  softmax 
m(x)=max(m(x(1)),m(x(2)))=max(3,4)=4m(x) = \\max(m(x^(1)),m(x^(2))) = \\max(3,4) = 4 f(x)=[e34f(x(1)),e44f(x(2))]=[e3,e1,e2,1]f(x) =[e^3-4f(x^(1)) , e^4-4 f(x^(2))] =[e^-3,e^-1, e^-2, 1] l(x)=e34l(x(1))+e44l(x(2))=(e3+e2+e1+1)l(x) =e^3-4 l(x^(1)) + e^4-4 l(x^(2))=(e^-3+e^-2+e^-1+1) softmax(x)=f(x)l(x)=[e3e3+e2+e1+1,e1e3+e2+e1+1,e2e3+e2+e1+1,1e3+e2+e1+1]\\mathrmsoftmax (x) = \\fracf(x)l(x) = [\\frace^-3e^-3+e^-2+e^-1+1, \\frace^-1e^-3+e^-2+e^-1+1, \\frace^-2e^-3+e^-2+e^-1+1, \\frac1e^-3+e^-2+e^-1+1]  softmax(x)\\mathrmsoftmax (x) 

 xx  BB   1  2  3  3   x=[]x=[\\quad]  m(x)=infm(x)=-\\inf , f(x)=[]f(x)=[\\quad] , l(x)=0l(x)=0  Example2
1 2 3 4 5 6 7 8 import torch from torch import softmax s = torch.tensor([0.1, 0.2, 0.3, 0.4]) v = torch.tensor([0.6, 0.7, 0.8, 0.9]) p = softmax(s, dim=-1) # tensor([0.2138, 0.2363, 0.2612, 0.2887]) print(torch.matmul(p, v)) # tensor(0.7625)  block  1 2 3 4 5 6 s1 = torch.tensor([0.1, 0.2]) v1 = torch.tensor([0.6, 0.7]) p1 = torch.softmax(s1, dim=-1) # tensor([0.4750, 0.5250]) output1 = torch.matmul(p1, v1) # tensor(0.6525) sum_exp1 = sum(torch.exp(s1)) # tensor(2.3266)  [0.1,0.2][0.1, 0.2]  exponential summation (softmax ) 2.32662.3266 
 block  1 2 3 4 5 6 s2 = torch.tensor([0.3, 0.4]) v2 = torch.tensor([0.8, 0.9]) p2 = torch.softmax(s2, dim=-1) # tensor([0.4750, 0.5250]) output2 = torch.matmul(p2, v2) # tensor(0.8525) sum_exp2 = sum(torch.exp(s2)) # tensor(2.8417)  [0.3,0.4][0.3, 0.4]  exponential summation ( softmax ) 2.84172.8417  1 output = (output1 * sum_exp1 + output2 * sum_exp2) / (sum_exp1 + sum_exp2) # tensor(0.7625)  block  output  expoential summation  normalization  expoential summation  softmax  (0.65252.3266+0.85252.8417)/(2.3266+2.8417)=0.7625(0.6525*2.3266+0.8525*2.8417)/(2.3266+2.8417)= 0.7625  max value  exponential  overflow
 sub block  exponential summation  sub-block 1  QQ  KK  HBM load  SRAM  O
 O(N2)O(N^2)  (  for loop  QQ  KK ) sub-block   row    M (sub-block ) O(N2)O(N^2) memory 
Recomputation   HBM  HBM Flash Attention 
,  Q\\mathbf Q , K\\mathbf K , V\\mathbf V ,  S\\mathbf S  P\\mathbf P  NNN \\times N  HBM backward  HBM load  SRAM
Flash attention  m(x)\\mathbf m(x)  l(x)\\mathbf l(x)  SRAM  Attention,  S\\mathbf S  P\\mathbf P ,  HBM , 
IO Complexity of FlashAttention Theorem 2
 NN head  dd SRAM  MM  dMNdd\\le M \\le Nd  Attention  O(Nd+N2)O(Nd+N^2)  HBM  FlashAttention  O(N2d2)M)O(\\fracN^2d^2)M)  HBM 
 dd 64~128 MM 100KB  d2Md^2 \\ll M   FlashAttention  Attention 
 Attention  IO   Q\\mathbf Q  K\\mathbf K RNd\\in \\mathbbR^N\\times d   S\\mathbf S RNN\\in \\mathbbR^N\\times N  HBM
 O(Nd+N2)O(Nd + N^2)  HBM 
 HBM   S\\mathbf S RNN\\in \\mathbbR^N\\times N  Softmax   P\\mathbf P RNN\\in \\mathbbR^N\\times N  HBM
 O(N2)O(N^2)  HBM 
 HBM   P\\mathbf P RNN\\in \\mathbbR^N\\times N   V\\mathbf V RNd\\in \\mathbbR^N\\times d   O\\mathbf O RNd\\in \\mathbbR^N\\times d ,  O\\mathbf O  HBM
 O(Nd+N2)O(Nd + N^2)  HBM 
 Attention  HBM  O(N2)O(N^2)  NdN \\gg d (e.g., GPT2, =1024 = 1024 , =64 = 64 )
 P\\mathbf P  S\\mathbf S 
 intermediate activations  backward  gradients operations fuse  operation  SRAM  softmax  sum  operation row  SRAM  FlashAttention  IO   TcT_c  K\\mathbf K  V\\mathbf V  HBM  SRAM  Q\\mathbf Q  O\\mathbf O  TcT_c 
 O(Nd+NdTc)=O(NdTc)O(Nd + NdT_c) = O(NdT_c)  HBM 
 Kj\\mathbf K_j  VjRBcd\\mathbf V_j \\in \\mathbbR^B_c\\times d  SRAM 
Bcd=O(M)Bc=O(Md) \\beginalign B_c \\times d = O(M) \\Leftrightarrow B_c = O(\\fracMd) \\endalign  Qi\\mathbf Q_i  OiRBrd\\mathbf O_i \\in \\mathbbR^B_r\\times d  SRAM 
Brd=O(M)Br=O(Md) \\beginalign B_r \\times d = O(M) \\Leftrightarrow B_r = O(\\fracMd) \\endalign  SijRBrBc\\mathbf S_ij \\in R^B_r \\times B_c  SRAM 
BrBc=O(M) \\beginalign B_rB_c = O(M) \\endalign 
Bc=O(Md),Br=O(min(Md,MBc))=O(min(Md,d)) \\beginalign B_c &amp;= O(\\fracMd), \\\\ B_r &amp;= O\\bigg(\\min(\\fracMd, \\fracMB_c)\\bigg)= O\\bigg(\\min(\\fracMd , d)\\bigg) \\endalign 
Tc=NBc=O(NdM) \\beginalign T_c =\\fracNB_c= O(\\fracNdM) \\endalign  O(NdTc)=O(N2d2)M)O(NdT_c)=O(\\fracN^2d^2)M) Reference FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness`}).add({id:2,tag:"en",href:"/blogs/lsh/",title:"LSH",description:"LSH (Locality-Sensitive Hashing, ) ",content:` Top N 

  (Nearest Neighbor, NN)   (Approximate Nearest Neighbor, ANN) (Locality-Sensitive Hashing, LSH)
Hash Hash   pre-image

 Hash f:keyaddressf: \\mathrmkey \\rightarrow \\mathrmaddress 
LSH Bucket h=xmodwh=x \\mod w 
LSHLocality-Sensitive
LSHBucket
Shingling: (bool )
Min-Hashing: signatures
Locality-Sensitive Hashing
Step 1: Shingling 
 k-shingle k-gram kk  token
token tokens=characters\\mathrmtokens = \\mathrmcharacters  shingles hash 4bytes  k-shingels 
Example:
k=2k=2 ;
Doc D1=abcabD_1= \\mathrmabcab ;
2-shingles set of Doc D1:S(D1)=ab,bc,caD_1: S(D_1)= \\\\mathrmab, \\mathrmbc, \\mathrmca\\ Hash the shingles: h(D1)=1,5,7h(D_1) = \\1, 5, 7\\ k=8,9,10k = 8, 9, 10 is often used in practice
Shingles 
 shingle k-1 k-gram  DiD_i  k-grams  Ci=S(Di)C_i = S(D_i) 
sim(D1,D2)=C1C2C1C2 \\mathrmsim(D_1, D_2) = \\frac|C_1 \\cap C_2||C_1 \\cup C_2| d(C1,C2)=1C1C2C1C2 \\mathrmd(C_1, C_2) =1- \\frac|C_1 \\cap C_2||C_1 \\cup C_2|  0/1bit, Boolean
Rows : k-grams
Columns  
 ee  ss   11  k-gram ee   ss 
 Jaccard  1 

Step 2: Min-Hashing  signatures
Key Idea:
 CC hash  signature h(C)h(C)  sim(C1,C2)\\mathrmsim(C_1 ,C_2 )  signatures h(C1)h(C_1)  h(C2)h(C_2) 
Goal:
 h()h(\\cdot) 
 sim(C1,C2)\\mathrmsim(C_1 ,C_2 )  h(C1)=h(C2)h(C_1 ) = h(C_2)   sim(C1,C2)\\mathrmsim(C_1 ,C_2 )  h(C1)=h(C2)h(C_1 ) = h(C_2)  Idea:
hash buckets
Min-Hashing  \\pi  Boolean  min-hash  h(C)h_\\pi(C) =  CC  11   h(C)=min(C) h_\\pi(C) = \\min_\\pi \\pi(C)  hh_\\pi signature)
 signature  MM :
Columns 
Rows  \\pi 
[Example]
[1]
 \\pi ,  Pr[h(C1)=h(C2)]=sim(C1,C2)\\mathrmPr\\Big[h_\\pi(C_1) = h_\\pi (C_2)\\Big] = \\mathrmsim(C_1 , C_2 ) 
 XX  doc zXz \\in X  shingle  Pr[(z)=min((X))]=1X) \\beginalign \\mathrmPr\\Big[\\pi(z)= \\min(\\pi(X))\\Big] = \\frac1|X|) \\endalign  zX\\forall z \\in X  min\\min  y\\mathbf y  shingles  (y):=min((C1C2))\\pi(\\mathbf y) := \\min(\\pi(C_1\\cup C_2 )) , 
(y)=min((C1)),ifyC1(C2=)or(y)=min((C2)),ifyC2(C1=) \\beginalign &amp;\\pi(\\mathbf y)=\\min(\\pi(C_1)) , \\quad \\textif $\\mathbf y \\in C_1$  \\quad(C_2 = \\emptyset )\\\\ \\textor \\quad &amp;\\pi(\\mathbf y)=\\min(\\pi(C_2)) ,\\quad \\textif $\\mathbf y \\in C_2$  \\quad (C_1 = \\emptyset ) \\endalign 
(y)=min((C1))=min((C2))ifyC1C2\\pi(\\mathbf y)=\\min(\\pi(C_1))=\\min(\\pi(C_2)) \\quad \\textif $\\mathbf y \\in C_1 \\cap C_2$  
Pr[min((C1))=min((C2))]=C1C2C1C2=sim(C1,C2) \\beginalign \\mathrmPr\\Big[\\min(\\pi(C_1)) = \\min(\\pi (C_2))\\Big] = \\frac|C_1 \\cap C_2||C_1 \\cup C_2|= \\mathrmsim(C_1 , C_2 ) \\endalign [2]
 CiC_i , CjC_j   33 
Type A 11  aa Type B 00  11 ,  bb Type C 00  cc sim(C1,C2)=aa+b \\mathrmsim(C_1 , C_2 ) = \\fracaa+b Type C
 h(C1)=h(C2)h_\\pi(C_1) = h_\\pi (C_2)  Type A
Pr[h(C1)=h(C2)]=Pr[aa+b]=sim(C1,C2) \\mathrmPr\\Big[h_\\pi(C_1) = h_\\pi (C_2)\\Big] = \\mathrmPr\\Big[ \\fracaa+b\\Big] = \\mathrmsim(C_1 , C_2 ) signature min-hash function  Jaccard
1-3
col/col: 34=0.75\\frac34 = 0.75 (input matrix)
sig/sig: 23=0.67\\frac23 = 0.67 (signature matrix)
  cc  hash hih_i  M(i,c)M(i,c) ,  M(i,c)=M(i, c) = \\infin  cc   jj  11 ,  hih_i  hi(j)&lt;M(i,c)h_i(j) &lt; M(i, c) ,  M(i,c)hi(j)M(i, c) \\larr h_i (j)  cc   ii 1 hih_i  MM M
hash
ha,b(x)=((ax+b)modp)modN h_a,b(x)=((a \\cdot x+b) \\mod p) \\mod N aa , bb  pp  ( p&gt;Np &gt; N ) Example
h1(x)=xmod5h_1(x)= x \\mod 5 h2(x)=(2x+1)mod5h_2(x)=(2x+1) \\mod 5 c1c_1 c2c_2 h1h_1 h2h_2 M(h1,c1)M(h_1,c_1) M(h2,c1)M(h_2,c_1) M(h1,c2)M(h_1,c_2) M(h2,c2)M(h_2,c_2) 1 0 h1(1)=1h_1(1) =1 h2(1)=3h_2(1) =3 1 3 \\infin \\infin 0 1 h1(2)=2h_1(2) =2 h2(2)=0h_2(2) =0 1 3 2 0 1 1 h1(3)=3h_1(3) =3 h2(3)=2h_2(3) =2 1 2 2 0 1 0 h1(4)=4h_1(4) =4 h2(4)=4h_2(4) =4 1 2 2 0 0 1 h1(5)=0h_1(5) =0 h2(5)=1h_2(5) =1 1 2 0 0 Step 3: Locality Sensitive Hashing Focus on pairs of signatures likely to be from similar documents
 CiC_i  CjC_j &gt;100 cN2c^2_N 
bucketbucket
hash  bucket
bucketsignaturespairs hash  hash  buckets 
bucketspairshashbucket
LSH  signature  MM  bb bandsband rr 
band hashbucketbandhashbandhash
signaturesband Min-Hash hash  bucketbandhashbucketbucket signaturesbands 100%hashbucketbucketbandsbucket LSH ss  22 sets ( docscolumnssignatures)  tt  
 sets  &gt;t&gt;t bucket  sets  &lt;t&lt;t bucketbucket0 : signature matrix   tt  FPFP  FNFN 
FPFP  tt buckets FNFN  tt buckets 
 C1C_1 , C2C_2 Signature tt 
band rr 
 trt^r  1tr1-t^r  bb bandband  (1tr)b(1-t^r)^b  C1C_1  C2C_2 bucket
 bb bandband 1(1tr)b1- (1-t^r)^b  C1C_1  C2C_2 bucket
FPFP  FNFN 
signatures  MM 
bb  (1tr)b=(1tMb)b(1-t^r)^b = (1-t^\\fracMb) ^b Smin-hash hash  LSH  rr  (1tr)b=(1tr)Mr(1-t^r)^b = (1-t^r) ^\\fracMr S bb  rr 
1(1tr)b1-(1-t^r)^b  tt hashstep function t=(1b)1rt = (\\frac1b)^\\frac1r 
 tt  pp hashbuckethashbuckethashbucket
 b=20b=20 , r=5r=5 0.4-0.60.6threshold
t 1(1tr)b1-(1-t^r)^b 0.2 0.0064 0.3 0.0475 0.4 0.1860 0.5 0.4701 0.6 0.8019 0.7 0.9748 0.8 0.9996 Example
 MM 100000100k100 0.80.8 
b=20b=20  r=5r =5  sim(C1,C2)=0.8\\mathrmsim(C_1 , C_2 ) = 0.8 C1C_1  C2C_2 band (0.8)5=0.328(0.8)^5 = 0.328 C1C_1  C2C_2  bb band (10.328)20=0.00035(1-0.328)^20 = 0.00035  0.035%0.035\\%  80%80\\%  FNFN   99.965%99.965\\% 
b=20b=20  r=5r =5  sim(C1,C2)=0.3\\mathrmsim(C_1 , C_2 ) = 0.3 C1C_1  C2C_2 band (0.3)5=0.0024(0.3)^5 = 0.0024 C1C_1  C2C_2  bb band (10.0024)20=0.9525(1-0.0024)^20 = 0.9525 C1C_1  C2C_2  bb band 1(10.0024)20=0.04741- (1-0.0024)^20 = 0.0474  4.74%4.74\\%  30%30\\%  FPFP   4.74%4.74\\%  
LSH:
 tt 
Signature kk  embedding
 bb  rr 
 FNFN  bb  rr  tt  tt  0.50.5  bb  rr S 0.50.5 
 FNFN  bb  rr  b=20b=20  r=6r=6  ss candidate
Summary Summary Shingling:
  hash  shingling 
Min-Hashing
signatures
 hash signatures
Pr[h(C1)=h(C2)]=sim(C1,C2) \\mathrmPr\\Big[h_\\pi(C_1) = h_\\pi (C_2)\\Big] = \\mathrmsim(C_1 , C_2)  hash 
Locality-Sensitive HashingN
 hashing  s\\ge s 
LSH  Distance Measure
d()d(\\cdot)  pair  x,yx,y 
(,)0( , ) \\ge 0 (,)=0(, ) = 0 iff = =  (,)=(,)(, ) = (, ) (x,y)(,)+(,)(x,y) \\le (, ) + (, ) ( triangle inequality )  Locality-Sensitive (LS) Families
hash  H\\mathcal H  (d1,d2,p1,p2)(d_1,d_2,p_1,p_2) -sensitive x,ySx,y \\in S , hash  hHh \\in \\mathcal H 
 d(x,y)d1d(x,y)\\leq d_1  h(x)=h(y)h(x) = h(y)  p1p_1  Pr[h(x)=h(y)]p1\\mathrmPr\\big[h(x)=h(y)\\big] \\ge p_1  d(x,y)d1d(x,y)\\geq d_1  h(x)=h(y)h(x) = h(y)  p2p_2  Pr[h(x)=h(y)]p2\\mathrmPr\\big[h(x)=h(y)\\big] \\le p_2  p1&gt;p2p_1&gt;p_2  d1&lt;d2d_1&lt;d_2 SS  dd Jaccard  HH Min-hash   hH\\forall \\ h \\in H 
Pr[h(x)=h(y)]=1d(x,y) \\mathrmPr\\Big[h(x) = h (y)\\Big] = 1-d(x,y) Jaccard  LSH  MinHash  (d1,d2,1d1,1d2)(d_1,d_2,1-d_1,1-d_2) -sensitive  d1&lt;d2d_1&lt;d_2 
 H\\mathcal H   H\\mathcal H  rr  H\\mathcal H&#x27; :
 h=[h1,,hr]H\\mathbf h = [h_1, \\cdots, h_r ] \\in \\mathcal H&#x27;   h(x)=h(y)\\mathbf h(x) = \\mathbf h(y)  hi(x)=hi(y)i,1irh_i(x) = h_i(y) \\ \\forall \\ i, \\ 1\\le i \\le r band rr 

 H\\mathcal H  (d1,d2,p1,p2)(d_1,d_2,p_1,p_2) -sensitive  H\\mathcal H&#x27;  (d1,d2,(p1)r,(p2)r)(d_1,d_2,(p_1)^r,(p_2)^r) -sensitive 
Reference https://web.stanford.edu/class/cs246/slides/03-lsh.pdf https://web.stanford.edu/class/cs246/slides/04-lsh_theory.pdf LSH`}).add({id:3,tag:"en",href:"/blogs/pythontools/",title:"PythonTools",description:" Python ",content:`Tools Docstring Parser docstring_parser
docstring_parser Python  ReSTGoogleNumpydoc  Epydoc 
1 from docstring_parser import parse 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 docstring = parse( &#39;&#39;&#39; Short description Long description spanning multiple lines - First line - Second line - Third line :param name: description 1 :param int priority: description 2 :param str sender: description 3 :raises ValueError: if name is invalid &#39;&#39;&#39; ) 1 2 docstring.long_description # &#39;Long description spanning multiple lines\\n - First line\\n - Second line\\n - Third line&#39; 1 2 docstring.short_description # &#39;Short description&#39; 1 2 3 4 docstring.params # [&lt;docstring_parser.common.DocstringParam at 0x1a67269ea10&gt;, # &lt;docstring_parser.common.DocstringParam at 0x1a67269eb30&gt;, # &lt;docstring_parser.common.DocstringParam at 0x1a67269eb60&gt;] 1 2 3 4 5 6 7 vars(docstring.params[0]) # &#39;args&#39;: [&#39;param&#39;, &#39;name&#39;], # &#39;description&#39;: &#39;description 1&#39;, # &#39;arg_name&#39;: &#39;name&#39;, # &#39;type_name&#39;: None, # &#39;is_optional&#39;: None, # &#39;default&#39;: None 1 2 docstring.params[1].type_name # &#39;int&#39; Ftfy ftfy
ftfy: fixes text for youftfyUnicodeftfyUnicodeUnicodeUnicode.
1 import ftfy 1 2 3 # fix mojibake (encoding mix-ups), ftfy.fix_text(&#39; No problems&#39;) # &#39; No problems&#39; 1 2 3 #  mojibake ftfy.fix_text(&#39;The Mona Lisa doesnt have eyebrows.&#39;) # &#34;The Mona Lisa doesn&#39;t have eyebrows.&#34; 1 2 ftfy.fix_text(&#39;&#39;) # &#39;LOUD NOISES&#39; 1 2 ftfy.fix_text(&#34;&amp;macr;\\\\_(\\x83\\x84)_/&amp;macr;&#34;) # &#39;\\\\_()_/&#39; 1 2 ftfy.fix_text(&#34;(&#39;&#39;)&#34;) # &#34;(&#39;&#39;)&#34; Prettytable prettytable
prettytable ASCII
1 2 3 4 5 6 7 8 9 10 from prettytable import PrettyTable table = PrettyTable() table.field_names = [&#34;City name&#34;, &#34;Area&#34;, &#34;Population&#34;, &#34;Annual Rainfall&#34;] table.add_rows( [ [&#34;Adelaide&#34;, 1295, 1158259, 600.5], [&#34;Brisbane&#34;, 5905, 1857594, 1146.4], ] ) 1 table City name Area Population Annual Rainfall Adelaide 1295 1158259 600.5 Brisbane 5905 1857594 1146.4 1 2 3 4 5 6 7 print(table.get_string()) # +-----------+------+------------+-----------------+ # | City name | Area | Population | Annual Rainfall | # +-----------+------+------------+-----------------+ # | Adelaide | 1295 | 1158259 | 600.5 | # | Brisbane | 5905 | 1857594 | 1146.4 | # +-----------+------+------------+-----------------+ 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 print(table.get_json_string()) # [ # [ # &#34;City name&#34;, # &#34;Area&#34;, # &#34;Population&#34;, # &#34;Annual Rainfall&#34; # ], #  # &#34;Annual Rainfall&#34;: 600.5, # &#34;Area&#34;: 1295, # &#34;City name&#34;: &#34;Adelaide&#34;, # &#34;Population&#34;: 1158259 # , #  # &#34;Annual Rainfall&#34;: 1146.4, # &#34;Area&#34;: 5905, # &#34;City name&#34;: &#34;Brisbane&#34;, # &#34;Population&#34;: 1857594 #  # ] Box box
box 
1 2 3 from box import Box movie_box = Box( &#34;Robin Hood: Men in Tights&#34;:  &#34;imdb stars&#34;: 6.7, &#34;length&#34;: 104  ) 1 2 movie_box.Robin_Hood_Men_in_Tights.imdb_stars # 6.7 1 2 3 4 # merge box_1 = Box(val=&#39;important_key&#39;: 1) box_2 = Box(val=&#39;less_important_key&#39;: 2) box_1.merge_update(box_2) 1 2 box_1 # Box(&#39;val&#39;: &#39;important_key&#39;: 1, &#39;less_important_key&#39;: 2) Fuzzy Finder fuzzyfinder
fuzzyfinder SublimeTextVimCtrl-P
Fuzzy Finder 
1 from fuzzyfinder import fuzzyfinder 1 2 3 suggestions = fuzzyfinder(&#39;abc&#39;, [&#39;defabca&#39;, &#39;abcd&#39;, &#39;aagbec&#39;, &#39;xyz&#39;, &#39;qux&#39;]) list(suggestions) # [&#39;abcd&#39;, &#39;defabca&#39;, &#39;aagbec&#39;] 1 2 3 4 5 #  collection = [&#39;aa bbb&#39;, &#39;aca xyz&#39;, &#39;qx ala&#39;, &#39;xza az&#39;, &#39;bc aa&#39;, &#39;xy abca&#39;] suggestions = fuzzyfinder(&#39;aa&#39;, collection, accessor=lambda x: x.split()[1]) list(suggestions) # [&#39;bc aa&#39;, &#39;qx ala&#39;, &#39;xy abca&#39;] Click click
ClickPython
1 2 3 4 5 6 7 8 9 10 11 12 import click @click.command() @click.option(&#39;--count&#39;, default=1, help=&#39;Number of greetings.&#39;) @click.option(&#39;--name&#39;, prompt=&#39;Your name&#39;, help=&#39;The person to greet.&#39;) def hello(count, name): &#34;&#34;&#34;Simple program that greets NAME for a total of COUNT times.&#34;&#34;&#34; for x in range(count): click.echo(f&#34;Hello name!&#34;) if __name__ == &#39;__main__&#39;: hello() Python Prompt Toolkit prompt_toolkit
prompt_toolkit PythonGNU readlinePython
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 import click from fuzzyfinder import fuzzyfinder from prompt_toolkit import prompt from prompt_toolkit.auto_suggest import AutoSuggestFromHistory from prompt_toolkit.completion import Completer, Completion, WordCompleter from prompt_toolkit.history import FileHistory SQLKeywords = [&#39;select&#39;, &#39;from&#39;, &#39;insert&#39;, &#39;update&#39;, &#39;delete&#39;, &#39;drop&#39;] class SQLCompleter(Completer): def get_completions(self, document, complete_event): word_before_cursor = document.get_word_before_cursor(WORD=True) matches = fuzzyfinder(word_before_cursor, SQLKeywords) for m in matches: yield Completion(m, start_position=-len(word_before_cursor)) while True: user_input = prompt( u&#39;&gt;&#39;, history=FileHistory(&#39;history.txt&#39;), #  auto_suggest=AutoSuggestFromHistory(), #  completer=SQLCompleter(), #  ) #  click.echo_via_pager(user_input) Pygments pygments
Pygments wiki
589


,HTMLRTFLaTeXANSI

1 2 3 4 5 6 7 8 9 from pygments import highlight from pygments.lexers import get_lexer_by_name from pygments.formatters import HtmlFormatter code = &#39;print(&#34;Hello World&#34;)&#39; lexer = get_lexer_by_name(&#34;python&#34;, stripall=True) formatter = HtmlFormatter(linenos=True, cssclass=&#34;source&#34;) result = highlight(code, lexer, formatter) print(result) 1print(&quot;Hello World&quot;) Questionary questionary
questionary 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import questionary questionary.text(&#34;What&#39;s your first name&#34;).ask() questionary.password(&#34;What&#39;s your secret?&#34;).ask() questionary.confirm(&#34;Are you amazed?&#34;).ask() questionary.select( &#34;What do you want to do?&#34;, choices=[&#34;Order a pizza&#34;, &#34;Make a reservation&#34;, &#34;Ask for opening hours&#34;], ).ask() questionary.rawselect( &#34;What do you want to do?&#34;, choices=[&#34;Order a pizza&#34;, &#34;Make a reservation&#34;, &#34;Ask for opening hours&#34;], ).ask() questionary.checkbox( &#34;Select toppings&#34;, choices=[&#34;foo&#34;, &#34;bar&#34;, &#34;bazz&#34;] ).ask() questionary.path(&#34;Path to the projects version file&#34;).ask() Chardet chardet
Chardet 
1 2 3 4 5 6 import urllib.request import chardet rawdata = urllib.request.urlopen(&#39;http://yahoo.co&#39;).read() chardet.detect(rawdata) # &#39;encoding&#39;: &#39;utf-8&#39;, &#39;confidence&#39;: 0.99, &#39;language&#39;: &#39;&#39; Rich rich
RichPythonmarkdown
RichRich
1 2 3 from rich import print print(&#34;[italic red]Hello[/italic red] World!&#34;) Hello World! 1 2 3 from rich.panel import Panel Panel.fit(&#34;[bold yellow]Hi, I&#39;m a Panel&#34;, border_style=&#34;red&#34;)   Hi, I'm a Panel   1 2 3 4 5 from rich import print from rich.panel import Panel from rich.text import Text print( Panel(Text(&#34;Hello&#34;, justify=&#34;right&#34;)))   Hello   1 2 3 4 5 6 7 8 9 10 11 12 13 14 MARKDOWN = &#34;&#34;&#34; # This is an h1 Rich can do a pretty *decent* job of rendering markdown. 1. This is a list item 2. This is another list item &#34;&#34;&#34; from rich.console import Console from rich.markdown import Markdown console = Console() md = Markdown(MARKDOWN) console.print(md)   This is an h1   Rich can do a pretty decent job of rendering markdown. 1 This is a list item 2 This is another list item 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 from rich.console import Console from rich.table import Table table = Table(title=&#34;Star Wars Movies&#34;) table.add_column(&#34;Released&#34;, justify=&#34;right&#34;, style=&#34;cyan&#34;, no_wrap=True) table.add_column(&#34;Title&#34;, style=&#34;magenta&#34;) table.add_column(&#34;Box Office&#34;, justify=&#34;right&#34;, style=&#34;green&#34;) table.add_row(&#34;Dec 20, 2019&#34;, &#34;Star Wars: The Rise of Skywalker&#34;, &#34;$952,110,690&#34;) table.add_row(&#34;May 25, 2018&#34;, &#34;Solo: A Star Wars Story&#34;, &#34;$393,151,347&#34;) table.add_row(&#34;Dec 15, 2017&#34;, &#34;Star Wars Ep. V111: The Last Jedi&#34;, &#34;$1,332,539,889&#34;) table.add_row(&#34;Dec 16, 2016&#34;, &#34;Rogue One: A Star Wars Story&#34;, &#34;$1,332,439,889&#34;) console = Console() console.print(table) Star Wars Movies   Released  Title  Box Office    Dec 20, 2019  Star Wars: The Rise of Skywalker  $952,110,690   May 25, 2018  Solo: A Star Wars Story  $393,151,347   Dec 15, 2017  Star Wars Ep. V111: The Last Jedi  $1,332,539,889   Dec 16, 2016  Rogue One: A Star Wars Story  $1,332,439,889   1 2 3 4 5 6 7 from rich.tree import Tree from rich import print tree = Tree(&#34;Rich Tree&#34;) tree.add(&#34;foo&#34;) tree.add(&#34;bar&#34;) print(tree) Rich Tree  foo  bar Termcolor termcolor
1 2 3 import sys from termcolor import colored, cprint 1 2 3 4 #  text = colored(&#34;Hello, World!&#34;, &#34;red&#34;, attrs=[&#34;reverse&#34;, &#34;blink&#34;]) cprint(text) # [5m[7m[31mHello, World![0m[0m 1 2 3 #  cprint(&#39;Hello, World!&#39;, &#39;green&#39;, &#39;on_red&#39;) # [41m[32mHello, World![0m 1 2 3 4 #  print_red_on_cyan = lambda x: cprint(x, &#39;red&#39;, &#39;on_cyan&#39;) print_red_on_cyan(&#39;Hello, World!&#39;) # [46m[31mHello, World![0m 1 2 3 for i in range(10): cprint(i, &#39;magenta&#39;, end=&#39; &#39;) # [35m0[0m [35m1[0m [35m2[0m [35m3[0m [35m4[0m [35m5[0m [35m6[0m [35m7[0m [35m8[0m [35m9[0m 1 2 3 #  cprint(&#34;Attention!&#34;, &#39;red&#39;, attrs=[&#39;bold&#39;], file=sys.stderr) # [1m[31mAttention![0m colorama colorama
colorama  ANSI MS Windows
ANSIUnixMacColoramaWindowsstdoutANSIwin32Colorama
APIPythonLinuxMacANSIWindowscoloramajust_fix_windows_consolev0.4.6init
ForeBackStyle
Fore: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Back: BLACK, RED, GREEN, YELLOW, BLUE, MAGENTA, CYAN, WHITE, RESET.
Style: DIM, NORMAL, BRIGHT, RESET_ALL
1 from colorama import Fore, Back, Style, init 1 2 3 4 5 6 #  #  autoreset=True # Fore.RESET # Back.RESET # Style.RESET_ALL init(autoreset=True) 1 2 f&#34;Fore.LIGHTGREEN_EXsome red text&#34; # &#39;\\x1b[92msome red text&#39; 1 2 f&#34;Back.GREENand with a green background&#34; # &#39;\\x1b[42mand with a green background&#39; 1 2 f&#34;Style.DIMand in dim text&#34; # &#39;\\x1b[2mand in dim text&#39;`}).add({id:4,tag:"en",href:"/blogs/python%E5%9F%BA%E7%A1%80/",title:"Python",description:"Python",content:` copy copy  +1
  
 
 ID 
1 2 3 4 5 6 7 a = 1 b = a print(id(a), id(b)) # 140729223153328 140729223153328 a = 2 print(a, b) # 2 1 print(id(a), id(b)) # 140729223153360 140729223153328 , 
1 2 3 4 5 list1 = [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;] list2 = list1 list1.append(&#34;d&#34;) print(list1, list2) # [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] print(id(list1), id(list2)) # 2212470388480 2212470388480  , , 
list()  copy
1 2 3 4 5 6 7 8 9 list1 = [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;] list2 = list1.copy() # copy list3 = list(list1) list1.append(&#34;d&#34;) print(list1, list2, list3) # [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, &#39;d&#39;] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;] print(id(list1), id(list2), id(list3)) # 2128034527104 2128034526144 2128033091072 1 2 3 4 5 6 7 8 9 10 list1 = [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, [1, 2, 3]] list2 = list1.copy() # copy list3 = list(list1) list1[3].append(4) print(list1, list2, list3) # [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, [1, 2, 3, 4]] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, [1, 2, 3, 4]] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, [1, 2, 3, 4]] print(id(list1), id(list2), id(list3)) # 2111124370112 2111124370816 2111124369664 print(id(list1[3]), id(list2[3]), id(list3[3])) # 2111124400320 2111124400320 2111124400320  1 2 3 4 5 6 7 8 9 import copy list1 = [&#34;a&#34;, &#34;b&#34;, &#34;c&#34;, [1, 2, 3]] list2 = copy.deepcopy(list1) list1[3].append(4) print(list1, list2) # [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, [1, 2, 3, 4]] [&#39;a&#39;, &#39;b&#39;, &#39;c&#39;, [1, 2, 3]] print(id(list1), id(list2)) # 1394256181440 1394256181696 print(id(list1[3]), id(list2[3])) # 1394256180608 1394256115584  [item] * 3  [item, item, item] item (list) *  items  [&quot;hello&quot;]
1 2 3 4 5 6 7 item = [&#34;hello&#34;] items = [item] * 3 print(items) # [[&#39;hello&#39;], [&#39;hello&#39;], [&#39;hello&#39;]] items[0][0] = &#34;world&#34; print(items) # [[&#39;world&#39;], [&#39;world&#39;], [&#39;world&#39;]] 1 2 3 4 5 items = [[&#39;hello&#39;] for _ in range(3)] print(id(items[0]), id(items[1]), id(items[2])) # 1618997298624 1618997299584 1618997299456 items[0][0] = &#34;world&#34; print(items) # [[&#39;world&#39;], [&#39;hello&#39;], [&#39;hello&#39;]] lambda 
1 2 3 4 5 6 def multipliers(): return [lambda x: i * x for i in range(4)] print([m(2) for m in multipliers()]) # [6, 6, 6, 6] 1 2 3 4 5 6 7 def multipliers(): # i=i return [lambda x, i=i: i * x for i in range(4)] print([m(2) for m in multipliers()]) # [0, 2, 4, 6] 1 2 3 4 5 6 def multipliers(): return (lambda x: i * x for i in range(4)) print([m(2) for m in multipliers()]) # [0, 2, 4, 6]   1 2 3 4 5 6 7 8 9 10 g1 = 1 g2 = [] def f(): g1 = 2 g2.append(1) f() print(g1) # 1 print(g2) # [1] g1: f  g2: f   python 
 nonlocal  global nonlocal  global  nonlocal 
Example
a = 1  globals  func2  nonlocal 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 a = 0 def func1(): a = 1 def func2(): a = 2 print(&#39;closure a: &#39;, a) print(f&#39;func1_a: a&#39;) func2() print(f&#39;after func2, func1_a: a&#39;) func1() print(f&#39;global a: a&#39;) 1 2 3 4 # func1_a:1 # closure a: 2 # after func2, func1_a:1 # global a:0 a = 1  globals  func2  nonlocal 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 a = 0 def func1(): a = 1 def func2(): nonlocal a a = 2 print(&#39;closure a: &#39;, a) print(f&#39;func1_a: a&#39;) func2() print(f&#39;after func2, func1_a: a&#39;) func1() print(f&#39;global a: a&#39;) 1 2 3 4 # func1_a: 1 # closure a: 2 # after func2, func1_a: 2 # global a: 0 a = 1  globals  func2  nonlocal 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 a = 0 def func1(): a = 1 def func2(): global a a = 2 print(&#39;closure a: &#39;, a) print(f&#39;func1_a: a&#39;) func2() print(f&#39;after func2, func1_a: a&#39;) func1() print(f&#39;global a: a&#39;) 1 2 3 4 # func1_a: 1 # closure a: 2 # after func2, func1_a: 1 # global a: 2  nonclosure  A A  B  B  A  
1 2 3 4 5 6 7 def func(name): def inner_func(age): print(&#39;name:&#39;, name, &#39;age:&#39;, age) return inner_func bb = func(&#39;aa&#39;) bb(26) 1 # name: aa age: 26  func  inner_func,  name func name 

 

Example

1 2 3 4 5 6 7 8 9 def animal_voice(animal): def sound(voice): print(animal, &#34;:&#34;, voice, &#34;...&#34;) return sound dog = animal_voice(&#34;dog&#34;) dog(&#34;wangwang&#34;) # dog : wangwang ... dog(&#34;wowo&#34;) # dog : wowo ... 1 2 3 4 5 6 7 8 9 10 11 class Animal: def __init__(self, animal): self.animal = animal def sound(self, voice): print(self.animal, &#34;:&#34;, voice, &#34;...&#34;) dog = Animal(&#39;dog&#39;) dog.sound(&#34;wangwang&#34;) # dog : wangwang ... dog.sound(&#34;wowo&#34;) # dog : wowo ... 1 2 print(id(Animal.sound)) # 2165033261520 print(id(dog.sound)) # 2165026975808  Animal  voice  Animal  dog 

Example
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 def makebold(fn): def wrapped(): return &#34;&lt;b&gt;&#34; + fn + &#34;&lt;b&gt;&#34; return wrapped def makeitalic(fn): def wrapped(): return &#34;&lt;i&gt;&#34; + fn + &#34;&lt;i&gt;&#34; return wrapped def hello(): return &#34;hello world&#34; hello = makeitalic(hello()) hello = makebold(hello()) print(hello()) # &lt;b&gt;&lt;i&gt;hello world&lt;i&gt;&lt;b&gt;  decorators  Python  
  
 @decorator_name 
Python     

:  :  :  :  Example 1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 def outer(f): def inner(*args, **kargs): inner.co += 1 return f(*args, **kargs) inner.co = 0 return inner @outer def f(): pass f() f() f() print(f.co) 1 # 3 Example 2
1 2 3 4 5 6 7 8 9 10 11 12 def wrapFun(func): def inner(a, b): print(&#39;function name:&#39;, func.__name__) r = func(a, b) return r return inner @wrapFun def myadd(a, b): return a + b print(myadd(2, 3)) 1 2 # function name: myadd # 5  stack
   stack
Example 3
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 def set_fun1(func): #  print(&#34;set_fun1&#34;) def call_fun1(*args, **kwargs): #  print(&#34;call_fun1&#34;) return func() return call_fun1 def set_fun2(func): print(&#34;set_fun2&#34;) def call_fun2(*args, **kwargs): print(&#34;call_fun2&#34;) return func() return call_fun2 #  @set_fun2 @set_fun1 def test(): print(&#34;--------------&#34;) test() 1 2 3 4 5 # set_fun1 # set_fun2 # call_fun2 # call_fun1 # --------------   __getitem__  __iter__  
 __next__  __iter__  

 yield  generator
yield 
 yield  yield 
 next()  for  yield 
 
  


1 print(&#39;__iter__&#39; in dir([1, 2, 3])) # True 
1 2 3 from collections.abc import Iterable print(isinstance(&#39;123&#39;, Iterable)) # True 1 2 3 4 5 6 7 8 9 arr = [1, 2, 3] arr_iter = arr.__iter__() print(arr_iter.__next__()) # 1 # arr,  print(&#39;__next__&#39; in dir(arr)) # False # arr_iter print(&#39;__next__&#39; in dir(arr_iter)) # True 1. __iter__()
 
  self 2. __next__ ()
 StopIteration 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 def __init__(self, start, end): self.start = start self.end = end def __iter__(self): return self def __next__(self): if self.start &lt; self.end: self.start += 1 return self.start - 1 else: raise StopIteration for i in MyRange(1, 3): print(i) # 1 2 for i in range(1, 3): print(i) # 1 2 3. iter(source, sentinel=None)
1 2 3 4 5 6 7 8 9 10 def iter(source, sentinel=None): # known special case of iter &#34;&#34;&#34; iter(iterable) -&gt; iterator iter(callable, sentinel) -&gt; iterator Get an iterator from an object. In the first form, the argument must supply its own iterator, or be a sequence. In the second form, the callable is called until it returns the sentinel. &#34;&#34;&#34; pass Example 1:
1 2 3 4 5 6 7 it = iter([1, 2, 3, 4, 5]) def func(): return next(it) for j in iter(func, 4): print(j) 1 2 3 # 1 # 2 # 3 Example 2:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 class Next: def __init__(self): self.data = [0, 1, 2, 3, 4] self._iter = iter(self.data) def get_len(self): return len(self.data) def __iter__(self): print(&#39;iter&#39;) return self def __call__(self): print(&#34;call&#34;) return next(self._iter) def __next__(self): print(&#39;i am next&#39;) return next(self._iter)  Next()  Next()()  Next().__call__()
 iter      raise StopIteration
 __call__  self._iter  __next__  __iter__ 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 for it in iter(Next(), 6): print(it) # call # 0 # call # 1 # call # 2 # call # 3 # call # 4 # call 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 iter_next = iter(Next()) print(&#34;===================&#34;) for it in iter_next: print(it) # iter # =================== # iter # i am next # 0 # i am next # 1 # i am next # 2 # i am next # 3 # i am next # 4 # i am next  try/except
try :
 try  try  except 
 except try 
 try  try 
 except  except  try  except 
except 
 except 
except (ValueError,IndexError) as e:
 except  try 
Except 
1 2 3 4 5 6 7 8 9 10 11 class AException(Exception): def __str__(self): return &#34;A Exception&#34; class BException(AException): def __str__(self): return &#34;B Exception&#34; class CException(AException, BException): pass Example 1
1 2 3 4 5 6 7 8 try: try: raise BException except AException: raise except Exception as exc: print(&#34;Raise exception&#34;) print(str(exc)) 1 2 # Raise exception # B Exception Example 2
1 2 3 4 5 6 7 8 try: try: raise BException except AException: raise AException except Exception as exc: print(&#34;Raise exception&#34;) print(str(exc)) 1 2 # Raise exception # A Exception Example 3
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 try: exc_massage = [] try: raise CException except AException as exc: exc_massage.append(&#34;AException&#34;) raise exc except BException as exc: exc_massage.append(&#34;BException&#34;) raise exc except CException as exc: exc_massage.append(&#34;CException&#34;) raise exc except CException: print(exc_massage) print(&#34;C Exception&#34;) except AException as e: print(&#34;A Exception&#34;) except BException: print(&#34;B Exception&#34;) 1 2 # [&#39;AException&#39;] # C Exception try/except&hellip;else
try/except  else  except 
else  try 
 else  try  except 
1 2 3 4 5 6 7 8 9 try: try: x = 1 / 0 except TypeError: print(&#34;TypeError&#34;) else: print(&#34;Else&#34;) except Exception as e: print(e) 1 # division by zero try/except&hellip;else&hellip;finally
finally 
Example 1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def test(): try: print(&#39;try&#39;) a = 1 / 0 print(&#39;try&#39;) return 0 except: print(&#39;except&#39;) return 1 else: print(&#34;else&#34;) return 2 finally: print(&#39;finally&#39;) print(test()) # try # except # finally # 1 Example 2
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def test(): try: print(&#39;try&#39;) a = 5.0 / 0.0 print(&#39;try&#39;) return 0 except: print(&#39;except&#39;) return 1 else: print(&#34;else&#34;) return 2 finally: print(&#39;finally&#39;) return 3 print(test()) # try # except # finally # 3 Example 3
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def test(): try: print(&#39;try&#39;) a = 1 / 1 print(&#39;try&#39;) return 0 except: print(&#39;except&#39;) return 1 else: print(&#34;else&#34;) return 2 finally: print(&#39;finally&#39;) return 3 print(test()) # try # try # finally # 3 Example 4
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 def test(): try: print(&#39;try&#39;) a = 1 / 1 print(&#39;try&#39;) except: print(&#39;except&#39;) return 1 else: print(&#34;else&#34;) return 2 finally: print(&#39;finally&#39;) return 3 print(test()) # try # try # else # finally # 3  python  C++
 TestClass 
   
   / /     1 2 3 4 5 6 7 8 9 10 11 12 class TestClass(object): #  val1 = 100 def __init__(self): #  self.val2 = 200 def fcn(self, val=400): val3 = 300 self.val4 = val self.val5 = 500 1 2 3 4 5 6 7 8 9 inst = TestClass() print(TestClass.val1) # 100 print(inst.val1) # 100 print(inst.val2) # 200 print(inst.val3) # &#39;TestClass&#39; object has no attribute &#39;val3&#39; print(inst.val4) # &#39;TestClass&#39; object has no attribute &#39;val4&#39; print(inst.val5) # &#39;TestClass&#39; object has no attribute &#39;val5&#39; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 inst1 = TestClass() inst2 = TestClass() print(inst1.val1) # 100 inst1.val1 = 1000 print(inst1.val1) # 1000 print(TestClass.val1) # 100 print(inst2.val1) # 100 TestClass.val1 = 2000 print(TestClass.val1) # 2000 print(inst1.val1) # 1000  print(inst2.val1) # 2000  inst3 = TestClass() print(inst3.val1) # 2000 
python 
list dict set
tuple string int float bool
Python  3 idtypevalue
id  id() 
type  type() 
value 
is  ==
is  id  ==  1 2 3 4 5 6 7 8 9 10 a = 1 b = a c = 1 d = 1.0 print(id(a)) # 140729241962160 print(id(b)) # 140729241962160 print(id(c)) # 140729241962160 print(id(d)) # 2070028299024 print(a is d) # False print(a == d) # True  a is d  id(d)==id(d) False  a==d  id(a)  id(d)  True python  [-5,256] 
 python -5~256 python :
1 2 3 4 5 6 7 a = 255 b = 255 print(a is b) # True c = 257 d = 257 print(c is d) # True Python console
1 2 3 4 5 6 7 8 a = 255 b = 255 id(a) Out[10]: 2922684620976 id(b) Out[11]: 2922684620976 a is b Out[4]: True 1 2 3 4 5 6 7 8 c = 257 d = 257 id(c) Out[8]: 2920614082448 id(d) Out[9]: 2920614081904 c is d Out[7]: False  1 2 3 4 5 6 7 8 9 10 11 class Person(object): tall = 180 hobbies = [] def __init__(self, name, age, weight): self.name = name self.age = age self.weight = weight def inform(self): print(&#39;%s is %s weights %s&#39; % (self.name, self.age, self.weight)) 
__name__
__doc__ 
__bases__
__dict__
__module__
__class__
1 2 3 4 5 6 print(Person.__name__) # Person print(Person.__doc__) # None print(Person.__bases__) # (&lt;class &#39;object&#39;&gt;,) print(Person.__dir__) # &lt;method &#39;__dir__&#39; of &#39;object&#39; objects&gt; print(Person.__module__) # __main__ print(Person.__class__) # &lt;class &#39;type&#39;&gt; __dict__  dir() 
__dict__   __dict__  () __dict__    __dict__    __dict__  python  __dict__  __dict__  list dir()  dir()  dir()  Python  API dir() ()  dir() 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # /&#34;football&#34;&#34;woman&#34; Person.hobbies.extend([&#34;football&#34;, &#34;woman&#34;]) print(Person.hobbies) # [&#39;football&#39;, &#39;woman&#39;] #  Person.hobbies2 = [&#34;reading&#34;, &#34;jogging&#34;, &#34;swimming&#34;] print(Person.hobbies2) # [&#39;reading&#39;, &#39;jogging&#39;, &#39;swimming&#39;] #  Bruce = Person(&#34;Bruce&#34;, 25, 60) print(f&#34;Bruce.name is Bruce.age years old&#34;) # Bruce is 25 years old #  Bruce.gender = &#34;male&#34; print(&#34;Bruce.name is Bruce.gender&#34;) # Bruce is male # class instance can access class attribute Bruce.hobbies.append(&#34;C#&#34;) print(Bruce.hobbies) # [&#39;football&#39;, &#39;woman&#39;, &#39;C#&#39;] print(Bruce.hobbies2) # [&#39;reading&#39;, &#39;jogging&#39;, &#39;swimming&#39;] /  &ldquo;&rdquo; 
   
   person.tall Bruce  &ldquo;person.tall is Bruce.tall&rdquo; / tall  Bruce  tall person.tall is not Bruce.tall  &ldquo;del Bruce.tall&rdquo;  tall  &ldquo;person.tall is Bruce.tall&rdquo; 1 2 3 4 5 6 7 8 9 10 11 12 # person.tallBruce print(Person.tall is Bruce.tall) # True #  Bruce.tall = 185 print(Bruce.tall) # 185 print(Person.tall is Bruce.tall) # False #  del Bruce.tall print(Bruce.tall) # 180 print(Person.tall is Bruce.tall) # True    
   person.hobbies Bruce  &ldquo;person.hobbies is Bruce hobbies&rdquo;  hobbies  Bruce  hobbies person.hobbies is not Bruce hobbies  &ldquo;del Bruce. hobbies&rdquo;  hobbies  &ldquo;person. hobbies is Bruce hobbies&rdquo;  hobbies  Bruce. hobbies  person.hobbiesperson.hobbies is Bruce. hobbies 1 2 3 4 5 6 7 8 9 10 11 12 13 14 # person.hobbiesBruce print(Person.hobbies is Bruce.hobbies) # True Bruce.hobbies.append(&#34;CSS&#34;) print(Person.hobbies is Bruce.hobbies) # True print(Person.hobbies) # [&#39;football&#39;, &#39;woman&#39;, &#39;C#&#39;, &#39;CSS&#39;] Will = Person(&#34;Will&#34;, 27, 60) print(f&#34;Will.name is Will.age years old&#34;) # Will is 27 years old # Will shares the same class attribute with wilber # Will don&#39;t have the &#34;gender&#34; attribute that belongs to wilber print(Will.hobbies) # [&#39;football&#39;, &#39;woman&#39;, &#39;C#&#39;, &#39;CSS&#39;] print(Will.gender) # AttributeError: &#39;Person&#39; object has no attribute &#39;gender&#39; 
__del__
1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Test: # python def __del__(self): print(&#34;Over&#34;) t1 = Test() t2 = t1 del t1 del t2 print(&#34;==========&#34;) # Over # ========== 1 2 3 4 5 6 7 8 9 10 11 12 class Test: # python def __del__(self): print(&#34;Over&#34;) t1 = Test() t2 = t1 del dog1 print(&#34;==========&#34;) # ========== # Over  t1 __del__  __del__ 
 class  &ldquo;_&rdquo;  &ldquo;__&rdquo;  /
 &ldquo;_&rdquo;
 protected    &ldquo;from moduleName import * &quot;  &ldquo;_&rdquo; 
 &ldquo;__&rdquo;
 private   
 Python  &quot;__&rdquo;   &ldquo;&rdquo;mangling

 
 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 class A(object): def __init__(self): self.__private() self.public() def __private(self): print(&#39;A.__private()&#39;) def public(self): print(&#39;A.public()&#39;) class B(A): def __private(self): print(&#39;B.__private()&#39;) def public(self): print(&#39;B.public()&#39;) b = B() # A.__private() # B.public()  class   Python    
() insubclass() 

type()  isinstance()  1 2 3 4 5 6 7 8 9 10 class Foo(object): pass class Bar(Foo): pass print(type(Foo()) == Foo) # True print(type(Bar()) == Foo) # False print(isinstance(Foo(), Foo)) # True print(isinstance(Bar(), Foo)) # True Example 1
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class A: def __init__(self): self.__j = 1 self.number = 5 class B(A): def __init__(self): self.__j = 2 self.number = 7 def show(self): print(self.__j, self.number) b = B() b.show() # 2 7 Example 2
1 2 3 4 5 6 7 8 9 10 11 12 13 14 class A(object): def __method(self): print(&#34;I&#39;m a method in A&#34;) def method(self): self.__method() class B(A): def __method(self): print(&#34;I&#39;m a method in B&#34;) B().method() # I&#39;m a method in A A().method() # I&#39;m a method in A Example 3
1 2 3 4 5 6 7 8 9 10 11 12 13 14 class Parent(object): &#34;&#34;&#34; parent class &#34;&#34;&#34; pass class Child(Parent): pass # doc print(Parent.__doc__) # parent class print(Child.__doc__) # None super 
super 

self 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Parent(object): Value = &#34;Hi, Parent value&#34; def fun(self): print(&#34;This is from Parent&#34;) class Child(Parent): Value = &#34;Hi, Child value&#34; def fun(self): print(&#34;This is from Child&#34;) # Parentfun Parent.fun(self) c = Child() c.fun() # This is from Child # This is from Parent  Python  super  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 class Parent(object): Value = &#34;Hi, Parent value&#34; def fun(self): print(&#34;This is from Parent&#34;) class Child(Parent): Value = &#34;Hi, Child value&#34; def fun(self): print(&#34;This is from Child&#34;) # super super(Child, self).fun() c = Child() c.fun() # This is from Child # This is from Parent super() Python  (MRO)  MRO Python  MRO 
 MRO  C3    MRO 
    super  super  MRO super 
1 2 3 def super(cls, inst): mro = inst.__class__.mro() return mro[mro.index(cls) + 1]  cls  inst 
inst  MRO  list  cls  MRO  index,  mro[index + 1]  super  super  enter B  enter C  enter A  super  enter A
self.__class__.__mro__   MRO
 MRO (
Example:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 class A(object): def __init__(self): print(&#34;Enter A&#34;) class B(A): def __init__(self): print(&#39;Enter B&#39;) super(B, self).__init__() print(&#39;Leave B&#39;) class C(A): def __init__(self): print(&#39;Enter C&#39;) super(C, self).__init__() print(&#39;Leave C&#39;) class D(B, C): def __init__(self): print(&#39;Enter D&#39;) super(D, self).__init__() print(&#34;Leave D&#34;) print(self.__class__.__mro__) d = D() # Enter D # Enter B # Enter C # Enter A # Leave C # Leave B # Leave D # (&lt;class &#39;__main__.D&#39;&gt;, &lt;class &#39;__main__.B&#39;&gt;, &lt;class &#39;__main__.C&#39;&gt;, &lt;class &#39;__main__.A&#39;&gt;, &lt;class &#39;object&#39;&gt;) 
class D Enter D &quot; ,  super super()  D MRO index 0index+1 class B,
 class B &ldquo;Enter B&rdquo; ,  super() index  1 index  2 class CEnter C .
 class C  super() class AEnter A
 class C  &ldquo;Leave C&rdquo; ,  class B Leave B,  class DLeave D
 super() Python  MRO   super()   MRO 
__new__ __new__ 
 cls python     __new__()  return  super(cls).__new__  object  __new__  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 class A(object): pass # object__new__() a = A() print(a) # &lt;__main__.A object at 0x000001BE6F8CD520&gt; class A(object): def __new__(cls): &#34;__new__&#34; return &#34;abc&#34; a = A() print(a) # &#39;abc&#39; print(type(a)) # &lt;class &#39;str&#39;&gt;  __new__() 
1 2 3 4 5 6 7 8 9 10 11 12 13 class Singleton(object): def __new__(cls, *args, **kwargs): if not hasattr(cls, &#34;_instance&#34;): cls._instance = super(Singleton, cls).__new__(cls) return cls._instance a = Singleton() b = Singleton() c = Singleton() print(a) # &lt;__main__.Singleton object at 0x000001F0B57D86D0&gt; print(b) # &lt;__main__.Singleton object at 0x000001F0B57D86D0&gt; print(c) # &lt;__main__.Singleton object at 0x000001F0B57D86D0&gt; __init__ __init__ 
 self,  self  __new__() 
__init__()  __new()__ 
 __new__()  cls  __init__() 

1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 class A: def __new__(cls, *args, **kwargs): print(&#34;A&#39; __new__&#34;) # return super(A,cls).__new__(cls) return object.__new__(cls) def __init__(self): print(&#34;A&#39; __init__&#34;) class B(A): def __new__(cls, *args, **kwargs): print(&#34;B&#39; __new__&#34;) def __init__(self): print(&#34;B&#39; __init__&#34;) a = A() # B&#39; __new__ BB b = B() # A&#39; __new__ # A&#39; __init__ # B&#39; __new__  Python  __init__ :
 
    
    
 
Python  typetype  Python 

1 2 3 4 5 6 7 class A: pass print(type(1)) # &lt;class &#39;int&#39;&gt; print(type(type(1))) # &lt;class &#39;type&#39;&gt; print(type(int)) # &lt;class &#39;type&#39;&gt; print(type(A)) # &lt;class &#39;type&#39;&gt; 
Python  type()   metaclass  Python   metaclass       type   __new__  type    
 CPU CPU 

CPU  0.01s
  
 CPU  

  



  Python + I/O    IO 

  1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 import asyncio import time async def say_after(delay, what): await asyncio.sleep(delay) print(f&#34;delay: what&#34;) async def main(): task1 = asyncio.create_task(say_after(2, &#39;hello1&#39;)) task2 = asyncio.create_task(say_after(2, &#39;world1&#39;)) print(f&#34;started at time.strftime(&#39;%X&#39;)&#34;) await say_after(1, &#39;hello2&#39;) await say_after(2, &#39;world2&#39;) await task1 await task2 print(f&#34;finished at time.strftime(&#39;%X&#39;)&#34;) asyncio.run(main()) 1 2 3 4 5 6 # started at 10:19:42 # 1: hello2 # 2: hello1 # 2: world1 # 2: world2 # finished at 10:19:45 asyncio :
asyncio.run()  &ldquo;main()&rdquo; 
await say_after(1, 'hello2')  await say_after(2, 'world2')  1  &ldquo;hello2&rdquo;   22  &ldquo;world2&rdquo;:
asyncio.create_task()    asyncio  
 33 s
 ,   ,   , 

   
  :  :  

 3 



mutex `}).add({id:5,tag:"en",href:"/blog/quick_start/",title:"QuickStart",description:"This is QuickStart.",content:` quickstart 
 
1 hugo new content/posts/my-first-post.md  Hugo 
1 hugo server -D Mathematics in Markdown Step Step 1  hugo.toml 
1 2 3 4 5 6 7 8 9 10 [markup] [markup.goldmark] [markup.goldmark.extensions] [markup.goldmark.extensions.passthrough] enable = true [markup.goldmark.extensions.passthrough.delimiters] block = [[&#39;\\[&#39;, &#39;\\]&#39;], [&#39;$$&#39;, &#39;$$&#39;]] inline = [[&#39;\\(&#39;, &#39;\\)&#39;]] [params] math = true Step 2  MathJax  KaTeX MathJax KaTeX
layouts/partials/math.html
MathJax:
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 &lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js&#34;&gt;&lt;/script&gt; &lt;script&gt; MathJax =  tex:  displayMath: [[&#39;\\\\[&#39;, &#39;\\\\]&#39;], [&#39;$$&#39;, &#39;$$&#39;]], // block inlineMath: [[&#39;\\\\(&#39;, &#39;\\\\)&#39;]] // inline , ; &lt;/script&gt;  if .Params.math  &lt;script&gt; MathJax =  tex: inlineMath: [[&#34;$&#34;, &#34;$&#34;]],	// block displayMath: [[&#34;$$&#34;, &#34;$$&#34;]],	// inline svg:  fontCache: &#34;global&#34;, , loader: load: [&#39;ui/safe&#39;] , ; &lt;/script&gt; &lt;script src=&#34;https://polyfill.io/v3/polyfill.min.js?features=es6&#34;&gt;&lt;/script&gt; &lt;script id=&#34;MathJax-script&#34; async src=&#34;https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js&#34; &gt;&lt;/script&gt;  end  Step 3  base template  partial template
layouts/_default/baseof.html
1 2 3 4 5 6 7 &lt;head&gt; ...  if .Param &#34;math&#34;   partialCached &#34;math.html&#34; .   end  ... &lt;/head&gt; inline &amp; display  inline  display 
 layouts/_default/_markup/render-passthrough.html 
 render-passthrough.html  inline  display  MathJax 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26  $opts := dict   if eq .Type &#34;block&#34;   $opts = dict &#34;displayMode&#34; true   end   with try (transform.ToMath .Inner $opts)   with .Err   errorf &#34;Failed to render MathJax: %q. See %s&#34; . $.Position   else   $rendered := .Value  &lt;!--  inline  display --&gt;  if $opts.displayMode  &lt;!-- MathJax  --&gt; &lt;div class=&#34;mathjax-display&#34;&gt;  $rendered  &lt;/div&gt;  else  &lt;!-- MathJax  --&gt; &lt;span class=&#34;mathjax-inline&#34;&gt;  $rendered  &lt;/span&gt;  end   end   end   assets/scss/components/_math.scss
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 //  .mathjax-inline  display: inline-block; //  font-size: 100%; //  vertical-align: middle; //  padding: 0.2em 0.4em; //  margin: 0; //  color: $primary; //  font-family: &#34;Times New Roman&#34;, serif; //   //  .mathjax-display  display: block; //  font-size: 100%; margin: 20px 0; //  padding: 0.5em; //  text-align: center; //  color: #1a73e8; //  font-family: &#34;Times New Roman&#34;, serif; //  border: 1px solid #e0e0e0; //  border-radius: 8px; //  background-color: #f4f6f9; //  box-shadow: 0 4px 8px rgba(0, 0, 0, 0.1); // `}).add({id:6,tag:"en",href:"/blogs/rope/",title:"RoPE",description:"RoPE Base ",content:`RoPE RoPE    
     
Transformer  Sinusoidal 
BERT  GPT  
 &ldquo;&rdquo; 
 mm  nn    mnm-n  nn  QQ  KK^\\top 
qm\\mathbf q_m  QQ  mm 
kn\\mathbf k_n  KK  nn 
   Score(qm,kn)=qmkn\\mathrmScore(\\mathbfq_m, \\mathbfk_n) = \\mathbfq_m^\\top \\cdot \\mathbfk_n     ,  mnm-n XLNET T5 DeBERTa  wii=1N\\w_i\\_i = 1^N  NN   wiw_i  ii  token
xii=1N\\x_i\\_i = 1^N  wii=1N\\w_i\\_i=1^N  embedding xix_i  ii  token wiw_i  dd 
 query keyvalue 
qm=fq(xm,m)kn=fk(xn,n)vn=fv(xn,n) \\beginalign \\boldsymbolq_m &amp;= \\boldsymbolf_\\boldsymbolq(x_m, m) \\\\ \\boldsymbolk_n &amp;= \\boldsymbolf_\\boldsymbolk(x_n, n)\\\\ \\boldsymbolv_n &amp;= \\boldsymbolf_\\boldsymbolv(x_n, n) \\endalign qm\\boldsymbolq_m  mm  token   xmx_m   mm   query  kn\\boldsymbolk_n  nn  token   xnx_n   nn   key  vn\\boldsymbolv_n  nn  token   xnx_n   nn   value   query  qm\\boldsymbolq_m  key  kn\\boldsymbolk_n  gg  gg   xmx_m  xnx_n   mnm-n 
fq(xm,m),fk(xk,n)=g(xm,xn,mn) \\beginequation \\langle \\mathbff_\\mathbfq(\\mathbfx_m, m), \\mathbff_\\mathbfk(\\mathbfx_k, n)\\rangle = g(\\mathbfx_m,\\mathbfx_n, m-n) \\endequation 
fq(xm,m)=(Wqxm)eimfk(xn,n)=(Wkxn)eing(xm,xn,mn)=Re[(Wqxm)(Wkxn)ei(mn)] \\beginaligned \\mathbff_\\mathbfq(\\mathbfx_m, m) &amp;= (\\mathbfW_q\\mathbfx_m) e^\\textim\\theta \\\\ \\\\ \\mathbff_\\mathbfk(\\mathbfx_n, n) &amp;= (\\mathbfW_k\\mathbfx_n) e^\\textin\\theta \\\\ \\\\ \\mathbfg(\\mathbfx_m,\\mathbfx_n, m-n) &amp;= \\mathrmRe\\bigg[(\\mathbfW_q\\mathbfx_m) (\\mathbfW_k\\mathbfx_n)^* e^\\texti(m-n)\\theta\\bigg] \\endaligned Re\\mathrmRe 
(Wkxn)(\\mathbfW_k\\mathbfx_n)^*  (Wkxn)(\\mathbfW_k\\mathbfx_n)^* 
fq(xm,m)=(cosmsinmsinmcosm)(Wq(1,1)Wq(1,2)Wq(2,1)Wq(2,2))(xm(1)xm(2))=(cosmsinmsinmcosm)(qm(1)qm(2)) \\beginaligned \\mathbff_\\mathbfq(\\mathbfx_m, m) &amp;=\\beginpmatrix\\cos m\\theta &amp; -\\sin m\\theta\\\\ \\sin m\\theta &amp; \\cos m\\theta\\endpmatrix \\beginpmatrixW_q^(1,1) &amp; W_q^(1,2) \\\\ W_q^(2,1) &amp; W_q^(2,2) \\endpmatrix \\beginpmatrixx_m^(1) \\\\ x_m^(2)\\endpmatrix\\\\ &amp;= \\beginpmatrix\\cos m\\theta &amp; -\\sin m\\theta\\\\ \\sin m\\theta &amp; \\cos m\\theta\\endpmatrix \\beginpmatrixq_m^(1) \\\\ q_m^(2)\\endpmatrix \\endaligned fk(xn,n)=(cosnsinnsinncosn)(Wk(1,1)Wk(1,2)Wk(2,1)Wk(2,2))(xm(1)xm(2))=(cosnsinnsinncosn)(km(1)km(2)) \\beginaligned \\mathbff_\\mathbfk(\\mathbfx_n, n) &amp;=\\beginpmatrix\\cos n\\theta &amp; -\\sin n\\theta\\\\ \\sin n\\theta &amp; \\cos n\\theta\\endpmatrix \\beginpmatrixW_k^(1,1) &amp; W_k^(1,2) \\\\ W_k^(2,1) &amp; W_k^(2,2) \\endpmatrix \\beginpmatrixx_m^(1) \\\\ x_m^(2)\\endpmatrix\\\\ &amp;= \\beginpmatrix\\cos n\\theta &amp; -\\sin n\\theta\\\\ \\sin n\\theta &amp; \\cos n\\theta\\endpmatrix \\beginpmatrixk_m^(1) \\\\ k_m^(2)\\endpmatrix \\endaligned g(xm,xn,mn)=(qm(1)qm(2))(cosmsinmsinmcosm)(cosnsinnsinncosn)(kn(1)kn(2))=(qm(1)qm(2))(cos(mn)sin(mn)sin(mn)cos(mn))(kn(1)kn(2))=(qm(1)qm(2))(cos(nm)sin(nm)sin(nm)cos(nm))(kn(1)kn(2))\\beginaligned \\mathbfg(\\mathbfx_m,\\mathbfx_n, m-n) &amp;= \\beginpmatrixq_m^(1) &amp; q_m^(2)\\endpmatrix \\beginpmatrix\\cos m\\theta &amp; \\sin m\\theta\\\\ -\\sin m\\theta &amp; \\cos m\\theta\\endpmatrix \\beginpmatrix\\cos n\\theta &amp; -\\sin n\\theta\\\\ \\sin n\\theta &amp; \\cos n\\theta\\endpmatrix \\beginpmatrixk_n^(1) \\\\ k_n^(2)\\endpmatrix\\\\[7pt] &amp;= \\beginpmatrixq_m^(1) &amp; q_m^(2)\\endpmatrix \\beginpmatrix\\cos (m-n)\\theta &amp; \\sin (m-n)\\theta\\\\ -\\sin( m-n)\\theta &amp; \\cos (m-n)\\theta\\endpmatrix \\beginpmatrixk_n^(1) \\\\ k_n^(2)\\endpmatrix\\ \\\\[7pt] &amp;= \\beginpmatrixq_m^(1) &amp; q_m^(2)\\endpmatrix \\beginpmatrix\\cos (n-m)\\theta &amp; -\\sin (n-m)\\theta\\\\ \\sin( n- m)\\theta &amp; \\cos (n-m)\\theta\\endpmatrix \\beginpmatrixk_n^(1) \\\\ k_n^(2)\\endpmatrix\\ \\endaligned   eix=cosx+isinxe^ix = \\cos x + i\\sin x qm=(qm(1)qm(2))=Wqxm=(Wq(1,1)Wq(1,2)Wq(2,1)Wq(2,2))(xm(1)xm(2)) \\beginalign \\boldq_m = \\beginpmatrix q_m^(1) \\\\ q_m^(2) \\endpmatrix = \\mathbfW_qx_m =\\beginpmatrixW_q^(1,1) &amp; W_q^(1,2) \\\\ W_q^(2,1) &amp; W_q^(2,2) \\endpmatrix \\beginpmatrix x_m^(1) \\\\ x_m^(2) \\endpmatrix \\\\ \\endalign  qm\\boldq_m 
qm=(qm(1)qm(2))=qm(1)+iqm(2) \\boldq_m =\\beginpmatrix q_m^(1) \\\\ q_m^(2) \\endpmatrix = q_m^(1) + iq_m^(2) fq(xm,m)=(Wqxm)eim=qmeim=(qm(1)+iqm(2))(cosm+isinm)=(qm(1)cosmqm(2)sinm)+i(qm(2)cosm+qm(1)sinm)=(qm(1)cosmqm(2)sinmqm(2)cosm+qm(1)sinm)=(cosmsinmsinmcosm)(qm(1)qm(2)) \\beginaligned \\mathbff_\\mathbfq(\\mathbfx_m, m) &amp;=(\\mathbfW_q\\mathbfx_m) e^\\textim\\theta = \\boldq_m e^\\textim\\theta\\\\[7pt] &amp;=(q_m^(1) + iq_m^(2)) \\cdot \\big(\\cos m\\theta + i\\sin m\\theta \\big) \\\\[7pt] &amp;=\\big(q_m^(1)\\cos m\\theta - q_m^(2) \\sin m\\theta \\big) + i\\big(q_m^(2)\\cos m\\theta + q_m^(1)\\sin m\\theta \\big) \\\\[7pt] &amp;=\\beginpmatrix q_m^(1)\\cos m\\theta - q_m^(2) \\sin m\\theta \\\\ q_m^(2)\\cos m\\theta + q_m^(1)\\sin m\\theta \\endpmatrix\\\\[7pt] &amp;=\\beginpmatrix \\cos m\\theta &amp; -\\sin m\\theta \\\\ \\sin m\\theta &amp; \\cos m\\theta \\endpmatrix \\beginpmatrix q_m^(1) \\\\ q_m^(2) \\endpmatrix \\endaligned g(xm,xn,mn)=Re[(Wqxm)(Wkxn)ei(mn)]=Re[(qm(1)+iqm(2))(kn(1)ikn(2))[cos(mn)+isin(mn)]]=Re[[(qm(1)kn(1)+qm(2)kn(2))+i(qm(2)kn(1)qm(1)kn(2))][cos(mn)+isin(mn)]]=(qm(1)kn(1)+qm(2)kn(2))cos(mn)(qm(2)kn(1)qm(1)kn(2))sin(mn)=(qm(1)qm(2))(cos(mn)sin(mn)sin(mn)cos(mn))(kn(1)kn(2))=(qm(1)qm(2))(cos(nm)sin(nm)sin(nm)cos(nm))(kn(1)kn(2)) \\beginaligned \\mathbfg(\\mathbfx_m,\\mathbfx_n, m-n) &amp;= \\mathrmRe\\bigg[(\\mathbfW_q\\mathbfx_m) (\\mathbfW_k\\mathbfx_n)^* e^\\texti(m-n)\\theta\\bigg] \\\\ &amp;=\\mathrmRe\\bigg [(q_m^(1) + iq_m^(2)) (k_n^(1) - ik_n^(2)) \\cdot \\big[\\cos (m-n)\\theta + i\\sin (m-n)\\theta \\big]\\bigg] \\\\[7pt] &amp;=\\mathrmRe\\bigg [ \\left[\\big(q_m^(1) k_n^(1)+ q_m^(2) k_n^(2)\\big)+ i\\big(q_m^(2) k_n^(1)- q_m^(1) k_n^(2) \\big)\\right]\\cdot \\big [\\cos (m-n)\\theta + i\\sin (m-n)\\theta \\big] \\bigg] \\\\[7pt] &amp;=\\left(q_m^(1) k_n^(1)+q_m^(2) k_n^(2)\\right) \\cos (m-n) \\theta-\\left(q_m^(2) k_n^(1)-q_m^(1) k_n^(2)\\right) \\sin (m-n) \\theta\\\\[7pt] &amp;= \\beginpmatrixq_m^(1) &amp; q_m^(2)\\endpmatrix \\beginpmatrix\\cos (m-n)\\theta &amp; \\sin (m-n)\\theta\\\\ -\\sin( m-n)\\theta &amp; \\cos (m-n)\\theta\\endpmatrix \\beginpmatrixk_n^(1) \\\\ k_n^(2)\\endpmatrix\\ \\\\[7pt] &amp;= \\beginpmatrixq_m^(1) &amp; q_m^(2)\\endpmatrix \\beginpmatrix\\cos (n-m)\\theta &amp; -\\sin (n-m)\\theta\\\\ \\sin( n- m)\\theta &amp; \\cos (n-m)\\theta\\endpmatrix \\beginpmatrixk_n^(1) \\\\ k_n^(2)\\endpmatrix\\\\ \\endaligned    ,  x\\mathbf x  y\\mathbf y  xy=xycos\\mathbfx^\\top \\cdot \\mathbfy = ||\\mathbfx|| \\cdot ||\\mathbfy|| \\cdot \\cos \\gamma   \\gamma        
Rm=(cosmsinmsinmcosm) \\beginaligned \\mathbf\\mathcalR_m =\\beginpmatrix\\cos m &amp; -\\sin m\\\\ \\sin m &amp; \\cos m\\endpmatrix \\endaligned  RmRn=Rnm\\mathbf\\mathcalR^\\top_m \\cdot \\mathbf\\mathcalR_n = \\mathbf\\mathcalR_n - m , nmn-m  
 x\\mathbf x  y\\mathbf y 
 , ,    x\\mathbf x  y\\mathbf y  mm  nn  (Rmx)(Rny)=xRnmy(\\mathbf\\mathcalR_m \\cdot \\mathbfx)^\\top \\cdot (\\mathbf\\mathcalR_n \\cdot \\mathbfy) = \\mathbfx^\\top \\cdot \\mathbf\\mathcalR_n - m \\cdot \\mathbfy  x\\mathbf x  y\\mathbf y ,  
 qm\\mathbfq_m  kn\\mathbfk_n     qm\\mathbfq_m  kn\\mathbfk_n    qm\\mathbfq_m  mm  Rmqm\\mathbf\\mathcalR_m \\cdot \\mathbf q_m  kn\\mathbfk_n  nn  Rnkn\\mathbf\\mathcalR_n \\cdot \\mathbf k_n ,   Score(qm,kn)=(Rmqm)(Rnkn)\\mathrmScore(\\mathbfq_m, \\mathbfk_n) = (\\mathbf\\mathcalR_m \\cdot \\mathbf q_m)^\\top \\cdot (\\mathbf\\mathcalR_n \\cdot \\mathbf k_n)  (cosm0sinm00000sinm0cosm0000000cosm1sinm10000sinm1cosm1000000cosmd/21sinmd/210000sinmd/21cosmd/21)Rm(q0q1q2q3qd2qd1) \\beginequation \\scriptsize\\underbrace\\beginpmatrix \\cos m\\theta_0 &amp; -\\sin m\\theta_0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\sin m\\theta_0 &amp; \\cos m\\theta_0 &amp; 0 &amp; 0 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\cos m\\theta_1 &amp; -\\sin m\\theta_1 &amp; \\cdots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sin m\\theta_1 &amp; \\cos m\\theta_1 &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\cos m\\theta_d/2-1 &amp; -\\sin m\\theta_d/2-1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\sin m\\theta_d/2-1 &amp; \\cos m\\theta_d/2-1 \\\\ \\endpmatrix_\\mathbf\\mathcalR_m \\beginpmatrixq_0 \\\\ q_1 \\\\ q_2 \\\\ q_3 \\\\ \\vdots \\\\ q_d-2 \\\\ q_d-1\\endpmatrix \\endequation , ii , i\\theta_i  Transformer  Sinusoidal ,  i=100002id\\theta_i = 10000^-\\frac2id  mm  qq  Rm\\mathbf\\mathcalR_m  nn  kk  Rn\\mathbf\\mathcalR_n  QQ , KK  Attention Attention :
(Rmq)(Rnk)=qRmRnk=qRnmk \\beginalign (\\mathbf\\mathcalR_m \\mathbfq)^\\top(\\mathbf\\mathcalR_n \\mathbfk) = \\mathbfq^\\top \\mathbf\\mathcalR_m^\\top\\mathbf\\mathcalR_n \\mathbfk = \\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfk \\endalign Rm\\mathbf\\mathcalR_m  ,  0 Rm\\mathbf\\mathcalR_m 
Rm=[cosm0sinm00000sinm0cosm0000000cosm1sinm10000sinm1cosm1000000cosmd/21sinmd/210000sinmd/21cosmd/21] \\beginequation \\mathbf\\mathcalR_m = \\scriptsize\\left [ \\beginarraycc: cc: cc: cc \\cos m\\theta_0 &amp; -\\sin m\\theta_0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\sin m\\theta_0 &amp; \\cos m\\theta_0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\hdashline 0 &amp; 0 &amp; \\cos m\\theta_1 &amp; -\\sin m\\theta_1 &amp; \\cdots &amp; \\cdots &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; \\sin m\\theta_1 &amp; \\cos m\\theta_1 &amp; \\cdots &amp; \\cdots &amp; 0 &amp; 0 \\\\ \\hdashline \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\ddots &amp; \\vdots &amp; \\vdots \\\\ \\hdashline 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\cdots &amp; \\cos m\\theta_d/2-1 &amp; -\\sin m\\theta_d/2-1 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; \\cdots &amp; \\cdots &amp; \\sin m\\theta_d/2-1 &amp; \\cos m\\theta_d/2-1 \\\\ \\endarray \\right] \\endequation   Rm\\mathbf\\mathcalR_m  RoPE
(q0q1q2q3qd2qd1)(cosm0cosm0cosm1cosm1cosmd/21cosmd/21)+(q1q0q3q2qd1qd2)(sinm0sinm0sinm1sinm1sinmd/21sinmd/21)(1) \\beginequation \\beginpmatrixq_0 \\\\ q_1 \\\\ q_2 \\\\ q_3 \\\\ \\vdots \\\\ q_d-2 \\\\ q_d-1 \\endpmatrix\\otimes\\beginpmatrix\\cos m\\theta_0 \\\\ \\cos m\\theta_0 \\\\ \\cos m\\theta_1 \\\\ \\cos m\\theta_1 \\\\ \\vdots \\\\ \\cos m\\theta_d/2-1 \\\\ \\cos m\\theta_d/2-1 \\endpmatrix + \\beginpmatrix-q_1 \\\\ q_0 \\\\ -q_3 \\\\ q_2 \\\\ \\vdots \\\\ -q_d-1 \\\\ q_d-2 \\endpmatrix\\otimes\\beginpmatrix\\sin m\\theta_0 \\\\ \\sin m\\theta_0 \\\\ \\sin m\\theta_1 \\\\ \\sin m\\theta_1 \\\\ \\vdots \\\\ \\sin m\\theta_d/2-1 \\\\ \\sin m\\theta_d/2-1 \\endpmatrix \\endequation\\tag1  \\otimes 
  k\\boldk  q\\boldq ,   , 
 q\\mathbfq  k\\mathbfk  ones   (1)
(Rmq)(Rnk)=qRnmk=2i=0d21cos(nm)i \\beginalign (\\mathbf\\mathcalR_m \\mathbfq)^\\top(\\mathbf\\mathcalR_n \\mathbfk) &amp;=\\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfk\\\\[7pt] &amp;= 2\\sum^\\fracd2-1_i = 0 \\cos (n-m) \\theta_i \\endalign  g(x)=2i=0d21cosxig(x) = 2\\sum^\\fracd2-1_i=0 \\cos x \\theta_i  i=100002id\\theta_i = 10000^-\\frac2id ii  i[0,d2)i \\in [0, \\fracd2) i\\theta_i  ii  i(104,1]\\theta_i \\in (10^-4, 1] i=0\\theta_i =0  g(x)=dg(x) = d  i=1\\theta_i =1  g(x)=dcosxg(x) = d\\cos x   cosxi\\cos x \\theta_i  xi2x2ix\\theta_i \\le \\frac\\pi2 \\Longrightarrow x \\le \\frac\\pi2\\theta_i  cosxi0\\cos x \\theta_i \\ge 0  cosxi\\cos x \\theta_i 
 i=d21i =\\fracd2-1 
 x210(48d)x \\le \\frac\\pi2\\cdot 10^(4-\\frac8d)  cosxd210\\cos x \\theta_\\fracd2-1 \\ge 0  cosxd21\\cos x \\theta_\\fracd2-1   x&gt;210(48d)x &gt; \\frac\\pi2\\cdot 10^(4-\\frac8d)  g(x)=2i=0d21cosxig(x) = 2\\sum^\\fracd2-1_i=0 \\cos x \\theta_i   g(x)=2i=0d21cosxig(x) = 2\\sum^\\fracd2-1_i=0 \\cos x \\theta_i  xx 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 def plot(plt_obj, head_size, seq_len, base=10000): &#34;&#34;&#34; plot &#34;&#34;&#34; theta = base ** (-np.arange(0, head_size, 2) / head_size) x = np.arange(seq_len) func_ = lambda t: np.cos(t * theta).sum() plt_obj.plot(x, np.fromiter((func_(i) for i in x), x.dtype)) plt_obj.set_title(f&#34;d:head_size, threshold: int(np.pi / 2 * 10 ** (4 - 8 / head_size))&#34;) plt_obj.set_ylabel(&#39;g(x)&#39;) plt_obj.set_xlabel(&#39;seq len&#39;) return axes if __name__ == &#39;__main__&#39;: _, axes = plt.subplots(nrows=2, ncols=2, figsize=(10, 10)) plot(axes[0, 0], head_size=256, seq_len=10000, base=1000) plot(axes[0, 1], head_size=256, seq_len=30000) plot(axes[1, 0], head_size=64, seq_len=10000) plot(axes[1, 1], head_size=64, seq_len=30000) plt.show()  RoPE  
 sin(x)\\sin (\\omega x)  T=2T= \\frac2\\pi\\omega  RoPE  sinmi\\sin m\\theta_i  cosmi\\cos m\\theta_i   i=b2id\\theta_i = b^-\\frac2id  i[0,1,2,...,d21]i \\in [0, 1,2,...,\\fracd2-1]  b=10000b=10000  ** **
T=2i=2b2id T = \\frac2\\pi\\theta_i = 2 \\pi b^\\frac2id  ii  
  (mn)2(m-n)\\theta \\ge 2\\pi  mn2m-n \\ge \\frac2\\pi\\theta  i=100002id\\theta_i = 10000^-\\frac2id 
i=0i=0  i=1\\theta_i = 1  mn2i=2&gt;6m-n \\ge \\frac2\\pi\\theta_i = 2\\pi&gt; 6  77  q\\mathbfq  k\\mathbfk ,  20482048  q\\mathbfq  k\\mathbfk  326 

i=d2i=\\fracd2  i=100001\\theta_i = 10000^-1  mn2i=2104&gt;6&gt;62831m-n \\ge \\frac2\\pi\\theta_i = 2*10^4\\pi&gt; 6&gt; 62831  6283262832  q\\mathbfq  k\\mathbfk ,  20482048 
,  q\\mathbfq  k\\mathbfk  1/4 ,  
Position Interpolation  Extending Context Window of Large Language Models via Positional Interpolation
Extending Context is Hardbut not Impossible
 [0,L)[0,L&#x27;)   [0,L)[0,L) 
 mm  mLL=mk\\fracm LL^\\prime = \\fracmk  i\\theta_i 
h(i)=1sb2id=1100002ids h\\left(\\theta_i\\right) =\\frac1sb^-\\frac2id = \\frac110000^\\frac2ids , s=LL=LLs= \\fracL_\\textL_\\text = \\fracL^\\primeL  s&gt;1s&gt;1  [0,2048)[0,2048)  [0,4096)[0,4096)  [0,4096)[0,4096)  [0,2048)[0,2048)  11  0.50.5  40964096  20482048     
:(1,2,,n1,n):(1,2,,n,n+1,,4n1,4n)(14,24,34,,n14,n) \\beginequation \\beginaligned&amp;\\text:\\,(1,2,\\cdots, n-1, n)\\\\[5pt] &amp;\\text:\\,(1,2,\\cdots, n,\\underbracen+1,\\cdots,4n-1,4n_\\text)\\xrightarrow\\quad\\text\\quad \\big(\\underbrace\\frac14,\\frac24,\\frac34_\\text,\\cdots, n-\\frac14, n\\big)\\endaligned \\endequation 
 PI 7B13B33B  65B LLaMA  32768  Pile  1000 
 
PI+
PI+
PI 

PI  ii 
()( 10  20 )
YaRN YaRN: Efficient Context Window Extension of Large Language Models
 RoPE  ii   i\\lambda_i  RoPE  embedding  ii  22\\pi  token 
i=2i=2b2id \\lambda_i=\\frac2 \\pi\\theta_i= 2 \\pi b^\\frac2 id NTK-aware NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation
NTK-awareNeural Tangent Kernel  RoPE   RoPE    

 q\\mathbfq  k\\mathbfk , , 
h(i)=(bs)2id=1100002ids2id h\\left(\\theta_i\\right) =(bs)^-\\frac2id= \\frac110000^\\frac2ids^\\frac2id , s=LL==LLs= \\fracL_\\textL_\\text = = \\fracL^\\primeL  s&gt;1s&gt;1 
 ss   ii  i\\theta_i &#x27; i=b2id\\theta_i = b^-\\frac2id i=(bs)2id\\theta_i&#x27;= (bs)^-\\frac2id  ii  rir_i  ri=ii=s2id(1s,1]r_\\theta_i =\\frac\\theta_i^\\prime\\theta_i = s^-\\frac2id \\in (\\frac1s,1] ii \\downarrow  rir_\\theta_i \\uparrow  ii  rir_\\theta_i  11  i=0i=0  i=1\\theta_i = 1 ,  ss   ii \\uparrow  rir_\\theta_i \\downarrow  ii  rir_\\theta_i  i=d2i=\\fracd2  i=110000s\\theta_i = \\frac110000s   [0,L)[0, L^\\prime)  [0,L)[0,L)  s2ids^-\\frac2id  NTK     
NTK-aware Scaled RoPE
 ii  d21\\fracd2-1   NTK-aware Scaled RoPE
h(i)=(bsdd2)2id=1100002ids2id2 h\\left(\\theta_i\\right) =(bs^\\fracdd-2)^-\\frac2id= \\frac110000^\\frac2ids^\\frac2id-2 NTK-by-parts   LL   \\lambda   r=Lr = \\fracL\\lambda 
  rir_i  LL   ii 
ri=Li=L2b2id r_i = \\fracL\\lambda_i = \\fracL2 \\pi b^\\frac2 id   \\gamma 
(ri)=1ri&gt;riri0ri&lt; \\gamma(r_i)= \\begincases 1 \\quad &amp; r_i &gt;\\beta \\\\[7pt] \\fracr_i-\\alpha\\beta-\\alpha \\quad &amp; \\alpha \\le r_i \\le \\beta \\\\[7pt] 0 \\quad &amp; r_i &lt;\\alpha \\\\[7pt] \\endcases  \\alpha  \\beta  irii \\downarrow \\ \\Longrightarrow\\ r_i \\uparrow  i\\theta_i 
h(i)=[1(ri)]is+(ri)i h\\left(\\theta_i\\right)=\\bigg [1-\\gamma(r_i)\\bigg] \\frac\\theta_is+\\gamma(r_i) \\theta_i  s=LL=LLs= \\fracL_\\textL_\\text = \\fracL^\\primeL ri&gt;r_i&gt;\\beta  \\beta  ii  ri\\alpha \\le r_i \\le \\beta  ri&lt;r_i&lt;\\alpha ,  \\alpha   ii   \\alpha  \\beta  Llama  \\alpha  \\beta  =1\\alpha=1  =32\\beta=32 
NTK-by-parts  i\\theta_i  Attention  RoPE 
Code
Llama 3  NTK-by-parts
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 Compute the inverse frequencies (\\theta) inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device) / dim)) low_freq_wavelen = old_context_len / low_freq_factor high_freq_wavelen = old_context_len / high_freq_factor wavelen = 2 * math.pi / inv_freq # wavelen &lt; high_freq_wavelen: do nothing # wavelen &gt; low_freq_wavelen: divide by factor inv_freq_llama = torch.where(wavelen &gt; low_freq_wavelen, inv_freq / factor, inv_freq) # otherwise: interpolate between the two, using a smooth factor smooth_factor = (old_context_len / wavelen - low_freq_factor) / (high_freq_factor - low_freq_factor) smoothed_inv_freq = (1 - smooth_factor) * inv_freq_llama / factor + smooth_factor * inv_freq_llama is_medium_freq = ~(wavelen &lt; high_freq_wavelen) * ~(wavelen &gt; low_freq_wavelen) inv_freq_llama = torch.where(is_medium_freq, smoothed_inv_freq, inv_freq_llama) Dynamically NTK Dynamically Scaled RoPE further increases performance of long context LLaMA with zero fine-tuning

  NTK-Aware Interpolation   base
h(i)=[b(s+1)dd2]2id=1100002id(s+1)2id2 \\beginalign &amp;h\\left(\\theta_i\\right) = [b(\\alpha s-\\alpha+1)^\\fracdd-2]^-\\frac2id= \\frac110000^\\frac2id(\\alpha s-\\alpha+1)^\\frac2id-2 \\\\[7pt] \\endalign s=max1,LLs = \\max\\1, \\fracL^\\primeL\\  LL^\\prime    \\alpha ,  &gt;1\\alpha&gt;1  =2\\alpha=2  Code
1 2 3 4 5 6 seq_len: default to max_position_embeddings, e.g. at init time seq_len = seq_len if seq_len is not None and seq_len &gt; max_position_embeddings else max_position_embeddings # Compute the inverse frequencies base = base * ((factor * seq_len / max_position_embeddings) - (factor - 1)) ** (dim / (dim - 2)) inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, dtype=torch.int64).float().to(device) / dim)) YaRN NTK-by-parts + Attention scaling
Attention scaling by temperature

softmax(qmTkntd) \\beginalign \\textsoftmax\\bigg( \\frac\\mathbfq_m^T \\mathbfk_nt \\sqrtd \\bigg) \\endalign  Llama 
1t=0.1ln(s)+1 \\beginalign \\sqrt\\frac1t= 0.1 \\mathrmln\\left(s\\right)+1 \\\\ \\endalign Code
 \\alpha  \\beta   \\alpha  \\beta  embedding   ii_\\alpha  ii_\\beta 
ri=L2b2ididlnL22lnb\\beta \\le r_i_\\beta =\\fracL2 \\pi b^\\frac2 i_\\betad \\quad \\Longrightarrow \\quad i_\\beta\\le \\fracd \\ln \\fracL2 \\pi \\beta2\\ln b ri=L2b2ididlnL22lnb\\alpha \\ge r_i_\\alpha =\\fracL2 \\pi b^\\frac2 i_\\alphad \\quad \\Longrightarrow \\quad i_\\alpha\\ge \\fracd \\ln \\fracL2 \\pi \\alpha2\\ln b 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # Compute the inverse frequencies def find_correction_dim(num_rotations, dim, base, max_position_embeddings): &#34;&#34;&#34;Inverse dimension formula to find the dimension based on the number of rotations&#34;&#34;&#34; return (dim * math.log(max_position_embeddings / (num_rotations * 2 * math.pi))) / (2 * math.log(base)) def find_correction_range(low_rot, high_rot, dim, base, max_position_embeddings): &#34;&#34;&#34;Find dimension range bounds based on rotations&#34;&#34;&#34; low = math.floor(find_correction_dim(low_rot, dim, base, max_position_embeddings)) high = math.ceil(find_correction_dim(high_rot, dim, base, max_position_embeddings)) return max(low, 0), min(high, dim - 1) # Optional config options # beta_fast/beta_slow: as suggested in the paper, default to 32/1 (correspondingly) beta_fast = config.rope_scaling.get(&#34;beta_fast&#34;) or 32 beta_slow = config.rope_scaling.get(&#34;beta_slow&#34;) or 1 low, high = find_correction_range(beta_fast, beta_slow, dim, base, max_position_embeddings)  embedding  [0,i][0,i_\\beta]  (i,i)(i_\\beta, i_\\alpha)  [i,d][i_\\alpha, d] 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 def linear_ramp_factor(min, max, dim): if min == max: max += 0.001 # Prevent singularity linear_func = (torch.arange(dim, dtype=torch.float32) - min) / (max - min) ramp_func = torch.clamp(linear_func, 0, 1) return ramp_func # Note on variable naming: &#34;interpolation&#34; comes from the original technique, where we interpolate the position IDs # to expand the possible context length. In other words, interpolation = apply scaling factor. pos_freqs = base ** (torch.arange(0, dim, 2).float().to(device) / dim) inv_freq_extrapolation = 1.0 / pos_freqs inv_freq_interpolation = 1.0 / (factor * pos_freqs) # Get n-dimensional rotational scaling corrected for extrapolation inv_freq_extrapolation_factor = 1 - linear_ramp_factor(low, high, dim // 2).float().to(device) inv_freq = ( inv_freq_interpolation * (1 - inv_freq_extrapolation_factor) + inv_freq_extrapolation * inv_freq_extrapolation_factor )  attention scaling
1 attention_factor = 0.1 * math.log(factor) + 1.0 inv_freq  position_ids  cos  sin  attention_factor,  cos  sin 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # inv_freq: [h_d/2] # inv_freq_expanded: [B, h_d/2, 1] # position_ids_expanded: [B, L, 1] # freqs: [B, L, h_d/2] freqs = (inv_freq_expanded.float() @ position_ids_expanded.float()).transpose(1, 2) # emb: [B, L, h_d] emb = torch.cat((freqs, freqs), dim=-1) cos = emb.cos() sin = emb.sin() # Advanced RoPE types (e.g. yarn) apply a post-processing scaling factor, equivalent to scaling attention # cos: [B, L, h_d] cos = cos * attention_factor sin = sin * attention_factor  qn\\mathbfq_n  kn\\mathbfk_n 1 2 3 4 5 6 7 8 9 10 def rotate_half(x): &#34;&#34;&#34;Rotates half the hidden dims of the input.&#34;&#34;&#34; x1 = x[..., : x.shape[-1] // 2] x2 = x[..., x.shape[-1] // 2 :] return torch.cat((-x2, x1), dim=-1) cos = cos.unsqueeze(unsqueeze_dim) sin = sin.unsqueeze(unsqueeze_dim) q_embed = (q * cos) + (rotate_half(q) * sin) k_embed = (k * cos) + (rotate_half(k) * sin) ReRoPE RoPE  Attention  Decoder  :
(010210321032103210L2L1L23210) \\beginequation\\beginpmatrix0 &amp; \\\\ 1 &amp; 0 &amp; \\\\ 2 &amp; 1 &amp; 0 &amp;\\\\ 3 &amp; 2 &amp; 1 &amp; 0 &amp; \\\\ \\ddots &amp; 3 &amp; 2 &amp; 1 &amp; 0 &amp; \\\\ \\ddots &amp; \\ddots &amp; 3 &amp; 2 &amp; 1 &amp; 0 &amp; \\\\ \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots \\\\ \\tinyL - 2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; \\ddots \\\\ \\tinyL - 1 &amp; \\tinyL - 2 &amp; \\ddots &amp; \\ddots &amp; \\ddots &amp; 3 &amp; 2 &amp; 1 &amp; 0 &amp; \\\\ \\endpmatrix\\endequation , LL 
, 
Leaky ReRoPE  ww  11  1k\\frac1k 
(010210210w1210ww1210w+1kw210w+2kw+1k210w+2k210w+2kw+1kww1210w+L1wkw+2kw+1kww1210) \\beginequation \\beginpmatrix \\colorred0 &amp; \\\\ \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreenw &amp; \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\tinyw + \\frac1k &amp; \\colorgreenw &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\tinyw + \\frac2k &amp; \\colorgreen\\tinyw + \\frac1k &amp; \\colorgreen\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\ddots &amp; \\colorgreen\\tinyw + \\frac2k &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\\\ \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\tinyw + \\frac2k &amp; \\colorgreen\\tinyw + \\frac1k &amp; \\colorgreenw &amp; \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\tinyw + \\fracL-1-wk &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\tinyw + \\frac2k &amp; \\colorgreen\\tinyw + \\frac1k &amp; \\colorgreenw &amp; \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\endpmatrix \\endequation ReRoPERectified RoPE  kk\\to\\infty 
(010210210w1210ww1210ww210ww210w210wwww1210wwwww1210) \\beginequation \\beginpmatrix \\colorred0 &amp; \\\\ \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreenw &amp; \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreenw &amp; \\colorgreenw &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreenw &amp; \\colorgreenw &amp; \\colorgreen\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\ddots &amp; \\colorgreenw &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\colorred\\ddots &amp; \\\\ \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreenw &amp; \\colorgreenw &amp; \\colorgreenw &amp; \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\colorgreenw &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreen\\ddots &amp; \\colorgreenw &amp; \\colorgreenw &amp; \\colorgreenw &amp; \\colorred\\tinyw - 1 &amp; \\colorred\\ddots &amp; \\colorred2 &amp; \\colorred1 &amp; \\colorred0 &amp; \\\\ \\endpmatrix \\endequation 
 Attention  q\\mathbfq  k\\mathbfk  ww  
Score(qm,kn)=qmRnmkn(mn&lt;w)qmRnmwk+wkn(mnw) \\mathrmScore(\\mathbfq_m, \\mathbfk_n) = \\left\\ \\beginaligned &amp;\\boldq^\\top_m \\cdot \\mathbf\\mathcalR_n - m \\cdot \\boldk_n \\qquad &amp;(m - n \\lt w) \\\\ &amp;\\boldq^\\top_m \\cdot \\mathbf\\mathcalR_\\fracn-m-wk+w \\cdot \\boldk_n \\qquad &amp;(m - n \\ge w) \\endaligned \\right.  Attention  flash attention 
LongRoPE LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens

  RoPE    token  RoPE 
  RoPE   token 
 RoPE   token   RoPE   nn  token RoPE 
[cos(n0),sin(n0),cos(n1),,cos(nd21),sin(nd21)] \\beginalign [\\cos(n\\theta_0), \\quad \\sin(n\\theta_0),\\quad \\cos(n\\theta_1),\\quad \\dots,\\quad \\cos(n\\theta_\\fracd2-1),\\quad \\sin(n\\theta_\\fracd2-1)] \\endalign dd : embedding  nin\\theta_i  nn  i=b2id\\theta_i = b^-\\frac2id  s=LLs=\\fracL^\\primeL  LL^\\prime  LL   \\lambda  ss  RoPE :
[cos(n0),sin(n0),cos(n1),,cos(nd21),sin(nd21)] \\beginalign [\\cos(\\fracn\\lambda\\theta_0), \\quad \\sin(\\fracn\\lambda\\theta_0),\\quad \\cos(\\fracn\\lambda\\theta_1),\\quad \\dots,\\quad \\cos(\\fracn\\lambda\\theta_\\fracd2-1),\\quad \\sin(\\fracn\\lambda\\theta_\\fracd2-1)] \\endalign PI: 
=s \\lambda = s  &ldquo;&rdquo; token 
NTK:  RoPE 
=si \\lambda = s^i NTK    44\\times 
YaRN RoPE PI NTK
YaRN  RoPE  LLM 
LongRoPE RoPE  token 
 LL  X\\mathbfX ,  xX\\mathbfx\\in\\mathbfX token  LL 
 I(^i,n^)\\mathbbI(\\hat\\lambda_i,\\hatn)  ^i\\hat\\lambda_i  embedding  n^\\hatn  token , 
argminxX;xLL(LLM(RoPE,X))whereRoPE(n)=[,cos(I(^i,n^)ni),sin(I(^i,n^)ni),],i=0,,d21;n[0,x);whereI(^i,n^)=1n&lt;n^1inn^ \\beginalign &amp; \\arg \\min_\\mathbfx\\in\\mathbfX; |\\mathbfx|\\geq L \\mathcalL \\left(\\textLLM(\\textRoPE,\\mathbfX)\\right)\\\\[7pt] \\textwhere \\quad &amp; \\textRoPE_(n) =\\left [\\quad \\cdots,\\quad \\cos\\left(\\mathbbI(\\hat\\lambda_i,\\hatn)\\cdot n \\theta_i\\right),\\quad \\sin\\left(\\mathbbI(\\hat\\lambda_i,\\hatn) \\cdot n \\theta_i\\right), \\quad \\cdots \\quad \\right] , \\quad i = 0,\\cdots,\\fracd2-1;\\quad n\\in [0,|\\mathbfx|);\\\\[7pt] \\textwhere\\quad &amp; \\mathbbI(\\hat\\lambda_i,\\hatn)=\\begincases1&amp;\\quad n &lt;\\hatn\\\\\\frac1\\lambda_i&amp;\\quad n\\ge\\hatn\\endcases \\endalign  n^1\\hatn-1  token  ^i\\hat\\lambda_i  token  nn^ n\\ge\\hatn , 
 LL  I(^i,n^)i[1,d]\\left\\\\mathbbI(\\hat\\lambda_i,\\hatn)\\right\\_i\\in [1,d] ,  X\\mathbfX  next token 


	n^\\hatn  0,1,2,4,8,12,16,20,24,28,32,64,128,2560, 1, 2, 4, 8, 12, 16, 20, 24, 28, 32, 64,128, 256 ,  n^=0\\hatn = 0  token  i\\lambda_i 

:  PINTK  YaRN  RoPE 
 RoPE   ii+1_i \\le _i+1  i\\lambda_i  RoPE .

88 \\times  finetune &gt;8&gt; 8 \\times  finetune  2048k2048k 
 LongRoPE  8k8k  256k256k 
 128k128k  256k256k  3232 \\times  6464 \\times Finetune 256k
 128k128k  RoPE  LLaMA2  400400   RoPE  256k256k  600600   2048k2048k  256k256k  LLM  2048k2048k 


 LLM  RoPE  4K4K  8K8K  \\lambda 
LLM  RoPE 
Base  Base of RoPE Bounds Context Length
RoPE 
i=b2id \\theta_i = b^-\\frac2id  bb  1000010000  Long Context  b=10000b=10000  bb 
 bb 
 RoPE 
1 Token 
2 Token 


 qm\\mathbfq_m  kn\\mathbfk_n  nmnm  qmRnmkn\\boldq^\\top_m \\cdot \\mathbf\\mathcalR_n - m \\cdot \\boldk_n  Token 
:
qRd\\mathbfq \\in \\mathbbR^d  \\mu  2\\sigma^2 k=q+\\mathbfk^* =q+\\epsilon  \\epsilon  00  k\\mathbfk^*  q\\mathbfq  token kRd\\mathbfk \\in \\mathbbR^d  q\\mathbfq  k\\mathbfk  token Eq,k,[qRnmkqRnmk]0 \\beginequation\\mathbbE_\\mathbfq,\\mathbfk,\\mathbf\\varepsilon\\big [\\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfk^* - \\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfk\\big] \\geq 0\\endequation Eq,k,[qRnm(q+)qRnmk]=Eq[qRnmq]Eq,k[qRnmk]=Eq[qRnmq]Eq[q]RnmEk[k]=Eq[qRnmq]21Rnm1=Eq[i=0d/21(q2i2+q2i+12)cos(nm)i]i=0d/2122cos(nm)i=i=0d/212(2+2)cos(nm)ii=0d/2122cos(nm)i=i=0d/2122cos(nm)i \\beginequation\\beginaligned &amp;\\,\\mathbbE_\\mathbfq,\\mathbfk,\\mathbf\\varepsilon\\big [\\mathbfq^\\top \\mathbf\\mathcalR_n-m (\\mathbfq + \\mathbf\\varepsilon) - \\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfk\\big] \\\\[7pt] =&amp;\\, \\mathbbE_\\mathbfq\\big [\\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfq\\big] - \\mathbbE_\\mathbfq,\\mathbfk\\big[\\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfk\\big] \\\\[5pt] =&amp;\\, \\mathbbE_\\mathbfq\\big [\\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfq\\big] - \\mathbbE_\\mathbfq[\\mathbfq]^\\top\\mathbf\\mathcalR_n-m \\mathbbE_\\mathbfk[\\mathbfk] \\\\[5pt] =&amp;\\, \\mathbbE_\\mathbfq\\big [\\mathbfq^\\top \\mathbf\\mathcalR_n-m \\mathbfq\\big] - \\mu^2\\mathbf1^\\top\\mathbf\\mathcalR_n-m \\mathbf1 \\\\[5pt] =&amp; \\mathbbE_\\mathbfq\\left [\\sum_i = 0^d/2-1 (q_2i^2 + q_2i+1^2)\\cos (n-m)\\theta_i\\right] - \\sum_i = 0^d/2-1 2\\mu^2\\cos (n-m)\\theta_i \\\\[5pt] =&amp; \\sum_i = 0^d/2-1 2(\\mu^2 + \\sigma^2)\\cos (n-m)\\theta_i - \\sum_i = 0^d/2-1 2\\mu^2\\cos (n-m)\\theta_i \\\\[5pt] =&amp; \\sum_i = 0^d/2-1 2\\sigma^2\\cos (n-m)\\theta_i \\\\ \\endaligned\\endequation i=0d/21cosmi0,m0,1,2,,L1 \\beginequation\\sum_i = 0^d/2-1 \\cos m\\theta_i \\geq 0,\\quad m\\in\\0,1,2,\\cdots, L-1\\\\endequation  Bm,=i=0d/21cosmiB_m,\\theta= \\sum_i=0^d/2-1 \\cos m\\theta_i  Bm,B_m,\\theta  tokens  tokens  mm  bb  i\\theta_i  Bm,B_m,\\theta  tokens  tokens 
 Bm,0B_m,\\theta \\ge 0  RoPE  \\theta  LL_\\theta 
L=supLBm,0m0,1,2,,L1 L_\\theta = \\sup\\L|B_m,\\theta \\ge 0 \\quad m\\in\\0,1,2,\\cdots, L-1\\  i=b2id\\theta_i = b^-\\frac2id  LL  bb 
bL=infbBm,0m0,1,2,,L1 b_L = \\inf\\ b|B_m,\\theta \\ge 0 \\quad m\\in\\0,1,2,\\cdots, L-1\\  Bm,B_m,\\theta 

fb(m)=i=0d/21cosmb2i/d01cosmbsds=t=mbsmb1mcosttlnbdt \\beginalignf_b(m) = \\sum_i = 0^d/2-1 \\cos m b^-2i/d\\approx \\int_0^1 \\cos m b^-s ds \\xlongequal\\textt = mb^-s \\int_mb^-1^m \\frac\\cos tt \\ln bdt\\endalign  Ci(x)=xcosttdt\\textCi(x) = -\\int_x^\\infty \\frac\\cos tt dt  Trigonometric integral , 
fb(m)Ci(m)Ci(mb1)lnb \\beginequationf_b(m) \\approx \\frac\\textCi(m) - \\textCi(mb^-1)\\ln b\\endequation Ci(x)\\textCi(x)  x0=0.6165x_0=0.6165\\cdots  m1m \\ge 1  Ci(m)1/2|\\textCi(m)|\\leq 1/2 
 Ci(mb1)0m0,1,2,,L1\\textCi(mb^-1)\\leq 0 \\quad m\\in\\0,1,2,\\cdots,L-1\\  mb1[0,x0]bmx0mb^-1 \\in [0,x_0] \\Longrightarrow b\\ge \\fracmx_0 
bLx02L b\\ge \\fracLx_0 \\approx 2L  dd \\rightarrow \\infin  dd  bb  fb(m)f_b(m)  LL  m=0,1,2,,L1m=0,1,2,\\cdots,L-1  fb(m)f_b(m)  bb 
Reference Transformer 2 Transformer 12 ReRoPE Transformer 16 Transformer 18RoPE  Extending Context Window of Large Language Models via Positional Interpolation Extending Context is Hardbut not Impossible YaRN: Efficient Context Window Extension of Large Language Models NTK-Aware Scaled RoPE allows LLaMA models to have extended (8k+) context size without any fine-tuning and minimal perplexity degradation Dynamically Scaled RoPE further increases performance of long context LLaMA with zero fine-tuning LongRoPE: Extending LLM Context Window Beyond 2 Million Tokens Base of RoPE Bounds Context Length`}).add({id:7,tag:"en",href:"/blogs/searchengine/basics/",title:"SearchEngine-1-",description:"wangshusen-",content:` query
SUGSUG 

GoogleAmazonYouTubeB 


/&amp;
 GoogleYouTube
 
 &amp;  
 
 33  33 


 /  10%10 \\%  &amp;  

 Amazon
Google Scholar
Yelp
Booking
ZillowRedfinAirbnb
LinkedInBoss 

:






 ////




 

 EAT




Relevance    qq   dd 
 uu ( (q,d)(q,d) 
 dd  qq    qq 
 qq  dd  qq  (q,d)(q,d) 

:   tf-idf  BERT  
  BERT    BERT  
  BERT  44 
 
EAT


EAT EAT
Expertise
Authoritativeness
Trustworthiness
 your money or your life EAT 
Your money


Your life



 












BERT  NLP CLIP  finetune


 /
query = 
query = 
query = 

 


///




 

&quot; 
&quot; 

()


 BERT 
BERT 

 
 44 
 () 82 
BERT 
 


 
 
 









 BERT  bad case


PageRank xx  xx 
PageRank ? B
A.	B  (EAT)	C 	D 	E 
 





 A/B 


 GSBDCG 
&amp;  Daily Active UserDAU Monthly Active UserMAU

Search DAU
Feed DAU

 = Search DAU / APP  DAU




  77 : APP  77 

Feb 1  11  APP
 11  88  Feb 2~8  APP  11 
Feb 1   77  = 8/1=80%\\text8  / \\text1  = 80\\% 

 11 
 77 
 3030 
 nn  nn  1730\\text1 \\le \\text7 \\le \\text30  APP 
APP  nn 
 nn 
 nn 
 LT7  LT30 LT  NN  OR
 


 AB  holdout 
 AB 
&amp;  10%10\\% 
 =  / 
  70%70\\% 
 =  / 

 \\le 
3 
  
     
 


 xx  xx 

 
 

       

 vs 


 


 10 2  AB 


 -&gt;   A/B test 


 Side by Side  






 50%50\\% 


 GSB(Good Same Bad
 GoodG
 SameS
 BadB
 300 GSB  50:220:3050:220:30  G&gt;BG &gt; B 
 
 qq  uu  cc  kk  d1,,dkd_1, \\cdots ,d_k 

 kk  kk  k=20k=20 
 score(q,u,c,di)\\textscore(q, u, c, d_i)  did_i 
 ()


DCG@k=i=1kscore(q,u,c,di)log2(i+1). \\mathrmDCG@k =\\sum_i = 1^k\\frac\\mathrmscore(q, u, c, d_i)\\log_2(i+1). DCG 
score(q,u,c,di)\\mathrmscore(q,u,c,d_i)  did_i 
log2(i+1)\\log_2(i+1) 
 DCG 
 DCG
 DCG
 &amp;

APP  DAU DAU
Search DAUAPP DAU)
 100%100\\% 

 11  77  3030 
LT7LT30 
APP 





 A/B  holdout 

 A/B 

()
()



Side by side  GSB 


 AB AB 
 AB 


  DCG 
Side by side 

 GSB DCG
 




?
 = DAU  
?
DAU 
 


 
 
   
 
  
Tokenization  term
 &gt; //

term
 key 
 key 
Term Weight 
 &gt; //
 &gt;  &gt; 
 &quot; 
 &quot; 
 
Term Weight
 term 

  ()


 NLP /
 
 

 
 







 
 qq  q1,,qk q_1^\\prime,\\cdots,q_k^\\prime  q,q1,,qkq, q_1^\\prime,\\cdots,q_k^\\prime 

)

qq = LV
dd =  LOUIS VUITTON 
qq  dd  qq  dd 
qq  qq 

 = 
 160  120  20  = 
Information Retrieval  qq  qq  d\\d\\  qq  dd .
BERT qq  dd  xqx_q  zdz_d  xqx_q ANN zdz_d 
KVKV qq  qListdq \\rightarrow \\textList \\langle d \\rangle  key-value qq 
 
(keyterm value) tt (term) tt 
 qq  t1,,tkt_1, \\cdots, t_k 
 tit_i  Di\\mathcalD_i ,  tit_i 
 kk  D1Dk\\mathcalD_1 \\cap \\cdots \\cap \\mathcalD_k 
 qq 
 




 ANN , 
KV 
key
value
Ranking 
 
BERT4/6/12
EAT

()



Reference https://github.com/wangshusen/SearchEngine`}).add({id:8,tag:"en",href:"/blogs/searchengine/rel/",title:"SearchEngine-2-",description:"wangshusen-",content:` 
\\text \\rightarrow \\text  \\rightarrow \\text  \\rightarrow \\text  
 (q,d)(q,d)  44  55  44 

 (q,d)(q,d) 

 V.S.   vs  
 dd  qq  qq 
 qq  dd 
qq = 
dd =  ASML 
 qq  dd 
qq = 
dd = 
 
OK
qq = 
dd = 
OK
qq = 
dd =  2015 
 /
  qq  dd 


 =


&amp; \\text \\in \\text  
 qq = dd = 
 qq = dd = 
 
 qq =  dd =
 qq =  dd =
 
 
 qq = dd = 
 qq = dd =
 
 qq =  dd =   qq =  dd =  &ldquo;  
 qq = dd =  top 10
 qq =  dd = 
 dd  qq  qq 
  dd  qq  qq 

 qq 


   (q,d)(q,d)  50%50\\% ** 50%50\\% **
 50%
 1
 qq =  dd = 
 dd  qq 
 50%50\\% 
 2
 qq =  dd = 
 dd  qq 
 50%50\\% 
  (q,d)(q,d) ****

 1
 qq =  dd = 
 dd  qq 

 2
 qq =  dd = 
 dd  qq 
 &quot; 
  dd  qq  qq 
 qq  dd  22 

qq  dd 

 dd  qq  dd  qq 
 44 
 &ldquo;&rdquo;  22 
 &ldquo;&rdquo;  22 
 44 
 &ldquo;&rdquo;  33  &quot;  22  55 
 
 nn  nn 
 qq  kk  (q,d1),,(q,dk)(q, d_1) , \\cdots, (q, d_k)  44  
 Topk 

 (q,d)(q, d) 

 80%80\\% 
 ground truth
 1000010000  200200 
AUCDCG Pointwise AUCArea Under the Curve
Pairwise PNRPositive to Negative Ratio
Listwise DCGDiscounted Cumulative Gain
: AUC  PNR 
DCG  DCG
Pointwise        (q,d)(q, d) 
 44  22  0/1
 y=1y = 1  y=0y = 0  p[0,1]p\\in [0,1]  pp 

F1AUC AUC 
 &amp;  ROC 
 **AUC Area Under the Curve**
AUC =0.5= 0.5  
 AUC  0.8 ~ 0.95 
Pairwise  
 pp )
 66  p1p2p6p_1 \\ge p_2 \\ge \\cdots \\ge p_6  kk  (k2)=k!2!(k2)!\\beginpmatrix k\\\\ 2 \\endpmatrix= \\frack!2!\\times (k-2)! 
k=6k=6  (62)=15\\beginpmatrix 6\\\\ 2 \\endpmatrix = 15 
 22  (2,3)(2,3) , (2,4)(2,4)  1313 
 PNR=132\\textPNR=\\frac132 ,\\langle\\text,\\text\\rangle  pair
 13:213:2  Pairwise 
Listwise  
Pairwise  v.s. Listwise   nn  d1,,dnd_1, \\cdots, d_n 
d1,,dnd_1, \\cdots, d_n  y1,,yny_1, \\cdots, y_n  [0,1][0,1] 
 y1y2yny_1 \\ge y_2 \\ge \\cdots \\ge y_n  pairwise  listwise 
 pairwise  listwise 
pairwise : 
listwise  listwise 
CGCumulative Gain  nn  y1,,yny_1, \\cdots, y_n 
 kk (kn)(k\\ll n) 
Cumulative Gain CG@k:
CG@k=i=1kyi CG@k = \\sum^k_i = 1y_i CG@k 
 yy  kk  kk 
 kk 
DCGDiscounted Cumulative Gain  nn  y1,,yny_1, \\cdots, y_n Discounted Cumulative Gain DCG@k:
DCG@k=i=1kyilog2(i+1) \\mathrmDCG@k =\\sum_i = 1^k\\fracy_i\\log_2(i+1) DCG@k ?
 yy  kk  kk 
 kk 
  pointwisepairwiselistwise 
pointwise (q,d)(q, d) 
pairwise (q,d1)(q, d_1)  (q,d2)(q, d_2) 
listwise (q,d1),(q,d2),,(q,dn)(q, d_1),(q, d_2), \\cdots, (q,d_n) 
 (point&amp;pair-wise) 
 AUC  PNR pointwise  pairwise 
 44  AUCAUC Macro F1  Micro F1
 44 
 &gt;&gt;&gt;\\text &gt; \\text &gt; \\text &gt;\\text  44  44 
 &ldquo;&rdquo;  &ldquo;&rdquo; &ldquo;&rdquo;
 (listwise)  session:  qq  d1,,dnd_1, \\cdots, d_n  session
 session kk  d1,,dkd_1, \\cdots, d_k kk  k=20k = 20 
 2020 
 kk  k=40k = 40  kk  k=20k = 20 
 y1,,yny_1, \\cdots, y_n 

 DCG@k=i=1kyilog2(i+1)\\mathrmDCG@k=\\sum_i=1^k\\fracy_i\\log_2(i+1)  session 
 DCG@k  session 

NDCG@k=DCG@kIDCG@k\\mathsfNDCG@k=\\frac\\mathsfDCG@k\\mathsfIDCG@k NDCG  DCGN  Normalized
 IDCG@k  DCG@k   NDCG@k  00  11  NDCG  DCG NDCG 


DCG NDCG DCG  NDCG 

 NDCG  NDCG=DCG/IDCG\\textNDCG= \\textDCG/ \\textIDCG  DCG  IDCG  DCG 
DCG  NDCG  DCG 
TF-IDFBM25   

TF-IDFBM25OkaTPBM25TP

2020  BERT 
 
 + BERT  
  BERT  BERT  BERT  
  BERT  44 / 66 /   

 q=q = \\text  Q=,,Q = \\\\text, \\text, \\text\\ QQ  dd  qq  dd 
TF-IDF  BM25 
TF-IDF Term Frequency (TF)  QQ :   Q=,,Q = \\\\text, \\text, \\text\\ 
tQt \\in Q term t=t = \\text 
tft,d\\texttf_t,d  tt  dd 
tft,d\\texttf_t,d  tt  dd 
tQtft,d\\sum_t \\in Q\\texttf_t,d  qq  dd 
 tft,d\\texttf_t,d  dd  tft,d\\texttf_t,d 
 dd  d=d+dd^\\prime=d+d 
TF  tft,d=2tft,d\\texttf_t,d^\\prime =2\\cdot \\texttf_t,d  dd^\\prime  dd 
 dd  ldl_d  tQtft,dld\\sum_t \\in Q\\frac\\texttf_t,dl_d 
ldl_d  dd   tQtft,dld\\sum_t \\in Q\\frac\\texttf_t,dl_d  tt 
?
term weight
&gt;&gt;\\text &gt; \\text &gt; \\text t=t =\\text 
t=t =\\text 
t=t =\\text 
 term weight term 
 tt  &lt;&lt;\\text &lt; \\text &lt; \\text 
Document Frequency (DF) dft\\textdf_t  tt  NN 
0dftN0\\le \\textdf_t \\le N dft\\textdf_t  tt 
stop word DF  NN 
 DF 
Inverse Document FrequencyIDF Inverse Document Frequency (IDF :
idft=logNdft \\mathrmidf_t =\\mathrmlog\\frac N\\mathrmdf_t IDF 
 &quot;  IDF 
 &quot;  IDF 
idft\\mathrmidf_t  tt  idft\\mathrmidf_t  tt 
 tQtft,dldidft\\sum_t \\in Q\\frac\\texttf_t,dl_d \\cdot \\mathrmidf_t 
Term Frequency-Inverse Document FrequencyTF-IDF  qq  QQ  dd  TF-IDF 
TFIDF(Q,d)=tQtft,dldidft \\mathrmTFIDF(Q, d)=\\sum_t\\in\\mathcalQ\\frac\\mathrmtf_t, dl_d\\cdot\\mathrm~idf_t TF-IDF 
TFIDF(Q,d)=tQlog(1+tft,d)idft \\mathrmTFIDF(Q, d)=\\sum_t\\in\\mathcalQ\\log(1+\\mathrmtf_t, d) \\cdot\\mathrm~idf_t Okapi Best Match 25 (BM25) BM25  TF-IDF 
tQtft,d(k+1)tft,d+k(1b+bldmean(ld))ln(1+Ndft+0.5dft+0.5) \\sum_t\\in\\mathcalQ\\frac\\mathrmtf_t, d\\cdot(k+1)\\mathrmtf_t, d+k\\cdot\\left(1-b+b\\cdot\\fracl_d\\mathrmmean(l_d)\\right) \\cdot \\ln\\left(1+\\fracN-\\mathrmdf_t+0.5\\mathrmdf_t+0.5\\right) kk  bb  k[1.2,2]k \\in[1.2,2]  b=0.75b=0.75 
BM25 
  BM25 BM25 
 (bag of words) TF-IDF  BM25  
 1
 /  /  /   /  /  /   2
 /  /  /   /  /  /  
 Latent Semantic Analysis (LSA)Latent Dirichlet Allocation (LDA) 
RNNBERTGPT 
 (Term Proximity) 

 Q=,Q =\\\\text, \\text\\  d=d= \\text  TF-IDF  BM25 
 
: QQ  dd    QQ  dd 
OkaTP :
 tt  dd  O(t,d)O(t,d) 
 dd  2727  8484  9898 
 O(t,d)=27,84,98O(t,d)=\\27,84,98\\ 
 O(t,d)O(t,d)  O(t,d)=tft,d|\\mathcalO(t,d)|=\\mathrmtf_t,d 
tt  tt^\\prime  QQ   TP
tp(t,t,d)=oO(t,d)oO(t,d)1(oo)2. \\mathrmtp(t, t&#x27;, d)=\\sum_o\\in O(t, d)\\sum_o&#x27;\\in O(t&#x27;, d)\\frac1(o-o&#x27;)^2.  t,tQt,t^\\prime \\in Q  dd   tp(t,t,d)\\mathrmtp(t,t^\\prime,d) 
OkaTP :
t,tQ,tttp(t,t,d)(k+1)tp(t,t,d)+k(1b+bldmean(ld))min(idft,idft) \\sum_t, t^\\prime\\in\\mathcalQ, t\\neq t\\frac\\operatornametp(t, t^\\prime, d)\\cdot(k+1)\\operatornametp(t, t^\\prime, d)+k\\cdot\\left(1-b+b\\cdot\\fracl_d\\operatornamemean(l_d)\\right) \\cdot \\min(\\mathrmidf_t,\\mathrmidf_t^\\prime)  BM25  Term Frequency tft,d\\mathrmtf_t, d  TP tp(t,t,d)\\mathrmtp(t,t&#x27;,d) TP 
 term  IDF  
 term 
  TF-IDFBM25 
TF
IDF

 OkaTP 
 QQ  
 QQ  
     

BERT   BERT  qq  dd 
/ BERT  BERT 
 BERT  
 BERT  4 
  BERT 22  44  BERT
 
  BERT   BERT  self attention 
Anchor Query token token token  Embedding 
 token  33  token 
token embedding token 
position embedding token 
segment embedding  position embedding  [SEP]  33 
 nn  token nn  00 ~ 11 

 v.s.   token
  22 
/ token
 Embedding Table 

 BERT  baseline
 tokens

 token 
 WoBERT
token 
BERT /token 
 token  128128  256256 
 token 
token  256256 tokens 128128 tokens
  (q,d)(q,d)  score (q,d)(q,d)  BERT 

 Redis  KV  q,d,score\\langle q, d, score\\rangle 
 id (q,d)(q,d)  key (score)  value
 (q,d)(q,d)  (q,d)(q,d) 
 TB  LRULeast Recently Used
 float32  int8
 float32 32bits  float32  int8 
post-training quantizationPTQ float32  int8
quantization-aware trainingQAT
 token 


 token  128128  9696  BERT  
 BERT 

 

 key  idvalue 


 / BERT 
 
 token 
 KV  q,d,score\\langle q, d, score\\rangle 
 float32  int8
 token 
 BERT 
 
    dd  zdz_d  (d,zd)(d, z_d) 
 (q,d)(q,d)  dd  zdz_d ,key  idvalue 
 qq  xqx_q  xq,zd\\langle x_q, z_d \\rangle ( sigmoid ) (q,d)(q,d) 
BERT   BERT  BERT
 44 
pretrain MLMMask Language Model()
post pretrain  
fine tuning
distillation
fine tuning  qq  dd 
 (q,d,y)(q,d,y) (
    
 pp  yy   
 (q,d)(q,d)  pp 
pp  yy 
 pp  yy    yy 
 (q,d1,y1)(q,d_1,y_1)  (q,d2,y2)(q,d_2,y_2)  qq  dd  y1&gt;y2y_1&gt;y_2 
 p1p_1  p2p_2  p1&gt;p2p_1&gt;p_2  p1&lt;p2p_1&lt;p_2 
  (q1,d1,y1),(qn,dn,yn)(q_1,d_1,y_1) ,\\cdots (q_n,d_n,y_n)  yiy_i  yi[0,1]y_i \\in [0,1] 
 (qi,di)(q_i,d_i)    pip_i 
 1ni=1nlog(yi,pi)\\frac1n\\sum_i=1^n\\log(y_i,p_i)  pip_i  yiy_i 

MSE_Loss(yi,pi)=12(yipi)2 \\mathrmMSE\\_Loss(y_i, p_i)=\\frac12(y_i-p_i)^2  soft label )
CE_Loss(yi,pi)=yilnpi(1yi)ln(1pi) \\mathrmCE\\_Loss(y_i, p_i)=-y_i\\cdot\\ln p_i-(1-y_i)\\cdot\\ln(1-p_i)  CE Loss  yy  00  11  00 ~ 11 
  qq  kk  d1,,dkd_1, \\cdots, d_k 
 (q,di)(q,d_i)  yiy_i  pip_i 
 yiy_i  pip_i 
 pip_i  yiy_i 
 yi&gt;yjy_i&gt;y_j  pipjp_i-p_j 
 pipjp_i \\ge p_j  (i,j)(i,j)  
 pi&lt;pjp_i&lt;p_j  (i,j)(i,j)  
 &gt;  pipjp_i-p_j  Pairwise logistic 
(i,j):yi&gt;yjln[1+exp((pipj))]. \\sum_(i, j): y_i &gt; y_j\\ln\\left [1+\\exp\\left(-\\gamma\\cdot(p_i-p_j)\\right)\\right]. pipjp_i-p_j  (i,j)(i,j) 
\\gamma  &gt;0&gt;0  logistic 
 kk  kk  kk  yy 
  MSE  CE AUC 
 pairwise logistic 

 AUC    CE  pairwise logistic 
post pretrain Zou et al. Pre-trained language model based ranking in Baidu search. In KDD , 2021. Zou et al. Pre-trained language model-based retrieval and ranking for web search. ACM Transactions on the Web, 2022.  -&gt;  -&gt;  -&gt; 

 (q,d)(q,d)  4848  BERT 10 
 x\\mathbf x  y^\\haty  y^\\haty  ()
 (q,d,y^)(q,d, \\haty)  MLM 
 1 (q,d)(q, d)  qq 
 qq  qq 
 qq  d1,,dn d_1, \\cdots, d_n 
 nn 
 2  1  (q,d)(q,d) 
 (q,d)(q,d)  x\\mathbfx  x\\mathbfx  44 
 (q,d,x)(q,d,\\mathbfx)   x\\mathbfx 
 yy  x\\mathbfx ()
 yy  x\\mathbfx  y^=t(x)\\haty = t(\\mathbfx) ,  t()t(\\cdot)  yy  t()t(\\cdot)  y^\\haty  y^\\haty  yy 
 (q,d)(q,d)  yy 
 (q,d)(q,d)  x\\mathbfx 
  (x,y)(\\mathbfx,y)  t(x)t(\\mathbfx)  yy  t()t(\\cdot) (GBDT/ x\\mathbfx  yy  y^\\haty  yy 
 t()t(\\cdot) 

 t()t(\\cdot)   (q,d)(q,d) 
 BERT BERT  -&gt;  t()t(\\cdot) -&gt;  t()t(\\cdot)  -&gt;  BERT 
 (q,d,x)(q,d,\\mathbfx)  y^=t(x)\\haty = t(\\mathbfx)  (q,d,y^)(q,d,\\haty)  BERT 
 3  (q,d,y^)(q,d,\\haty)  y^\\haty 
 BERT  (q,d,y^)(q,d,\\haty) 
 33  33 
 y^\\haty  AUC 

 MLM 

  -&gt; 
 (q,d,y)(q,d, y) 
 (q,d,y^)(q,d,\\haty) 

 x\\mathbfx  yy 
(q,d)(q,d) 
 x\\mathbfx  yy 
 y^\\haty 
distillation 

BERT  (q,d)(q,d) BERT 
 44 ~ 1212  BERT  22 ~ 44  BERT BERT

 22 ~ 1212   4848 better  48  BERT  teacher

4848  1212 AUC  2%2\\%  4848  1212  1010 AUC  4848  44 AUC  0.5%0.5\\%  ?
 4848  BERT  teacher ()
Teacher  student  4848  teacher 2424  1212  teacher  (q,d)(q,d)  teacher  (q,d)(q,d)  y^\\haty 
  11  AUC  1010   (q,d,y^)(q,d,\\haty) 
 11 epoch 11  22 epoch 22  11 epoch)  
Student 
 student teacher )
 (q,d,y^)(q,d,\\haty)  student
 student 

 student  teacher 
 y^\\haty 

 4848  -&gt; 1212  -&gt; 44   4848  -&gt; 44   
 pretrain MLM  BERT 
post pretrain GBDT  x\\mathrmx  y^\\haty  BERT 
fine tuning
distillation (q,d)(q, d) 
Reference https://github.com/wangshusen/SearchEngine`}).add({id:9,tag:"en",href:"/blogs/transformer/",title:"Transformer",description:"Transformer ",content:` Transformer 
Encoder Decoder Encoder  
 Encoder   Decoder  Encoder-Decoder   Seq2Seq   Transformer  Encoder   Encoder  Transformer  Encoder  (auto-encoding)   (Bi-directional)
 Encoder 
BERT
1:  (Masked Language Modeling, MLM) 2: (Next Sentence Prediction, NSP) DistilBERT (knowledge distillation) DistilBERT  40% 60%  97% 
RoBERTa
    NSP  XLM (XLM)  GPT  BERT  MLM MLM  (Translation Language Modeling, TLM)XLM  NLU 
XLM-RoBERTa XLM  RoBERTaXLM-RoBERTa (XLM-R)  Common Crawl  2.5 TB  MLM  XLM  TLM  XLM  BERT 
ALBERTALBERT  Encoder  NLU 
   NSP  ELECTRAMLM ELECTRA 
 MLM  30   DeBERTaDeBERTa 
 (Self-Attention)   softmax DeBERTa  SuperGLUE  Decoder   Decoder  Transformer  Decoder  (auto-regressive) 
 Decoder  Decoder 
GPT Transformer Decoder  BookCorpus GPT 
GPT-2OpenAI  GPT-2
CTRLGPT-2  (prompt)  Transformer  (Conditional Transformer Language, CTRL) 
GPT-3 GPT-2  100 GPT-3  1750  (few-shot learning) 
GPT-Neo / GPT-J-6B GPT-3  GPT-3  EleutherAI GPT  GPT-Neo  GPT-J-6B  1.32.760  GPT-3 
Encoder-Decoder  Encoder-Decoder  Seq2Seq  Transformer Encoder  Decoder 
Encoder-Decoder  Encoder  Decoder 
Encoder-Decoder 
T5 NLU  NLG  Seq2Seq  Encoder Decoder T5  MLM  SuperGLUE  Seq2Seq  110  T5 
BART BERT  GPT  Encoder  Decoder  NLU  NLG 
M2M-100M2M-100  100 
BigBird O(n2)O(n^2) Transformer  BigBird  512  4096
Transformer Layer Transformer  Encoder  layer  Block  22 sublayer
Block
multi-head self-attention position-wise feed-forward network querykey  value  layer 
Add &amp; Norm
 residual connection
 Transformer  xRd\\mathbf x \\in \\mathbb R^d  sublayer(x)Rd\\mathrmsublayer (\\mathbf x )\\in \\mathbb R^d  x+sublayer(x)Rd\\mathbf x +\\mathrmsublayer (\\mathbf x )\\in \\mathbb R^d 
 layer normalization ( Layer Normalization)
Transformer  dd 
Self-Attention 
ll 
dd : hidden size
 XRld\\mathbf X \\in \\mathbbR^l\\times d  WQRddk\\mathbf W^Q \\in \\mathbbR^d\\times d_k  WKRddk\\mathbf W^K\\in\\mathbbR^d\\times d_k  WVRddv\\mathbf W^V \\in \\mathbbR^d \\times d_v  Q\\mathbf Q  K\\mathbf K  V\\mathbf V 

 X=[X1X2]R2d\\mathbf X = \\beginbmatrix\\mathbf X_1 &amp;\\mathbf X_2 \\endbmatrix\\in \\mathbbR^2\\times d , XiR1d\\mathbf X_i \\in \\mathbbR^1\\times d X1\\mathbf X_1  WQ\\mathbf W^Q  q1R1dk\\mathbf q_1 \\in \\mathbbR^1\\times d_k X1\\mathbf X_1  WK\\mathbf W^K  k1R1dk\\mathbf k_1 \\in \\mathbbR^1\\times d_k X1\\mathbf X_1  WV\\mathbf W^V  v1R1dv\\mathbf v_1 \\in \\mathbbR^1\\times d_v 

Scaled Dot-product Attention  Query, QRldk\\mathbfQ\\in\\mathbbR^l\\times d_k (key) token  query
 Key KRldk\\mathbfK\\in\\mathbbR^l\\times d_k 
 Value, VRldv\\mathbfV\\in\\mathbbR^l\\times d_v  value  value
Attention(Q,K,V)=softmax(QKdk)V \\beginalign \\textAttention(\\mathbfQ,\\mathbfK,\\mathbfV) = \\textsoftmax\\left(\\frac\\mathbfQ\\mathbfK^\\top\\sqrtd_k\\right)\\mathbfV \\endalign 
: QKRll\\mathbfQ\\mathbfK^\\top \\in\\mathbbR^l\\times l Scaled Dot-product Attention  queries  keys 
 dk\\sqrtd_k   Softmax   softmax(QKdk)Rll\\mathrmsoftmax\\left(\\frac\\mathbfQ\\mathbfK^\\top \\sqrtd_k\\right) \\in\\mathbbR^l\\times l  wijw_ij  ii  token(query)  jj  token(key) 
token embeddings
 wijw_ij  value  v1,,vl\\mathbfv_1,\\cdots,\\mathbfv_l  ii  token(query)  xi=jwijvj\\mathbfx_i^\\prime = \\sum_j w_ij\\mathbfv_j 
Attention(qi,K,V)=j=1l1Zexp(qi,kjdk)vj \\beginalign \\textAttention(\\mathbfq_i,\\mathbfK,\\mathbfV) = \\sum_j=1^l \\frac1Z\\exp\\left(\\frac\\langle\\mathbfq_i, \\mathbfk_j\\rangle\\sqrtd_k\\right)\\mathbfv_j \\endalign  ZZ  K\\mathbf K , V\\mathbf V  key  value 
Scaled Dot-product Attention  qi\\mathbfq_i  query  kj\\mathbfk_j  softmax  qi\\mathbfq_i  vj\\mathbfv_j  dvd_v   dkd_k 
 dk\\sqrtd_k 
scaled 
 softmax 
queries  keys  dkd_k  1 dk\\sqrtd_k :

 u\\mathbf u  v\\mathbf v  dd  00  11 
 uiu_i  viv_i  uiviu_iv_i  E[uivi]=E[ui]E[vi]=0\\mathrmE[u_iv_i] = \\mathrmE[u_i] E [v_i] = 0  Var(uivi)=E[(uivi)2](E[uivi])2=E[ui2]E[vi2]=1\\mathrmVar(u_iv_i)=\\mathrmE[(u_iv_i)^2] - (\\mathrmE [u_iv_i])^2= \\mathrmE[u_i^2] \\mathrmE[v_i^2]=1  u\\mathbf u  v\\mathbf v  uiviu_iv_i 
uv=i=1duivi \\beginalign \\mathbf u \\cdot \\mathbf v = \\sum ^d_i = 1u_iv_i \\endalign  E[uv]=0\\mathrmE[\\mathbf u \\cdot \\mathbf v] = 0  Var[uv]=dVar(uivi)=d\\mathrmVar[\\mathbf u \\cdot \\mathbf v] = d \\cdot \\mathrmVar(u_iv_i)= d 
Var(uvdk)=dk(dk)2=1 \\beginalign \\mathrmVar(\\frac\\mathbfu \\cdot \\mathbfv\\sqrtd_k) = \\fracd_k(\\sqrtd_k)^2 = 1 \\endalign 0Softmax 0
 dk\\sqrtd_k  softmax  1 0 0
softmax  0~1 
 x=(x1,x2,...,xn)x = ( x_1 , x_2 , ..., x_n ) ,  xkx_k  yky_k  xkx_k  yky_k  1 
 x=[a,a,2a]T\\mathbf x = [a, a, 2a]^T ,  aa  y^3\\hat y_3 
1 2 3 4 5 6 for a in (1,10,100): print(nn.Softmax((torch.tensor([a, a, 2*a]).float()))) tensor([0.2119, 0.2119, 0.5761]) tensor([4.5396e-05, 4.5396e-05, 9.9991e-01]) tensor([3.7835e-44, 3.7835e-44, 1.0000e+00])  xx  xkx_k  softmax  yy  yky_k  1 0
 dk\\sqrtd_k 
 dk\\sqrtd_k  softmax  1 0 0
Attention 
 causal_mask  -\\infin  softmax  00  e=0e^\\infin=0 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 import torch import torch.nn.functional as F from math import sqrt def scaled_dot_product_attention(query, key, value, causal_mask=None): # [B,h,L,d/h] dim_k = query.size(-1) scores = torch.bmm(query, key.transpose(-1, -2)) / sqrt(dim_k) if causal_mask is not None: # -inf mask_value = torch.finfo(attn_weights.dtype).min # [a11, -inf, ..., -inf] # [a21, a22, ..., -inf] # ... # [an1, an2, ..., ann] scores = torch.where(causal_mask, attn_weights, mask_value) # softmax () # [b11, 0, ..., 0] # [b21, b22, ..., 0] # ... # [bn1, bn2, ..., bnn] attn_weights = F.softmax(scores, dim=-1) # dropout attn_weights = self.attn_dropout(attn_weights) attn_output = torch.bmm(attn_weights, value) return attn_output mask 
1 2 3 4 # causal_mask  causal_mask = torch.tril( torch.ones((query_length, query_length), dtype=torch.bool) ).view(1, 1, query_length, query_length) Multi-headed attention headi=Attention(Q,K,V)MultiHead(Q,K,V)=Concat(head1,...,headh) \\beginalign \\mathrmhead_i &amp;= \\textAttention(\\mathbfQ,\\mathbfK,\\mathbfV)\\\\[7pt] \\textMultiHead(\\mathbfQ,\\mathbfK,\\mathbfV) &amp;= \\textConcat(\\mathrmhead_1,...,\\mathrmhead_h) \\endalign /  

 Q\\mathbfQ , K\\mathbfK , V\\mathbfV  [batch_size, seq_len, head_dim]  head_dim 
 head_dim  embed_dim  token  BERT  1212  768/12=64768/12=64 
1 2 3 4 5 6 7 8 9 10 11 12 13 from torch import nn class AttentionHead(nn.Module): def __init__(self, embed_dim, head_dim): super().__init__() self.q = nn.Linear(embed_dim, head_dim) self.k = nn.Linear(embed_dim, head_dim) self.v = nn.Linear(embed_dim, head_dim) def forward(self, query, key, value, query_mask=None, key_mask=None, mask=None): attn_outputs = scaled_dot_product_attention( self.q(query), self.k(key), self.v(value), query_mask, key_mask, mask) return attn_outputs  Multi-head Attention 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 lass MultiHeadAttention(nn.Module): def __init__(self, config): super().__init__() embed_dim = config.hidden_size num_heads = config.num_attention_heads head_dim = embed_dim // num_heads self.heads = nn.ModuleList( [AttentionHead(embed_dim, head_dim) for _ in range(num_heads)] ) self.output_linear = nn.Linear(embed_dim, embed_dim) def forward(self, query, key, value, query_mask=None, key_mask=None, mask=None): x = torch.cat([ h(query, key, value, query_mask, key_mask, mask) for h in self.heads ], dim=-1) x = self.output_linear(x) return x MHA &amp; MQA &amp; GQA
MHAMulti-head Attention
  hh  QueryKey  Value 
MQAMulti-Query Attention
Fast Transformer Decoding: One Write-Head is All You Need
MQA  Key  Value  Query  Key  Value 
GQAGrouped-Query Attention
GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints
GQA  G  Key  Value GQA-G  GG  grouped-query attention
GQA-1  Key  Value MQA GQA-H  MHA GQA  MHA  MQA 
The Feed-Forward Layer (FFN) Transformer Encoder/Decoder  position-wise feed-forward layer
 4  GELU 
 xRBLhidden_size\\mathbf x \\in \\mathbbR^B\\times L \\times \\mathrmhidden\\_size  MLP BL, hidden_size
1 2 3 4 5 6 7 8 9 10 11 12 13 14 class FeedForward(nn.Module): def __init__(self, config): super().__init__() self.linear_1 = nn.Linear(config.hidden_size, config.intermediate_size) self.linear_2 = nn.Linear(config.intermediate_size, config.hidden_size) self.gelu = nn.GELU() self.dropout = nn.Dropout(config.hidden_dropout_prob) def forward(self, x): x = self.linear_1(x) x = self.gelu(x) x = self.linear_2(x) x = self.dropout(x) return x Layer Normalization Layer Normalization   
Skip Connections 
 Transformer Encoder/Decoder  Layer Normalization :
Post layer normalization
PostNorm:xt+1=Norm(xt+Ft(xt)) \\beginalign \\textPost Norm: \\quad \\boldsymbolx_t+1 = \\textNorm(\\boldsymbolx_t + F_t(\\boldsymbolx_t)) \\endalign Transformer  Add&amp;Norm  Post-LN Layer normalization  Skip Connections   (learning rate warm-up) 
Pre layer normalization
PreNorm:xt+1=xt+Ft(Norm(xt)) \\beginalign \\textPre Norm:  \\quad \\boldsymbolx_t+1 = \\boldsymbolx_t + F_t(\\textNorm(\\boldsymbolx_t))\\\\ \\endalign  Layer Normalization  Skip Connections Pre Norm  Post Norm
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 class TransformerEncoderLayer(nn.Module): def __init__(self, config): super().__init__() self.layer_norm_1 = nn.LayerNorm(config.hidden_size) self.layer_norm_2 = nn.LayerNorm(config.hidden_size) self.attention = MultiHeadAttention(config) self.feed_forward = FeedForward(config) def forward(self, x, mask=None): # Apply layer normalization and then copy input into query, key, value hidden_state = self.layer_norm_1(x) # Apply attention with a skip connection x = x + self.attention(hidden_state, hidden_state, hidden_state, mask=mask) # Apply feed-forward layer with a skip connection x = x + self.feed_forward(self.layer_norm_2(x)) return x Post Norm  xx , F(x)F(x)  11  x+F(x)x+F(x)  22  Normalization  11  Post Norm 
xt+1=xt+Ft(xt)2 \\beginequation x_t+1 = \\fracx_t + F_t(x_t)\\sqrt2 \\endequation 
xl=xl12+Fl1(xl1)2=xl22+Fl2(xl2)2+Fl1(xl1)2==x02l/2+F0(x0)2l/2+F1(x1)2(l1)/2+F2(x2)2(l2)/2++Fl1(xl1)21/2 \\beginequation\\beginaligned x_l =&amp;\\, \\fracx_l-1\\sqrt2 + \\fracF_l-1(x_l-1)\\sqrt2 \\\\ =&amp;\\, \\fracx_l-22 + \\fracF_l-2(x_l-2)2 + \\fracF_l-1(x_l-1)\\sqrt2 \\\\[7pt] =&amp;\\, \\cdots \\\\[7pt] =&amp;\\,\\fracx_02^l/2 + \\fracF_0(x_0)2^l/2 + \\fracF_1(x_1)2^(l-1)/2 + \\fracF_2(x_2)2^(l-2)/2 + \\cdots + \\fracF_l-1(x_l-1)2^1/2 \\endaligned\\endequation  Post Norm 
Pre Norm Pre Norm
xl=x0+F0(x0)+F1(x1/2)+F2(x2/3)++Fl1(xl1/l) \\beginequation x_l = x_0 + F_0(x_0) + F_1(x_1/\\sqrt2) + F_2(x_2/\\sqrt3) + \\cdots + F_l-1(x_l-1/\\sqrtl)\\endequation  Post Norm  xlx_l  xlx_l  Normalization
 LL  Pre Norm  LL  Post Norm 
xt+1=xt+Ft(Norm(xt))=xt1+Ft1(Norm(xt1))+Ft(Norm(xt))==x0+F0(Norm(x0))++Ft1(Norm(xt1))+Ft(Norm(xt)) \\beginaligned \\mathbfx_t+1 =&amp;\\,\\mathbfx_t + F_t(\\textNorm(\\mathbfx_t)) \\\\[7pt] =&amp;\\, \\mathbfx_t-1 + F_t-1(\\textNorm(\\mathbfx_t-1)) + F_t(\\textNorm(\\mathbfx_t)) \\\\[7pt] =&amp;\\, \\cdots \\\\[7pt] =&amp;\\, \\mathbfx_0 + F_0 (\\textNorm(\\mathbfx_0)) + \\cdots + F_t-1(\\textNorm(\\mathbfx_t-1)) + F_t(\\textNorm(\\mathbfx_t)) \\endaligned  xt+1=O(t+1) \\mathbfx_t+1=\\mathscrO(t+1)  tt 
Ft(Norm(xt))+Ft+1(Norm(xt+1))Ft(Norm(xt))+Ft+1(Norm(xt))=(FtFt+1)(Norm(xt)) \\beginaligned &amp;\\, F_t(\\textNorm(\\mathbfx_t)) + F_t+1(\\textNorm(\\mathbfx_t+1)) \\\\[7pt] \\approx&amp;\\, F_t(\\textNorm(\\mathbfx_t)) + F_t+1(\\textNorm(\\mathbfx_t)) \\\\[7pt] =&amp;\\, (F_t\\oplus F_t+1)(\\textNorm(\\mathbfx_t)) \\endaligned  tt  xt\\mathbfx_t  xt+1\\mathbfx_t+1  Ft+1(Norm(xt+1))F_t+1(\\textNorm(\\mathbfx_t+1))  Ft+1(Norm(xt))F_t+1(\\textNorm(\\mathbfx_t))  tt  t+1t+1  tt  Pre Norm 
DeepNet:
However, the gradients of Pre-LN at bottom layers tend to be larger than at top layers, leading to a degradation in performance compared with Post-LN.
Pre Norm bottom layers Pre Norm degradation Post Norm.
Warmup 
f(x+x)f(x)+xf(x),x \\beginequationf(x+\\Delta x) \\approx f(x) + \\langle\\nabla_x f(x), \\Delta x\\rangle\\endequation  f(x+x)f(x)f(x+\\Delta x) - f(x) 
Warmup  0 
 Wamrup
Adam 
 Post Norm  Wamruploss loss  NAN  Wamrup  Pre Norm  Warmup 
Reference Attention Is All You Need Transformers The Illustrated Transformer The Annotated Transformer Transformer Pre NormPost Norm BERT0.02`}).add({id:10,tag:"en",href:"/blogs/transformer-attention/",title:"Transformer Attention",description:"Transformer Attention",content:`KV Cache KV Cache 
KV Cache  Decoder  Decoder  Causal Mask attention KK  VV 
KV Cache   11  token
Att(Q,K,V)=softmax(q1k1)v1 \\mathrmAtt(Q, K, V) = \\textsoftmax(\\mathbfq_1 \\mathbfk_1^\\top ) \\mathbfv_1  : Q=(q1)R1dQ = \\left( \\mathbfq_1 \\right) \\in \\mathbbR^1\\times d  K=(k1)R1dK = \\left( \\mathbfk_1 \\right) \\in \\mathbbR^1\\times d  V=(v1)R1dV = \\left( \\mathbfv_1 \\right) \\in \\mathbbR^1\\times d  22  token Attention 
Att(Q,K,V)=softmax([q1k1q2k1q2k2])[v1v2]=[softmax(q1k1)0softmax(q2k1)softmax(q2k2)][v1v2]=[softmax(q1k1)v1softmax(q2k1)v1+softmax(q2k2)v2]=[Att1(Q,K,V)Att2(Q,K,V)] \\beginaligned \\mathrm Att(Q, K, V) &amp; = \\mathrmsoftmax( \\beginbmatrix \\mathbfq_1\\mathbfk_1^\\top&amp;-\\infty \\\\ \\mathbfq_2\\mathbfk_1^\\top&amp;\\mathbfq_2\\mathbfk_2^\\top \\endbmatrix) \\beginbmatrix\\mathbfv_1\\\\\\mathbfv_2\\endbmatrix \\\\[7pt] &amp; =\\beginbmatrix \\textsoftmax( \\mathbfq_1\\mathbfk_1^\\top)&amp;0\\\\ \\textsoftmax(\\mathbfq_2\\mathbfk_1^\\top)&amp;\\textsoftmax(\\mathbfq_2\\mathbfk_2^\\top) \\endbmatrix \\beginbmatrix\\mathbfv_1\\\\\\mathbfv_2\\endbmatrix \\\\[7pt] &amp;=\\beginbmatrix \\mathrmsoftmax(\\mathbfq_1\\mathbfk_1^\\top)\\mathbfv_1\\\\[7pt] \\mathrmsoftmax(\\mathbfq_2\\mathbfk_1^\\top)\\mathbfv_1+\\mathrmsoftmax(\\mathbfq_2\\mathbfk_2^\\top)\\mathbfv_2 \\endbmatrix \\\\[7pt] &amp; = \\beginbmatrix \\mathrmAtt_1(Q, K, V) \\\\ \\mathrmAtt_2(Q, K, V) \\endbmatrix \\endaligned  Att1(Q,K,V)\\mathrmAtt_1(Q,K,V)  Att2(Q,K,V)\\mathrmAtt_2(Q,K,V)  Attention  11 , 22  qi,kiRd\\mathbfq_i, \\mathbfk_i \\in \\mathbb R^d Att1(Q,K,V)=softmax(q1k1)v1Att2(Q,K,V)=softmax(q2k1)v1+softmax(q2k2)v2 \\beginaligned \\mathrmAtt_1(Q, K, V) &amp;= \\mathrmsoftmax(\\mathbfq_1\\mathbfk_1^\\top)\\mathbfv_1 \\\\[7pt] \\mathrmAtt_2(Q, K, V) &amp;= \\mathrmsoftmax(\\mathbfq_2\\mathbfk_1^\\top)\\mathbfv_1+\\mathrmsoftmax(\\mathbfq_2\\mathbfk_2^\\top)\\mathbfv_2 \\endaligned  Decoder  Causal Mask q2k1\\mathbfq_2\\mathbfk_1^\\top  mask
 33  token 
Att(Q,K,V)=[Att1(Q,K,V)Att2(Q,K,V)Att3(Q,K,V)] \\beginaligned \\mathrm Att(Q, K, V) = \\beginbmatrix \\mathrmAtt_1(Q, K, V) \\\\ \\mathrmAtt_2(Q, K, V) \\\\ \\mathrmAtt_3(Q, K, V) \\endbmatrix \\endaligned  Att1(Q,K,V)\\mathrmAtt_1(Q,K,V)  Att2(Q,K,V)\\mathrmAtt_2(Q,K,V)  Att3(Q,K,V)\\mathrmAtt_3(Q,K,V)  Attention  11 , 22 , 33  qi,kiRd\\mathbfq_i, \\mathbfk_i \\in \\mathbb R^d Att1(Q,K,V)=softmax(q1k1)v1Att2(Q,K,V)=softmax(q2k1)v1+softmax(q2k2)v2Att3(Q,K,V)=softmax(q3k1)v1+softmax(q3k2)v2+softmax(q3k3)v3 \\beginaligned \\mathrmAtt_1(Q, K, V) &amp;= \\mathrmsoftmax(\\mathbfq_1\\mathbfk_1^\\top)\\mathbfv_1 \\\\[7pt] \\mathrmAtt_2(Q, K, V) &amp;= \\mathrmsoftmax(\\mathbfq_2\\mathbfk_1^\\top)\\mathbfv_1+\\mathrmsoftmax(\\mathbfq_2\\mathbfk_2^\\top)\\mathbfv_2\\\\[7pt] \\mathrmAtt_3(Q, K, V) &amp;=\\mathrmsoftmax(\\mathbfq_3\\mathbfk_1^\\top)\\mathbfv_1+\\mathrmsoftmax(\\mathbfq_3\\mathbfk_2^\\top)\\mathbfv_2+\\mathrmsoftmax(\\mathbfq_3\\mathbfk_3^\\top)\\mathbfv_3 \\endaligned Attk\\mathrmAtt_k    qk\\mathbfq_k    KK  VV   KV cache Q cache
  kk  k1k-1  
 past_key_values  KK , VV 
 ((k,v), (k,v), ..., (k,v)) n_layer  (k,v)  k  v  [B, n_head, L, head_dims]
 token  past_key_values 
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # query:[B, H, 1, H_D] # key:[B, H, L+1, H_D] # value:[B, H, L+1, H_D] if layer_past is not None: past_key = layer_past[0] past_value = layer_past[1] key = torch.cat((past_key, key), dim=-2) value = torch.cat((past_value, value), dim=-2) if use_cache is True: present = (key, value) else: present = None # attn_weights:[B, H, 1, L+1] attn_weights = torch.matmul(query, key.transpose(-1, -2)) # causal mask mask_value = torch.tensor(torch.finfo(attn_weights.dtype).min) attn_weights = torch.where(causal_mask, attn_weights, mask_value) attn_weights = nn.Softmax(dim=-1)(attn_weights) # attn_output: [B, H, 1, H_D] attn_output = torch.matmul(attn_weights, value) # merge head:[B, 1, D] attn_output = self._merge_heads(attn_output, num_attention_heads, head_dim) if use_cache is True: presents = presents + (outputs[1],) KV Cache  LL  NN  dd hidden_size lnl_n   float16 2  2B(L+N)dln22 \\cdot B(L+N)dl_n \\cdot 2  float32 4  2B(L+N)dln42 \\cdot B(L+N)dl_n \\cdot 4 KV Cache   GPU  GPU 

 KV Cache 1.2 KV Cache      Context 8 
 KV Cache : 
 Context  Context  batch size  MHA &amp; MQA &amp; GQA &amp; MLA 
dd hidden size nhn_h  dhd_h  ll block  htRd\\mathbfh_t \\in \\mathbbR^d :  tt  token  hidden state MHA  MHA  :
[qt1;qt2;...;qtnh]=qt=htWQRdhnh,qtiRdh,WQRddhnh[kt1;kt2;...;ktnh]=kt=htWKRdhnh,ktiRdh,WKRddhnh[vt1;vt2;...;vtnh]=vt=htWVRdhnh,vtiRdh,WVRddhnh \\beginalign \\left [\\mathbfq_t^1;\\mathbfq_t^2;...;\\mathbfq_t^n_h \\right]=\\mathbfq_t = \\mathbfh_t \\mathbfW^Q\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfq_t^i\\in \\mathbbR^d_h, \\quad \\mathbfW^Q\\in \\mathbbR^d \\times d_h \\cdot n_h\\\\ \\\\ \\left [\\mathbfk_t^1;\\mathbfk_t^2;...;\\mathbfk_t^n_h\\right]=\\mathbfk_t = \\mathbfh_t \\mathbfW^K \\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfk_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^K\\in \\mathbbR^d \\times d_h \\cdot n_h\\\\ \\\\ \\left[\\mathbfv_t^1;\\mathbfv_t^2;...;\\mathbfv_t^n_h\\right]=\\mathbfv_t = \\mathbfh_t \\mathbfW^V\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfv_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^V\\in \\mathbbR^d \\times d_h \\cdot n_h \\endalign qti\\mathbfq_t^i , kti\\mathbfk_t^i , vti\\mathbfv_t^i  ii  ot=[ot1,ot2,,otnh]Rdhnhoti=j=1tSoftmaxj(qtikjidh)vjiRnhut=otWO=[ot1,ot2,,otnh]WORd,WORdhnhd \\beginalign &amp;\\mathbfo_t =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\in \\mathbbR^d_h\\cdot n_h\\\\ \\\\ &amp;\\mathbfo_t^i=\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrtd_h)\\mathbfv_j^i \\in \\mathbbR^n_h \\\\ \\\\ &amp;\\mathbfu_t =\\mathbfo_t\\mathbfW^O =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\mathbfW^O \\in \\mathbbR^d, \\quad \\mathbfW^O \\in \\mathbbR^d_h \\cdot n_h\\times d \\endalign WO\\mathbfW^O   key  value (KV Cache)
 token MHA  2nhdhl2n_hd_hl 
KV Cache 
KV Cache token by token  t+1t+1  token ktik^i_\\le t  vtiv^i_\\le t 
MQA MQA  Attention Head  KK  VV ,  MHA  k\\mathbfk  v\\mathbfv  i^i ,  kt\\mathbfk_t^*  vt\\mathbfv_t^* [qt1;qt2;...;qtnh]=qt=htWQRdhnh,qtiRdh,WQRddhnh[kt;kt;...;kt]=kt=htWKRdhnh,ktRdh,WKRddhnh[vt;vt;...;vt]=vt=htWVRdhnh,vtRdh,WVRddhnh \\beginalign \\left [\\mathbfq_t^1;\\mathbfq_t^2;...;\\mathbfq_t^n_h \\right]=\\mathbfq_t = \\mathbfh_t \\mathbfW^Q\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfq_t^i\\in \\mathbbR^d_h, \\quad \\mathbfW^Q\\in \\mathbbR^d \\times d_h \\cdot n_h\\\\ \\\\ \\left [\\mathbfk_t^*;\\mathbfk_t^*;...;\\mathbfk_t^*\\right] =\\mathbfk_t = \\mathbfh_t \\mathbfW^K \\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfk_t^* \\in \\mathbbR^d_h, \\quad \\mathbfW^K\\in \\mathbbR^d \\times d_h \\cdot n_h\\\\ \\\\ \\left [\\mathbfv_t^*;\\mathbfv_t^*;...;\\mathbfv_t^*\\right] =\\mathbfv_t = \\mathbfh_t \\mathbfW^V\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfv_t^* \\in \\mathbbR^d_h, \\quad \\mathbfW^V\\in \\mathbbR^d \\times d_h \\cdot n_h \\endalign ot=[ot1,ot2,,otnh]Rdhnhoti=j=1tSoftmaxj(qtikjdh)vjRnhut=otWO=[ot1,ot2,,otnh]WORd,WORdhnhd \\beginalign &amp;\\mathbfo_t =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\in \\mathbbR^d_h\\cdot n_h\\\\ \\\\ &amp;\\mathbfo_t^i=\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^* ^\\top\\sqrtd_h)\\mathbfv_j^* \\in \\mathbbR^n_h \\\\ \\\\ &amp;\\mathbfu_t =\\mathbfo_t\\mathbfW^O =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\mathbfW^O \\in \\mathbbR^d, \\quad \\mathbfW^O \\in \\mathbbR^d_h \\cdot n_h\\times d \\endalign MQA  KV Cache  1nh\\frac1n_h ,  token MQA  2dhl2d_hl  
 MQA 
MQA  KV Attention  FFN/GLU 
GQA GQA  Head  gg  gg  nhn_h  KK  VV [qt1;qt2;...;qtnh]=qt=htWQRdhnh,qtiRdh,WQRddhnh[kt1;;kt1nhg;ktg;;ktgnhg]=kt=htWKRdhnh,ktiRdh,WKRddhnh[vt1;;vt1nhg;vtg;;vtgnhg]=vt=htWVRdhnh,vtiRdh,WVRddhnh \\beginalign \\left [\\mathbfq_t^1;\\mathbfq_t^2;...;\\mathbfq_t^n_h \\right]=\\mathbfq_t = \\mathbfh_t \\mathbfW^Q\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfq_t^i\\in \\mathbbR^d_h, \\quad \\mathbfW^Q\\in \\mathbbR^d \\times d_h \\cdot n_h\\\\[7pt] \\left[ \\underbrace\\mathbfk_t^1;\\cdots;\\mathbfk_t^1_\\lceil \\fracn_hg \\rceil; \\cdots\\ \\underbrace\\mathbfk_t^g;\\cdots;\\mathbfk_t^g_\\lceil \\fracn_hg \\rceil \\right] =\\mathbfk_t = \\mathbfh_t \\mathbfW^K \\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfk_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^K\\in \\mathbbR^d \\times d_h \\cdot n_h\\\\[7pt] \\left[ \\underbrace\\mathbfv_t^1;\\cdots;\\mathbfv_t^1_\\lceil \\fracn_hg \\rceil; \\cdots\\ \\underbrace\\mathbfv_t^g;\\cdots;\\mathbfv_t^g_\\lceil \\fracn_hg \\rceil \\right] =\\mathbfv_t = \\mathbfh_t \\mathbfW^V\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfv_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^V\\in \\mathbbR^d \\times d_h \\cdot n_h \\endalign ot=[ot1,ot2,,otnh]Rdhnhoti=j=1tSoftmaxj(qtikjidh)vjiRnhut=otWO=[ot1,ot2,,otnh]WORd,WORdhnhd \\beginalign &amp;\\mathbfo_t =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\in \\mathbbR^d_h\\cdot n_h\\\\[7pt] &amp;\\mathbfo_t^i=\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrtd_h)\\mathbfv_j^i \\in \\mathbbR^n_h \\\\[7pt] &amp;\\mathbfu_t =\\mathbfo_t\\mathbfW^O =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\mathbfW^O \\in \\mathbbR^d, \\quad \\mathbfW^O \\in \\mathbbR^d_h \\cdot n_h\\times d \\endalign g=nhg=n_h MHA g=1g=1 MQA 1&lt;g&lt;nh1&lt;g&lt;n_h KV Cache  gnh\\fracgn_h   token GQA  2gdhl2gd_hl 
Llama2/3-70B GQA  g=8g=8  GQA  Attention  Head  8  g=8g=8  KK  VV  Attention Head KK  VV 
MLA MLA  key  value  KV cache
[qt1;qt2;...;qtnh]=qt=htWQRdhnh,qtiRdh,WQRddhnh[kt1;kt2;...;ktnh]=kt=ctKVWUKRdhnh,ktiRdh,WUKRdcdhnh[vt1;vt2;...;vtnh]=vt=ctKVWUVRdhnh,vtiRdh,WUVRdcdhnhctKV=htWDKVRdc,WDKVRddc \\beginalign \\left [\\mathbfq_t^1;\\mathbfq_t^2;...;\\mathbfq_t^n_h \\right]= &amp;\\mathbfq_t = \\mathbfh_t \\mathbfW^Q\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfq_t^i\\in \\mathbbR^d_h, \\quad \\mathbfW^Q\\in R^d \\times d_h \\cdot n_h\\\\ \\\\ \\left [\\mathbfk_t^1;\\mathbfk_t^2;...;\\mathbfk_t^n_h\\right]= &amp;\\mathbfk_t = \\mathbfc_t^KV \\mathbfW^UK \\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfk_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^UK\\in \\mathbbR^d_c \\times d_h \\cdot n_h\\\\ \\\\ \\left [\\mathbfv_t^1;\\mathbfv_t^2;...;\\mathbfv_t^n_h\\right]= &amp;\\mathbfv_t = \\mathbfc_t^KV \\mathbfW^UV\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfv_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^UV\\in \\mathbbR^d_c \\times d_h \\cdot n_h\\\\ \\\\ &amp;\\mathbfc_t^KV = \\mathbfh_t \\mathbfW^DKV\\in\\mathbbR^d_c,\\quad \\mathbfW^DKV\\in\\mathbbR^d\\times d_c \\endalign ctKV\\mathbfc_t^KV keys  values  dcd_c KV  dcdhnhd_c \\ll d_h \\cdot n_h WDKV\\mathbfW^DKV down-projection  WUK\\mathbfW^UK , WUV\\mathbfW^UV  key  value  up-projection  ot=[ot1,ot2,,otnh]Rdhnhoti=j=1tSoftmaxj(qtikjidh)vjiRdhut=otWO=[ot1,ot2,,otnh]WORd,WORdhnhd \\beginalign &amp;\\mathbfo_t =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\in \\mathbbR^d_h\\cdot n_h\\\\ \\\\ &amp;\\mathbfo_t^i=\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrtd_h)\\mathbfv_j^i \\in \\mathbbR^d_h \\\\ \\\\ &amp;\\mathbfu_t =\\mathbfo_t\\mathbfW^O =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\mathbfW^O \\in \\mathbbR^d, \\quad \\mathbfW^O \\in \\mathbbR^d_h \\cdot n_h\\times d \\endalign 
qtikji=(htWQ,i)(cjKVWUK,i)=ht(WQ,iWUK,i)qticjKVkjiuti=otiWO,i=j=1tSoftmaxj(qtikjidh)vjiWO,i=j=1tSoftmaxj(qtikjidh)cjKVoti(WUV,iWO,i)WO,i \\beginalign \\mathbfq_t^i \\mathbfk_j^i^\\top = \\left(\\mathbfh_t\\mathbfW^Q, i\\right) \\left(\\mathbfc_j^KV\\mathbfW^UK, i\\right)^\\top = \\underbrace\\mathbfh_t\\left(\\mathbfW^Q, i\\mathbfW^UK, i^\\top\\right)_\\mathbfq^\\prime_t^i \\underbrace\\mathbfc_j^KV_\\mathbfk^\\prime_j^i^\\top \\\\[7pt] \\mathbfu_t^i = \\mathbfo_t^i\\mathbfW^O, i =\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrtd_h)\\mathbfv_j^i \\mathbfW^O, i = \\underbrace\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrtd_h)\\mathbfc_j^KV_\\mathbfo^\\prime_t^i \\underbrace\\left(\\mathbfW^UV, i \\mathbfW^O, i\\right)_\\mathbfW^\\prime^O, i \\endalign  WQ,iWUK,i\\mathbfW^Q,i\\mathbfW^UK,i^\\top  QQ  cjKV\\mathbfc_j^KV  kj\\mathbfk_j  WUK,iWO,i\\mathbfW^UK,i \\mathbfW^O,i  cjKV\\mathbfc_j^KV  vj\\mathbfv_j MLA  KV Cache  ctKVRdc\\mathbfc^KV_t \\in\\mathbbR^d_c ,  kt,vtRdhnh\\mathbfk_t, \\mathbfv_t \\in \\mathbbR^d_h\\cdot n_h   dcdhnhd_c \\ll d_h \\cdot n_h  ctKV\\mathbfc^KV_t  head ii  MLA  MQA dcd_c  KV Cache 
 token MLA  dcld_cl 
WQ,iWUK,i\\mathbfW^Q,i\\mathbfW^UK,i^\\top  BF16 
  activation  query  KV 
[qt1;qt2;...;qtnh]=qt=ctQWUQRdhnh,qtiRdh,WUQRdcdhnhctQ=htWDQRdc,WDQRddc \\beginalign \\left [\\mathbfq_t^1;\\mathbfq_t^2;...;\\mathbfq_t^n_h \\right]=&amp;\\mathbfq_t = \\mathbfc_t^Q \\mathbfW^UQ\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfq_t^i\\in \\mathbbR^d_h, \\quad \\mathbfW^UQ\\in \\mathbbR^d_c^\\prime \\times d_h \\cdot n_h\\\\ \\\\ &amp;\\mathbfc_t^Q = \\mathbfh_t \\mathbfW^DQ\\in\\mathbbR^d_c^\\prime,\\quad \\mathbfW^DQ\\in\\mathbbR^d\\times d_c^\\prime \\\\ \\endalign ctQ\\mathbfc_t^Q query  dcd_c^\\prime query  dcdhnhd_c^\\prime \\ll d_h \\cdot n_h WDQW^DQ  down-projection  WUQW^UQ up-projection   RoPE
RoPE  MLA  ROPE 
qti=htWQ,iRtkti=ctKVWUK,iRtqtikji=(htWQ,iRt)(cjKVWUK,iRj)=ht(WQ,iRtjWUK,i)cjKV \\beginalign \\mathbfq_t^i &amp;= \\mathbfh_t \\mathbfW^Q, i\\textcolor#6D8E14\\mathbf\\mathcalR_t\\\\ \\\\ \\mathbfk_t^i &amp;= \\mathbfc_t^KV \\mathbfW^UK, i \\textcolor#6D8E14\\mathbf\\mathcalR_t \\\\ \\\\ \\mathbfq_t^i \\mathbfk_j^i^\\top &amp;= \\left(\\mathbfh_t\\mathbfW^Q, i\\textcolor#6D8E14\\mathbf\\mathcalR_t \\right) \\left( \\mathbfc_j^KV\\mathbfW^UK, i \\textcolor#6D8E14\\mathbf\\mathcalR_j \\right)^\\top = \\mathbfh_t\\left(\\mathbfW^Q, i \\textcolor#6D8E14\\mathbf\\mathcalR_t-j\\mathbfW^UK, i^\\top\\right) \\mathbfc_j^KV\\\\ \\\\ \\endalign  WQ,iRtjWUK,i\\mathbfW^Q,i \\textcolor#6D8E14\\mathbf\\mathcalR_t-j\\mathbfW^UK,i^\\top  WQ,iRtjWUK,i\\mathbfW^Q,i \\textcolor#6D8E14\\mathbf\\mathcalR_t-j\\mathbfW^UK,i^\\top  tjt-j 
 Attention Head  QQ  KK  dhRd_h^R  RoPE KK  Head 
ctQ=htWDQRdc,WDQRddc[qtC,1;qtC,2;;qtC,nh]=qtC=ctQWUQRdhnh,qtC,iRdh,WUQRdcdhnh[qtR,1;qtR,2;;qtR,nh]=qtR=ctQWQRRtRdhRnh,qtR,iRdhR,WQRRdcdhRnh[(qtC,1qtR,1);(qtC,2qtR,2);(qtC,nhqtR,nh)]=qtR(dh+dhR)nh \\beginaligned &amp;\\mathbfc_t^Q = \\mathbfh_t \\mathbfW^DQ\\in\\mathbbR^d_c^\\prime,\\quad \\mathbfW^DQ\\in\\mathbbR^d\\times d_c^\\prime\\\\ \\\\ \\left[\\mathbfq_t^C,1;\\mathbfq_t^C,2;\\cdots;\\mathbfq_t^C, n_h \\right] = &amp;\\mathbfq_t^C = \\mathbfc_t^Q \\mathbfW^UQ \\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfq_t^C, i\\in \\mathbbR^d_h, \\quad \\mathbfW^UQ\\in R^d_c^\\prime \\times d_h \\cdot n_h\\\\ \\\\ \\left[\\mathbfq_t^R,1;\\mathbfq_t^R,2;\\cdots;\\mathbfq_t^R, n_h \\right]= &amp;\\mathbfq_t^R = \\mathbfc_t^Q \\mathbfW^QR \\textcolor#6D8E14\\mathbf\\mathcalR_t \\in \\mathbbR^d_h^R\\cdot n_h, \\quad \\mathbfq_t^R, i\\in \\mathbbR^d_h^R, \\quad \\mathbfW^QR\\in R^d_c^\\prime \\times d_h^R \\cdot n_h\\\\ \\\\ \\left[ \\beginpmatrix\\mathbfq_t^C,1 &amp; \\mathbfq_t^R,1 \\endpmatrix; \\beginpmatrix\\mathbfq_t^C,2 &amp; \\mathbfq_t^R,2 \\endpmatrix; \\cdots \\beginpmatrix\\mathbfq_t^C, n_h &amp; \\mathbfq_t^R, n_h \\endpmatrix \\right] =&amp;\\mathbfq_t \\in \\mathbbR^(d_h+d_h^R)\\cdot n_h \\\\ \\endaligned ctKV=htWDKVRdc,WDKVRddc[ktC,1;ktC,2;...;ktC,nh]=ktC=ctKVWUKRdhnh,ktC,iRdh,WUKRdcdhnhktR=htWKRRtRdhR,WKRRddhR[(ktC,1ktR);(ktC,2ktR);(ktC,nhktR)]=ktR(dh+dhR)nh[vt1;vt2;...;vtnh]=vt=ctKVWUVRdhnh,vtiRdh,WUVRdcdhnh \\beginaligned &amp;\\mathbfc_t^KV = \\mathbfh_t \\mathbfW^DKV\\in\\mathbbR^d_c,\\quad \\mathbfW^DKV\\in\\mathbbR^d\\times d_c \\\\ \\\\ \\left [\\mathbfk_t^C,1;\\mathbfk_t^C,2;...;\\mathbfk_t^C, n_h\\right]= &amp;\\mathbfk_t^C = \\mathbfc_t^KV \\mathbfW^UK \\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfk_t^C, i \\in \\mathbbR^d_h, \\quad \\mathbfW^UK\\in \\mathbbR^d_c \\times d_h \\cdot n_h\\\\ \\\\ &amp;\\mathbfk_t^R = \\mathbfh_t \\mathbfW^KR \\textcolor#6D8E14\\mathbf\\mathcalR_t \\in \\mathbbR^d_h^R, \\quad \\mathbfW^KR\\in \\mathbbR^d \\times d_h^R\\\\ \\\\ \\left[ \\beginpmatrix\\mathbfk_t^C,1 &amp; \\mathbfk_t^R \\endpmatrix; \\beginpmatrix\\mathbfk_t^C,2 &amp; \\mathbfk_t^R \\endpmatrix; \\cdots \\beginpmatrix\\mathbfk_t^C, n_h &amp; \\mathbfk_t^R \\endpmatrix \\right] =&amp;\\mathbfk_t \\in \\mathbbR^(d_h+d_h^R)\\cdot n_h\\\\ \\\\ \\left [\\mathbfv_t^1;\\mathbfv_t^2;...;\\mathbfv_t^n_h\\right]= &amp;\\mathbfv_t = \\mathbfc_t^KV \\mathbfW^UV\\in \\mathbbR^d_h\\cdot n_h, \\quad \\mathbfv_t^i \\in \\mathbbR^d_h, \\quad \\mathbfW^UV\\in \\mathbbR^d_c \\times d_h \\cdot n_h\\\\[7pt] \\endaligned ot=[ot1,ot2,,otnh]Rdhnhoti=j=1tSoftmaxj(qtikji(dh+dhR))vjiRdhut=otWO=[ot1,ot2,,otnh]WORd,WORdhnhd \\beginalign &amp;\\mathbfo_t =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\in \\mathbbR^d_h\\cdot n_h\\\\ \\\\ &amp;\\mathbfo_t^i=\\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrt(d_h+d_h^R))\\mathbfv_j^i \\in \\mathbbR^d_h \\\\ \\\\ &amp;\\mathbfu_t =\\mathbfo_t\\mathbfW^O =\\left [\\mathbfo_t^1, \\mathbfo_t^2, \\cdots, \\mathbfo_t^n_h\\right] \\mathbfW^O \\in \\mathbbR^d, \\quad \\mathbfW^O \\in \\mathbbR^d_h \\cdot n_h\\times d \\endalign  RoPE  qtC\\mathbfq_t^C  ktC\\mathbfk_t^C   KV Cache  ctKVRdc\\mathbfc^KV_t \\in\\mathbbR^d_c   RoPE  Head  K Cache  dhRd_h^R  token  RoPE  MLA  (dc+dhR)l(d_c+d_h^R)l 
 DeepSeek-V2 dcd_c  4dh4d_h  dhRd^R_h  dh2\\fracd_h2 
Forward
DeepSeek-V2 
Config Value hidden_size dd hidden_size 5120  nhn_h num_attention_heads 128 Key Value  dcd_c kv_lora_rank 512 Query  dcd_c^\\prime q_lora_rank 1536 head_size dhd_h qk_nope_head_dim 128 RoPE  head_size dhRd_h^R qk_rope_head_dim 64 value head_size dhd_h v_head_dim 128 ctQ=htWDQRdc,WDQRddcctKV=htWDKVRdc,WDKVRddc \\beginalign \\mathbfc_t^Q &amp;= \\mathbfh_t \\mathbfW^DQ\\in\\mathbbR^d_c^\\prime,\\quad \\mathbfW^DQ\\in\\mathbbR^d\\times d_c^\\prime\\\\ \\\\ \\mathbfc_t^KV &amp;= \\mathbfh_t \\mathbfW^DKV\\in\\mathbbR^d_c,\\quad \\mathbfW^DKV\\in\\mathbbR^d\\times d_c \\endalign 
qti=[ctQWUQ,ictQWQR,iRt]Rdh+dhR,WUQ,iRdcdh,WQR,iRdcdhR,kti=[ctKVWUK,ihtWKRRt]Rdh+dhR,WUK,iRdcdh,WKRRddhRuti=otiWO,i=j=1tSoftmaxj(qtikji(dh+dhR))(cjKVWUV,i)WO,i \\beginalign \\mathbfq_t^i &amp;= \\beginbmatrix \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i &amp; \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix \\in\\mathbbR^\\textcolor#86422Fd_h + d_h^R,\\quad \\mathbfW^UQ, i\\in\\mathbbR^d_c&#x27;\\times d_h, \\quad \\mathbfW^QR, i\\in\\mathbbR^d_c&#x27;\\times d_h^R,\\\\ \\\\ \\mathbfk_t^i &amp;= \\beginbmatrix \\mathbfc_t^KV\\textcolor#A54F08\\mathbfW^UK, i &amp; \\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix \\in\\mathbbR^\\textcolor#86422Fd_h + d_h^R, \\quad \\mathbfW^UK, i\\in\\mathbbR^d_c\\times d_h, \\quad \\mathbfW^KR \\in\\mathbbR^d\\times d_h^R \\\\ \\\\ \\mathbfu_t^i &amp;= \\mathbfo_t^i\\mathbfW^O, i = \\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrt(d_h+d_h^R))\\left(\\mathbfc_j^KV \\textcolor#A54F08\\mathbfW^UV, i \\right)\\textcolor#A54F08\\mathbfW^O, i\\\\[7pt] \\endalign 
qti=[ctQWUQ,iWUK,ictQWQR,iRi]Rdc+dhR,WUQ,iRdcdh,WUK,iRdcdh,WQR,iRdcdhR,kti=[ctKVhtWKRRt]Rdc+dhR,WKRRddhRuti=otiWO,i=j=1tSoftmaxj(qtikji(dh+dhR))cjKV(WUV,iWO,i) \\beginalign \\mathbfq_t^i &amp;= \\beginbmatrix \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i\\mathbfW^UK, i^\\top &amp; \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_i \\endbmatrix \\in\\mathbbR^\\textcolor#86422Fd_c + d_h^R, \\quad \\mathbfW^UQ, i\\in\\mathbbR^d_c&#x27;\\times d_h, \\quad \\mathbfW^UK, i\\in\\mathbbR^d_c\\times d_h, \\quad \\mathbfW^QR, i\\in\\mathbbR^d_c&#x27;\\times d_h^R, \\\\ \\\\ \\mathbfk_t^i &amp;= \\beginbmatrix \\mathbfc_t^KV &amp; \\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix \\in\\mathbbR^\\textcolor#86422Fd_c + d_h^R, \\quad \\mathbfW^KR \\in\\mathbbR^d\\times d_h^R \\\\ \\\\ \\mathbfu_t^i &amp;= \\mathbfo_t^i\\mathbfW^O, i = \\sum_j = 1^t\\mathrmSoftmax_j(\\frac\\mathbfq_t^i\\mathbfk_j^i ^\\top\\sqrt(d_h+d_h^R))\\mathbfc_j^KV \\left(\\textcolor#A54F08\\mathbfW^UV, i \\mathbfW^O, i\\right)\\\\ \\\\ \\endalign  qtikji\\mathbfq_t^i\\mathbfk_j^i ^\\top     head_size  dh+dhRd_h+d_h^R  dc+dhRd_c+d_h^R ,  DeepSeek-V2  dh&lt;dcd_h&lt;d_c ,  &gt;  KV Cache   LLM  d=dhnhd = d_h\\cdot n_h  DeepSeek-V2  nhn_h  MLA  KV Cache  hh  hh  KV Cache Code
MLA 
 q_a_proj: WDQW^DQ q_b_proj: [WUQ,WQR][W^UQ, W^QR] kv_a_proj_with_mqa: [WDKV,WKR][W^DKV, W^KR] kv_b_proj: [WUK,WUV][W^UK,W^UV] o_proj WOW^O 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # q_head_dim: d_h+d_h^R if self.q_lora_rank is None: self.q_proj = nn.Linear( self.hidden_size, self.num_heads * self.q_head_dim, bias=False ) else: # W^DQ:[d, d_c&#39;] # [5120, 1536] self.q_a_proj = nn.Linear( self.hidden_size, config.q_lora_rank, bias=config.attention_bias ) self.q_a_layernorm = DeepseekV2RMSNorm(config.q_lora_rank) # [W^UQ, W^QR]:[d_c&#39;, n_h*(d_h+d_h^R)] # [1536 128*(128+64)] self.q_b_proj = nn.Linear( config.q_lora_rank, self.num_heads * self.q_head_dim, bias=False ) # [W^DKV, W^KR]:[d, d_c+d_h^R] # [5120 (512+64)] self.kv_a_proj_with_mqa = nn.Linear( self.hidden_size, config.kv_lora_rank + config.qk_rope_head_dim, bias=config.attention_bias, ) self.kv_a_layernorm = DeepseekV2RMSNorm(config.kv_lora_rank) # [W^UK,W^UV]:[d_c, n_h*(d_h+d_h)] # [512, 128*(128+128)] self.kv_b_proj = nn.Linear( config.kv_lora_rank, self.num_heads * (self.q_head_dim - self.qk_rope_head_dim + self.v_head_dim), bias=False, ) # W^O:[n_h*d_h, d] # [128*128, 5120] self.o_proj = nn.Linear( self.num_heads * self.v_head_dim, self.hidden_size, bias=config.attention_bias, ) self._init_rope() # softmax_scale: \\sqrt128+64 self.softmax_scale = self.q_head_dim ** (-0.5)  q_nope  q_pe 1 2 3 4 5 6 7 8 9 10 # [B,L5120] -&gt; [B, L, 1536] -&gt; [B, L24576] = [B, L128*(128+64)] q = self.q_b_proj(self.q_a_layernorm(self.q_a_proj(hidden_states))) # [B, L128*(128+64)] -&gt; [B, 128, L, (128+64)] q = q.view(bsz, q_len, self.num_heads, self.q_head_dim).transpose(1, 2) # [B, 128, L, 128+64] -&gt; [B, 128, L, 128], [B, 128, L, 64] q_nope, q_pe = torch.split( q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1 )  k_nope, k_pe  value_states 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # [B,L5120] -&gt; [B, L, (512+64)] compressed_kv = self.kv_a_proj_with_mqa(hidden_states) # [B, L, (512+64)] -&gt; [B, L, 512], [B, L, 64] compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) # [B, 1, L, 64] k_pe = k_pe.view(bsz, q_len, 1, self.qk_rope_head_dim).transpose(1, 2) # [B, L, 512] -&gt; [B, L, 128*(128+128)] -&gt; [B, 128, L, 128+128] kv = ( self.kv_b_proj(self.kv_a_layernorm(compressed_kv)) .view(bsz, q_len, self.num_heads, self.qk_nope_head_dim + self.v_head_dim) .transpose(1, 2) ) # [B, 128, L, 128+128] -&gt; [B, 128, L, 128], [B, 128, L, 128] k_nope, value_states = torch.split( kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1 )  query_states  key_states 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # RoPE q_pe, k_pe = apply_rotary_pos_emb(q_pe, k_pe, cos, sin, position_ids) # [B, 128, L, 128]+ [B, 128, L, 64] -&gt; [B, 128, L, (128+64)] query_states = k_pe.new_empty(bsz, self.num_heads, q_len, self.q_head_dim) query_states[:, :, :, : self.qk_nope_head_dim] = q_nope query_states[:, :, :, self.qk_nope_head_dim:] = q_pe # [B, 1, L, 64] -&gt; [B, 128, L, 64] # [B, 128, L, 128]+ [B, 128, L, 64] -&gt; [B, 128, L, (128+64)] key_states = k_pe.new_empty(bsz, self.num_heads, q_len, self.q_head_dim) key_states[:, :, :, : self.qk_nope_head_dim] = k_nope key_states[:, :, :, self.qk_nope_head_dim:] = k_pe # [B, 128, L, (128+64)] * [B, 128, (128+64), L] -&gt; [B, 128, L, L] attn_weights = ( torch.matmul(query_states, key_states.transpose(2, 3)) * self.softmax_scale )  attention 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 attn_weights = attn_weights + attention_mask # upcast attention to fp32 attn_weights = nn.functional.softmax( attn_weights, dim=-1, dtype=torch.float32 ).to(query_states.dtype) attn_weights = nn.functional.dropout( attn_weights, p=self.attention_dropout, training=self.training ) # [B, 128, L, L] -&gt; [B, 128, L, 128] attn_output = torch.matmul(attn_weights, value_states) # [B, 128, L, 128] -&gt; [B, L, 128, 128] attn_output = attn_output.transpose(1, 2).contiguous() # [B, L, 128, 128] -&gt; [B, L, 128*128] attn_output = attn_output.reshape(bsz, q_len, self.num_heads * self.v_head_dim) # [B, L, 128*128] -&gt; [B, L, 5120] attn_output = self.o_proj(attn_output) MLA  MLA 
 KV Cache  token  Cache   token   Cache Decompressed (CD) [ctKVWUK,ihtWKRRt]\\beginbmatrix\\mathbfc_t^KV\\textcolor#A54F08\\mathbfW^UK, i &amp; \\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix + cjKVWUV,i\\mathbfc_j^KV \\textcolor#A54F08\\mathbfW^UV, i 81.92 kB 0.08 MFLOP qkv 
 Cache Compressed (CC) [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix 1.152 kB 33.64 MFLOP qkv   Absorbed Cache Compressed (A_CC) [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix 1.152 kB 0.28 MFLOP qkv   Absorbed Cache Compressed Move Elision (A_CC_ME) [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix 1.152 kB 0.28 MFLOP qkv 
MoveElision Cache Decompressed (CD)
KV Cache: [ctKVWUK,ihtWKRRt]\\beginbmatrix\\mathbfc_t^KV\\textcolor#A54F08\\mathbfW^UK, i &amp; \\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix  cjKVWUV,i\\mathbfc_j^KV \\textcolor#A54F08\\mathbfW^UV, i BL128(128+64+128)=40960BLBL\\cdot 128 \\cdot (128+64+128) = 40960 \\cdot BL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 # [B,L5120] -&gt; [B, L, (512+64)] compressed_kv = self.kv_a_proj_with_mqa(hidden_states_kv) # [B, L, (512+64)] -&gt; [B, L, 512], [B, L, 64] compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) k_pe = k_pe.view(bsz, kv_seq_len, 1, self.qk_rope_head_dim).transpose(1, 2) # [B, L, 512] -&gt; [B, L, 128*(128+128)] -&gt; [B, 128, L, 128+128] kv = self.kv_b_proj(self.kv_a_layernorm(compressed_kv)).view( bsz, kv_seq_len, self.num_heads, self.qk_nope_head_dim + self.v_head_dim ).transpose(1, 2) # [B, 128, L, 128], [B, 128, L, 128] k_nope, value_states = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1) cos, sin = self.rotary_emb(value_states) k_pe = apply_rotary_pos_emb(k_pe, cos, sin, kv_position_ids) # [B, 128, L, 128+64] key_states = k_pe.new_empty(bsz, self.num_heads, kv_seq_len, self.q_head_dim) key_states[:, :, :, : self.qk_nope_head_dim] = k_nope key_states[:, :, :, self.qk_nope_head_dim:] = k_pe forward
 q_nope: ctQWUQ,i\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i  q_pe: ctQWQR,iRt\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_t q = self.q_b_proj(self.q_a_layernorm(self.q_a_proj(hidden_states_q))) q = q.view(bsz, q_len, self.num_heads, self.q_head_dim).transpose(1, 2) q_nope, q_pe = torch.split( q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1 )
cos, sin = self.rotary_emb(q_pe) q_pe = apply_rotary_pos_emb(q_pe, cos, sin, position_ids)
query_states: [ctQWUQ,ictQWQR,iRt]\\beginbmatrix\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i &amp; \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix : [B, 128, L, 128+64]
1 2 3 4 # [B, 128, L, 128+64] query_states = q_pe.new_empty(bsz, self.num_heads, q_len, self.q_head_dim) query_states[:, :, :, : self.qk_nope_head_dim] = q_nope query_states[:, :, :, self.qk_nope_head_dim:] = q_pe  attention
1 2 3 4 5 6 7 8 9 10 11 12 13 14 #  [B, 128, L, 128+64]*[B, 128, L, 128+64] attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) * self.softmax_scale kv_seq_len = key_states.size(2) # upcast attention to fp32 attn_weights = nn.functional.softmax( attn_weights, dim=-1, dtype=torch.float32 ).to(query_states.dtype) attn_output = torch.matmul(attn_weights, value_states) attn_output = attn_output.transpose(1, 2).contiguous() attn_output = attn_output.reshape(bsz, q_len, self.num_heads * self.v_head_dim) attn_output = self.o_proj(attn_output) Cache Compressed (CC)
 RoPE  k_pe  KV Cache
KV Cache: [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix BL(512+64)=576BLBL \\cdot (512+64) = 576 \\cdot BL 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # [B,L5120] -&gt; [B, L, (512+64)] compressed_kv = self.kv_a_proj_with_mqa(hidden_states_kv) # [B, L, (512+64)] -&gt; [B, L, 512], [B, L, 64] compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) # [B, L, 512] compressed_kv = self.kv_a_layernorm(compressed_kv) # [B, 1, L, 64] k_pe = k_pe.view(bsz, kv_seq_len, 1, self.qk_rope_head_dim).transpose(1, 2) cos, sin = self.rotary_emb(k_pe) k_pe = apply_rotary_pos_emb(k_pe, cos, sin, kv_position_ids).view( bsz, kv_seq_len,self.qk_rope_head_dim ) # [B, L, 512+64] compressed_kv = torch.cat([compressed_kv, k_pe], dim=-1) forward
 q_nope: ctQWUQ,i\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i  q_pe: ctQWQR,iRt\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_t :  Cache Decompressed (CD)
1 2 3 4 5 6 7 8 q = self.q_b_proj(self.q_a_layernorm(self.q_a_proj(hidden_states_q))) q = q.view(bsz, q_len, self.num_heads, self.q_head_dim).transpose(1, 2) q_nope, q_pe = torch.split( q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1 ) cos, sin = self.rotary_emb(q_pe) q_pe = apply_rotary_pos_emb(q_pe, cos, sin, position_ids)  compressed_kv 
compressed_kv: ctKV\\mathbfc_t^KV k_pe: htWKRRt\\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t 1 2 3 4 5 #  compressed compressed_kv, k_pe compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) k_pe = k_pe.view(bsz, kv_seq_len, 1, self.qk_rope_head_dim).transpose(1, 2)  kv_b_proj  WUKW^UK  WUVW^UV 1 2 3 4 5 6 7 # kv_b_proj.weight:[W^UK,W^UV]:[ n_h, (d_h+d_h), d_c] # [128, (128+128), 512] kv_b_proj = self.kv_b_proj.weight.view(self.num_heads, -1, self.kv_lora_rank) # W^UK  c_t^Q W^UQ  q_absorb = kv_b_proj[:, :self.qk_nope_head_dim, :] # W^UV  W^O  out_absorb = kv_b_proj[:, self.qk_nope_head_dim:, :] query_states: [ctQWUQ,iWUK,ictQWQR,iRi]\\beginbmatrix\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i\\mathbfW^UK, i^\\top &amp; \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_i \\endbmatrix : [B, 128, L, 512+64]
q_nope  q_absorb : WUKW^UK 1 2 3 4 # [B, 128, 512+64] query_states = k_pe.new_empty(bsz, self.num_heads, q_len, qk_head_dim) query_states[:, :, :, : self.kv_lora_rank] = torch.einsum(&#39;hdc,bhid-&gt;bhic&#39;, q_absorb, q_nope) query_states[:, :, :, self.kv_lora_rank:] = q_pe key_states: [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix : [B, 128, L, 512+64]
1 2 3 4 5 # [B, 128, 512+64] qk_head_dim = self.kv_lora_rank + self.qk_rope_head_dim key_states = k_pe.new_empty(bsz, self.num_heads, kv_seq_len, qk_head_dim) key_states[:, :, :, : self.kv_lora_rank] = compressed_kv.unsqueeze(1) key_states[:, :, :, self.kv_lora_rank:] = k_pe  attention
1 2 3 4 5 6 7 8 9 10 11 #  [B, 128, L, 512+64]*[B, 128, L, 512+64] attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) * self.softmax_scale # upcast attention to fp32 attn_weights = nn.functional.softmax( attn_weights, dim=-1, dtype=torch.float32 ).to(q_nope.dtype) # v attn_output = torch.einsum(&#39;bhql,blc-&gt;bhqc&#39;, attn_weights, compressed_kv) attn_output = torch.einsum(&#39;bhqc,hdc-&gt;bhqd&#39;, attn_output, out_absorb) Absorbed Cache Compressed (A_CC)
 RoPE  k_pe  KV Cache
KV Cache: [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix :  Cache Compressed (CC)
BL(512+64)=576BLBL \\cdot (512+64) = 576 \\cdot BL forward
 q_nope: ctQWUQ\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ  q_pe: ctQWQRRt\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR\\color#6D8E14\\mathbf\\mathcalR_t :  Cache Decompressed (CD)
1 2 3 4 5 6 7 8 q = self.q_b_proj(self.q_a_layernorm(self.q_a_proj(hidden_states_q))) q = q.view(bsz, q_len, self.num_heads, self.q_head_dim).transpose(1, 2) q_nope, q_pe = torch.split( q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1 ) cos, sin = self.rotary_emb(q_pe) q_pe = apply_rotary_pos_emb(q_pe, cos, sin, position_ids) query_states: [ctQWUQctQWQRRt]\\beginbmatrix\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ &amp; \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR\\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix [B, 128, L, 128+64]:  Cache Decompressed (CD)
1 2 3 4 # [B, 128, L, 128+64] query_states = q_pe.new_empty(bsz, self.num_heads, q_len, self.q_head_dim) query_states[:, :, :, : self.qk_nope_head_dim] = q_nope query_states[:, :, :, self.qk_nope_head_dim:] = q_pe key_states: [ctKVWUKhtWKRRt]\\beginbmatrix\\mathbfc_t^KV\\textcolor#A54F08\\mathbfW^UK &amp; \\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t \\endbmatrix [B, 128, L, 128+64]
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 kv_seq_len = compressed_kv.size(1) # [B, L, (512+64)] -&gt; [B, L, 512], [B, L, 64] compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) k_pe = k_pe.view(bsz, kv_seq_len, 1, self.qk_rope_head_dim).transpose(1, 2) # [B, L, 512] -&gt; [B, L, 128*(128+128)] -&gt; [B, 128, L, 128+128] kv = self.kv_b_proj(compressed_kv).view( bsz, kv_seq_len, self.num_heads, self.qk_nope_head_dim + self.v_head_dim ).transpose(1, 2) # [B, 128, L, 128], [B, 128, L, 128] k_nope, value_states = torch.split(kv, [self.qk_nope_head_dim, self.v_head_dim], dim=-1) key_states = k_pe.new_empty(bsz, self.num_heads, kv_seq_len, self.q_head_dim) key_states[:, :, :, : self.qk_nope_head_dim] = k_nope key_states[:, :, :, self.qk_nope_head_dim:] = k_pe  attention
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 #  [B, 128, L, 128+64]*[B, 128, L, 128+64] attn_weights = torch.matmul(query_states, key_states.transpose(2, 3)) * self.softmax_scale # avoid copying key-states # attn_weights = torch.matmul(q_nope, k_nope.transpose(2, 3)) + torch.matmul(q_pe, k_pe.transpose(2, 3)) # attn_weights *= self.softmax_scale # upcast attention to fp32 attn_weights = nn.functional.softmax( attn_weights, dim=-1, dtype=torch.float32 ).to(q_pe.dtype) attn_output = torch.matmul(attn_weights, value_states) attn_output = attn_output.transpose(1, 2).contiguous() attn_output = attn_output.reshape(bsz, q_len, self.num_heads * self.v_head_dim) attn_output = self.o_proj(attn_output) Absorbed Cache Compressed Move Elision (A_CC_ME)
 RoPE  k_pe  KV Cache
KV Cache: [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix :  Cache Compressed (CC)
BL(512+64)=576BLBL \\cdot (512+64) = 576 \\cdot BL forward
 q_nope: ctQWUQ\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ  q_pe: ctQWQRRt\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR\\color#6D8E14\\mathbf\\mathcalR_t :  Cache Decompressed (CD)
1 2 3 4 5 6 7 8 q = self.q_b_proj(self.q_a_layernorm(self.q_a_proj(hidden_states_q))) q = q.view(bsz, q_len, self.num_heads, self.q_head_dim).transpose(1, 2) q_nope, q_pe = torch.split( q, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=-1 ) cos, sin = self.rotary_emb(q_pe) q_pe = apply_rotary_pos_emb(q_pe, cos, sin, position_ids)  compressed_kv 
compressed_kv: ctKV\\mathbfc_t^KV k_pe: htWKRRt\\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t 1 2 3 4 5 #  compressed compressed_kv, k_pe compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) k_pe = k_pe.view(bsz, kv_seq_len, 1, self.qk_rope_head_dim).transpose(1, 2)  kv_b_proj  WUKW^UK  WUVW^UV 1 2 3 4 5 6 7 # kv_b_proj.weight:[W^UK,W^UV]:[ n_h, (d_h+d_h), d_c] # [128, (128+128), 512] kv_b_proj = self.kv_b_proj.weight.view(self.num_heads, -1, self.kv_lora_rank) # W^UK  c_t^Q W^UQ  q_absorb = kv_b_proj[:, :self.qk_nope_head_dim, :] # W^UV  W^O  out_absorb = kv_b_proj[:, self.qk_nope_head_dim:, :] q_nope  q_absorb : WUKW^UK 1 q_nope = torch.matmul(q_nope, q_absorb)  attention
MoveElision :  RoPE  RoPE  Attention Score  qtkj=qtCkjC+qtRkjR\\mathbfq_t\\mathbfk_j^\\top = \\mathbfq_t^C \\mathcalk_j^C^\\top+ \\mathbfq_t^R k_j^R^\\top )
1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # MoveElision [B, 128, L, 512]*[B, 128, L, 512] + [B, 128, L, 64]*[B, 128, L, 64] attn_weights = ( torch.matmul(q_pe, k_pe.mT) + torch.matmul(q_nope, compressed_kv.unsqueeze(-3).mT) ) * self.softmax_scale # upcast attention to fp32 attn_weights = nn.functional.softmax( attn_weights, dim=-1, dtype=torch.float32 ).to(q_nope.dtype) attn_output = torch.einsum(&#39;bhql,blc-&gt;bhqc&#39;, attn_weights, compressed_kv) # torch.einsum(&#39;bhqc,hdc-&gt;bhqd&#39;, attn_output, out_absorb) attn_output = torch.matmul(attn_output, out_absorb.mT) attn_output = attn_output.transpose(1, 2).contiguous() attn_output = attn_output.reshape(bsz, q_len, self.num_heads * self.v_head_dim) attn_output = self.o_proj(attn_output) Absorbed materialized Cache Compressed Move elision (AM_CC_ME)
 RoPE  k_pe  KV Cache
KV Cache: [ctKVhtWKRRt]\\beginbmatrix \\mathbfc_t^KV &amp;\\mathbfh_t \\textcolor#A54F08\\mathbfW^KR \\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix :  Cache Compressed (CC)
BL(512+64)=576BLBL \\cdot (512+64) = 576 \\cdot BL forward
 WQRW^QR  WUQWUK\\textcolor#A54F08\\mathbfW^UQ\\mathbfW^UK^\\top  WUVWO\\textcolor#A54F08\\mathbfW^UV \\mathbfW^O 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 def get_absorbed_proj(self) -&gt; Tuple[torch.Tensor, torch.Tensor, torch.Tensor]: #  if not hasattr(self, &#39;_absorbed&#39;): #  bias  assert self.q_b_proj.bias is None and self.kv_b_proj.bias is None and self.o_proj.bias is None # [128, (128+64), 1536] q_b_proj = self.q_b_proj.weight.view(self.num_heads, -1, self.q_lora_rank) # W^UQ, W^QR # [n_h, nope_hd, q_lora_rank], [n_h, rope_hd, q_lora_rank] # [128, 128, 1536], [128, 64, 1536] q_b_proj_nope, q_b_proj_rope = torch.split( q_b_proj, [self.qk_nope_head_dim, self.qk_rope_head_dim], dim=1 ) # [128, (128+128), 1536] kv_b_proj = self.kv_b_proj.weight.view(self.num_heads, -1, self.kv_lora_rank) # W^UK, W^UV # [n_h, nope_hd, kv_lora_rank], [n_h, v_hd, kv_lora_rank] # [128, 128, 512], [128, 64, 512] q_absorb, out_absorb = torch.split( kv_b_proj, [self.qk_nope_head_dim, self.v_head_dim], dim=1 ) # [5120, 128, 128] o_proj = self.o_proj.weight.view(self.hidden_size, self.num_heads, self.v_head_dim) # q_abosrbed: W^UQ*W^UK^T # [n_h, kv_lora_rank, q_lora_rank] # [128, 512, 1536] q_absorbed = torch.einsum(&#39;hdq,hdk-&gt;hkq&#39;, q_b_proj_nope, q_absorb) # out_absorbed: W^UV*W^O # [hidden_size, n_h, kv_lora_rank] # [5120, 128, 512] out_absorbed = torch.einsum(&#39;hvk,dhv-&gt;dhk&#39;, out_absorb, o_proj) self._absorbed = q_b_proj_rope, q_absorbed, out_absorbed return self._absorbed q: [q_nope, q_pe]: [ctQWUQ,iWUK,ictQWQR,iRi]\\beginbmatrix\\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^UQ, i\\mathbfW^UK, i^\\top &amp; \\mathbfc_t^Q\\textcolor#A54F08\\mathbfW^QR, i\\color#6D8E14\\mathbf\\mathcalR_i\\endbmatrix [B, 128, L, 512+64]
1 2 3 4 5 6 7 q_b_proj_rope, q_absorbed, out_absorbed = self.get_absorbed_proj() q = self.q_a_layernorm(self.q_a_proj(hidden_states_q)) q_nope = torch.einsum(&#39;bqc,hdc-&gt;bhqd&#39;, q, q_absorbed) q_pe = torch.einsum(&#39;bqc,hdc-&gt;bhqd&#39;, q, q_b_proj_rope) cos, sin = self.rotary_emb(q_pe) q_pe = apply_rotary_pos_emb(q_pe, cos, sin, q_position_ids) k: [compressed_kv, k_pe]: [ctKVhtWKRRt]\\beginbmatrix\\mathbfc_t^KV&amp;\\mathbfh_t\\textcolor#A54F08\\mathbfW^KR\\color#6D8E14\\mathbf\\mathcalR_t\\endbmatrix [B, 128, L, 512+64]
1 2 3 4 5 kv_seq_len = compressed_kv.size(1) compressed_kv, k_pe = torch.split( compressed_kv, [self.kv_lora_rank, self.qk_rope_head_dim], dim=-1 ) k_pe = k_pe.view(bsz, 1, kv_seq_len, self.qk_rope_head_dim)  attention
MoveElision :  RoPE  RoPE  Attention Score  qtkj=qtCkjC+qtRkjR\\mathbfq_t\\mathbfk_j^\\top = \\mathbfq_t^C \\mathcalk_j^C^\\top+ \\mathbfq_t^R k_j^R^\\top )
1 2 3 4 5 6 7 8 9 # MoveElision [B, 128, L, 512]*[B, 128, L, 512] + [B, 128, L, 64]*[B, 128, L, 64] attn_weights = ( torch.matmul(q_pe, k_pe.mT) + torch.matmul(q_nope, compressed_kv.unsqueeze(-3).mT) ) * self.softmax_scale attn_weights = nn.functional.softmax( attn_weights, dim=-1, dtype=torch.float32 ).to(q_nope.dtype) attn_output = torch.einsum(&#39;bhql,blc-&gt;bhqc&#39;, attn_weights, compressed_kv) attn_output = torch.einsum(&#39;bhqc,dhc-&gt;bqd&#39;, attn_output, out_absorbed)  WUKW^UK  WUQW^UQ  WUVW^UV  WOW^O 
 WUKW^UK  WUQW^UQ  HH  15365121536 \\times 512  128 WUVW^UV  WOW^O  HH  51205125120 \\times 512 
Reference DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model  MHAMQAGQA  MLA DeepSeek-V2  (1) MLA `}).add({id:11,tag:"en",href:"/blogs/distributedtraining/",title:"",description:"DP & DDPTPPPZeRO",content:`(DP &amp; DDP) DataParallel DP  GPU  GPU  batch  GPU 


 DP 
DP  forward 
 batch  device 
 device 
 device 
 device 
 device  device  device  device 
3-4 

 device 
DP DP  Parameter Server 
DistributedDataParallel 

init_process_group
 parameterbuffer model = DDP(model).to(local_rank)
 reducer hook

 

parameter  buffer  DDP  find_unused_parameter  true  forward  ready 
reducer 
  grad hook  reducer  ready reducer 
 bucket  ready reducer  bucket  all-reduce   bucket reducer  parameter.grad  
DDP  DP  DP DDP  1.  GIL  2.   1.     1.   optimizer 2  GPU,  GPU  3.  GPU Broadcast   GPU   1.   optimizer 2.  3. Ring All-Reduce    4.    GPU  Ring All-Reduce  GPU  DDP  ( broadcast)
TP (Tensor Parallelism) Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism
   GPU  GPU  GPU 
MLP   XR(BL)D\\mathbfX \\in \\mathbbR^(B\\times L) \\times D  BB  LL  DD 
 B=1B=1  XRLD\\mathbfX \\in \\mathbbR^L \\times D MLP 
 ARDD\\mathbf A \\in \\mathbbR^D\\times D^\\prime ( DD^\\prime  DD  44 ) GELU
 BRDD\\mathbf B \\in \\mathbbR^D^\\prime \\times D  Z=(XA)B\\mathbf Z = \\sigma(\\mathbf X \\cdot \\mathbf A) \\mathbf B GPU 
 ARDD\\mathbf A \\in \\mathbbR^D\\times D^\\prime  DD^\\prime  X\\mathbfX GPU  BRDD\\mathbf B \\in \\mathbbR^D^\\prime \\times D  DD^\\prime   A\\mathbf A  nn  A=[A1,,An]\\mathbf A= \\beginbmatrix\\mathbf A_1,\\cdots, \\mathbf A_n \\endbmatrix  AiRDDn\\mathbf A_i \\in \\mathbbR^D \\times \\fracD^\\primen :
XA=[XA1,,XAn],XAiRLDn \\mathbf X \\cdot \\mathbf A = \\beginbmatrix\\mathbf X \\mathbf A_1,\\cdots, \\mathbf X\\mathbf A_n \\endbmatrix , \\quad \\mathbf X \\mathbf A_i \\in \\mathbbR^L\\times \\fracD^\\primen GeLU
[Y1,,Yn]=[GeLU(XA1),,GeLU(XAn)],YiRLDn \\beginbmatrix\\mathbf Y_1,\\cdots, \\mathbf Y_n\\endbmatrix = \\beginbmatrix\\operatornameGeLU\\left(\\mathbf X \\mathbf A_1\\right),\\cdots, \\operatornameGeLU \\left(\\mathbf X\\mathbf A_n \\right)\\endbmatrix , \\quad \\mathbf Y_i \\in \\mathbbR^L\\times \\fracD^\\primen  B\\mathbf B  nn  B=[B1,,Bn]\\mathbf B= \\beginbmatrix\\mathbf B_1,\\cdots, \\mathbf B_n \\endbmatrix^\\top  BiRDnD\\mathbf B_i \\in \\mathbfR^\\fracD^\\primen\\times D 
Z=inZi=[Y1,,Yn][B1,,Bn],ZRLD \\mathbf Z =\\sum_i^n\\mathbf Z_i = \\beginbmatrix\\mathbf Y_1,\\cdots, \\mathbf Y_n\\endbmatrix \\beginbmatrix\\mathbf B_1,\\cdots, \\mathbf B_n \\endbmatrix^\\top , \\quad \\mathbf Z \\in \\mathbbR^L\\times D  MLP -  GPU
Self-Attention  
 XR(BL)D\\mathbfX \\in \\mathbbR^(B\\times L) \\times D  BB  LL  DD 
 B=1B=1  XRLD\\mathbfX \\in \\mathbbR^L \\times D 
 X\\mathbfX  X\\mathbfX  Q\\mathbf Q  K\\mathbf K  V\\mathbf V 
 Dh\\fracDh ,  h=2h=2  X\\mathbfX  Q\\mathbf Q  K\\mathbf K  Softmax  V\\mathbf V  LDhL \\times \\fracDh 
 GPU 00  GPU 11  all reduce 
 22  all reduce( MLP+Self-Attention ) TP 
 TP
 44  GPU TP  44  TP  88  88  GPU 
PP (Pipeline Parallelism) GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism
 GPU   () :
 GPU   GPU  batch   44  GPU ( GPU) F0F_0  F1F_1  F2F_2  F3F_3  44  B3B_3  B2B_2  B1B_1  B0B_0 
 PP  
PP PP   (chunks) chunks=4\\textchunks = 4 
GPU 00  chunk 00  11  22  33 ( F0,0F_0,0  F0,1F_0,1  F0,2F_0,2  F0,3F_0,3 ) 
 GPU GPU 00  33  22  11  00 ( B0,3B_0,3  B0,2B_0,2  B0,1B_0,1  B0,0B_0,0 ) 
 (gradient accumulation stepsGAS) PyTorch chunks DeepSpeed  GAS 
Gradient Accumulation 
  (chunksPP  micro-batches (MBS) 
DP  batch size  batch size
 dp_degree=4\\textdp\\_degree = 4  batch_sizeall=1024\\textbatch\\_size_\\textall=1024  44  batch sizebatch batch_sizedp=1024/4=256\\textbatch\\_size_\\textdp=1024/4 = 256 
 chunks=32\\textchunks = 32  microbatch_size=256/32=8\\textmicro batch\\_size = 256/32= 8 
 micro batch
 DP + PP : mbschunksdp_degree(8324=1024) \\textmbs*\\textchunks*\\textdp\\_degree (8*32*4=1024)  mini-batch  micro-batch pipipline  micro-batch  micro-batch  micro-batch  Bubble( Bubble)
ZeRO ZeRO: Memory Optimizations Toward Training Trillion Parameter Models
 Model States  GPU  GPU
ZeRO 
ZeRO  GPU  GPU 
  Model States  Residual states 
Model States
Optimizer States
Optimizer States  Optimizer  SGD  Momentum  Float32 Master Parameters
Gradient

Model Parameter

DDP Optimizer States 
  \\mathbf\\Phi ,  \\mathbf\\Phi fp16fp16  fp32 
(2+2+K) (2 +2+K)\\mathbf\\Phi Residual States
 activationbufferfragmentation
ZeRO-DP Model States ZeRO  Model States  (Paritition) Pos\\textP_\\textos  Pos+g\\textP_\\textos+\\textg  Pos+g+p\\textP_\\textos+\\textg+\\textp  ZeRO-1ZeRO-2ZeRO-3
ZeRO-1 [ Pos\\textP_\\textos ]  Optimizer States
parametersgradients 2+2+KNd2\\mathbf\\Phi+2\\mathbf\\Phi+ \\fracK \\cdot \\mathbf\\PhiN_d  NN  44\\mathbf\\Phi 
ZeRO-2 [ Pos+g\\textP_\\textos+\\textg ]  Optimizer States  Gradients
 2+(2+K)Nd2\\mathbf\\Phi+ \\frac(2+K) \\cdot \\mathbf\\PhiN_d  NN  22\\mathbf\\Phi 
ZeRO-3 [ Pos+g+p\\textP_\\textos+\\textg+\\textp ]  Optimizer StatesGradients  Parameters
 (2+2+K)Nd\\frac(2+2+K) \\cdot \\mathbf\\PhiN_d  NN  00 
ZeRO-1  ZeRO-2  ZeRO-3  W\\mathbf W ( 50%50\\% )
ZeRO V.S.  ZeRO 
 forward  backward  W\\mathbf W 
  X GPU 
ZeRO  forward  backward  GPU  W\\mathbf W 
  W  X\\mathbf X  W\\mathbf W 
ZeRO-RResidual States PP_\\alpha : Partitioned Activation Checkpointing
activation 
 checkpointing activation GPU  activationactivation 
CBC_B : Constant Size Buffer 
 AllReduce
  bucket 
 buffer
 GPU GPU  buffer 

MDM_D : Memory Defragmentation 
 gradient checkpointing 
 checkpointed activation  discarded activation
 fail
ZeRO-Offload forward  backward  W\\mathbf W fp16activation GPU
update  CPU   W\\mathbf W (fp32)optimizer statesfp32 gradients(fp16)
 Mixed Precision Training
 float 3232 bit 44  float16 1212 bit 22  
 
  fp16 
 batchsize  
 GPU  fp16  GPU  22 - 88  
 Overflow / Underflow Underflow   Rounding Error Mixed Precision  fp16  fp32 
 fp32 (accumulated)
 fp32  fp16 
FP32  
weights, activations, gradients   fp16 
fp32  weight 
 activations  batchsize  activations   activiations  back-propogation 
 activation  fp16  fp32  
 fp32  weights
 weightt=weightt1+lrgradients \\textweight_t= \\text weight_t-1+ \\textlr \\cdot \\textgradients  lrgradients \\textlr \\cdot \\textgradients  fp16    Rounding Error
 weights  fp32 update fp32 
 Loss Scale  fp16 underflow 
fp16  underflow 
Loss Scale
 loss  scaleloss  scale  scale  scaled  fp16 
 dLoss 2k2^k   2k2^k  scaled-gradient  fp16  scaled-gradient  fp32 scale 
 Broadcast Broadcast 
Scatter Scatter 
Gather Gather  Scatter  root 
Reduce Reduce 
  MPI_Reduce  root  00  MPI_SUM  reduction   44  root 
 22    ii  00  ii 
All-reduce All-reduce  Reduce  All-reduce 
 All-reduce  Scatter  reduce-scatter  reduce-scatter  all reduce 
Ring-All-Reduce All-Reduce  Ring Ring-AllReduce  reduce-scatter  all-gather 
 33  33  reduce-scatter  all-gather 
 nn  nn  ii  ii  n1n-1  reduce-scatter  all-gather
Reduce-scatter  22  reduce 
All-gather  reduce-scatter reduce all-gather  22   reduce 
Ring-AllReduce   W  \\mathbf\\Phi GPU  NN  \\mathbf\\Phi  N\\frac\\mathbf\\PhiN  GPU  send 
Reduce-Scatter  (N1)N(N-1)\\frac\\mathbf\\PhiN All-Gather  (N1)N(N-1)\\frac\\mathbf\\PhiN  2(N1)N2(N-1)\\frac\\mathbf\\PhiN  NN  22\\mathbf\\Phi   2N2N\\mathbf\\Phi  Worker 
Reference Megatron-LM: Training Multi-Billion Parameter Language Models Using Model Parallelism
GPipe: Easy Scaling with Micro-Batch Pipeline Parallelism
ZeRO: Memory Optimizations Toward Training Trillion Parameter Models
Mixed Precision Training
python-parallel-programmning-cookbook
MPI Reduce and Allreduce`}).add({id:12,tag:"en",href:"/blogs/%E8%87%AA%E4%BF%A1%E6%81%AF%E4%BA%92%E4%BF%A1%E6%81%AF%E7%86%B5/",title:"&&",description:"",content:`  self-information 
   
 bitnat  hart
   
 00  100%100\\% 
 n\\omega_n 
n\\omega_n 
I(n)=log(P(n))=log(1P(n)) \\beginequation \\operatorname I (\\omega _n)=-\\log\\bigg(\\operatorname P (\\omega _n)\\bigg)=\\log \\left(\\frac 1\\operatorname P (\\omega _n)\\right) \\endequation  22  bit  ee  nat  1010  hart  CC  AA  BB  CC  AA  BB 
I(C)=I(AB)=I(A)+I(B) \\beginalign \\operatorname I (C)=\\operatorname I (A\\cap B)=\\operatorname I (A)+\\operatorname I (B) \\endalign 
  Mutual InformationMI  
MI 
MI  (X,Y)\\displaystyle \\displaystyle (X,Y)  X\\displaystyle X  Y\\displaystyle Y 
MI Pointwise Mutual InformationPMI
  
  (X,Y)(X , Y)  XY\\mathcal X\\times \\mathcal Y   p(x,y)p(x,y)  p(x)p(x)  p(y)p(y)   
I(X;Y)=KL(p(x,y)p(x)p(y)) \\beginalign I(X; Y)= KL\\big(p(x, y)\\|p(x)\\times p(y)\\big) \\endalign  KLKL  KL  (KullbackLeibler divergence)
 KL   p(x,y)p(x,y)  p(x)p(x)  p(y)p(y)  I(X,Y)=0I(X,Y)=0  XX  YY  YY  XX 
:
I(X;Y)=yYxXp(x,y)log(p(x,y)p(x)p(y)) \\beginalign I(X; Y)=\\sum _y\\in Y\\sum _x\\in Xp(x, y)\\log \\left(\\frac p(x, y)p(x)\\, p(y)\\right) \\endalign 
I(X;Y)=YXp(x,y)log(p(x,y)p(x)p(y))dxdy \\beginalign I(X; Y)=\\int _Y\\int _Xp(x, y)\\log \\left(\\frac p(x, y)p(x)\\, p(y)\\right)\\; dx\\ dy \\endalign   XX  YY  XX  YY 
  XX  YY 
 XX  YY  XX  YY  
I(X;Y)=0I(X; Y) = 0  XX  YY  
 XX  YY   YY  XX   XX  YY  XX  YY 
 YY  XX  YY  XX   XX  YY  XX  YY 
 
I(X;Y)0 \\beginalign \\displaystyle I(X; Y)\\geq 0 \\endalign 
I(X;Y)=I(Y;X) \\beginalign \\displaystyle I(X; Y)= I(Y; X) \\endalign   
H(Y)H(Y) 
H(YX)H(Y|X) &ldquo; XX  YY &rdquo; 
H(Y)H(YX)H(Y)-H(Y|X) &quot; YY &quot; &ldquo; XX  YY &rdquo;
I(X;Y)I(X;Y)  XX  YY  YY  XX  YY  YY  XX 
;


I(X;Y)=H(X)H(XY)=H(Y)H(YX)=H(X)+H(Y)H(X,Y)=H(X,Y)H(XY)H(YX) \\beginaligned I(X; Y)&amp;= H(X)-H(X|Y)\\\\ &amp;= H(Y)-H(Y|X)\\\\ &amp;= H(X)+H(Y)-H(X, Y)\\\\ &amp;= H(X, Y)-H(X|Y)-H(Y|X) \\endaligned 
I(X;Y)=x,yp(x,y)logp(x,y)p(x)p(y)=x,yp(x,y)logp(x,y)p(x)x,yp(x,y)logp(y)=x,yp(x)p(yx)logp(yx)x,yp(x,y)logp(y)=xp(x)(yp(yx)logp(yx))ylogp(y)(xp(x,y))=xp(x)H(YX=x)ylogp(y)p(y)=H(Y)H(YX) \\beginaligned I(X; Y)&amp;=\\sum _x, yp(x, y)\\log \\frac p(x, y)p(x)p(y)\\\\ &amp;=\\sum _x, yp(x, y)\\log \\frac p(x, y)p(x)-\\sum _x, yp(x, y)\\log p(y)\\\\ &amp;=\\sum _x, yp(x)p(y|x)\\log p(y|x)-\\sum _x, yp(x, y)\\log p(y)\\\\ &amp;=\\sum _xp(x)\\left(\\sum _yp(y|x)\\log p(y|x)\\right)-\\sum _y\\log p(y)\\left(\\sum _xp(x, y)\\right)\\\\ &amp;=-\\sum _xp(x)H(Y|X = x)-\\sum _y\\log p(y)p(y)\\\\ &amp;= H(Y)-H(Y|X)\\\\ \\endaligned 
I(X;X)=H(X)H(XX)=H(X)I(X;Y) \\beginaligned I(X; X) &amp;= H(X) - H(X|X)\\\\ &amp;= H(X) \\\\ &amp;\\ge I(X; Y) \\endaligned  XX  p(x)p(x)  YY  XX  p(xy)p(x|y)  p(xy)p(x|y)  p(x)p(x) 
I(X;Y)=yp(y)xp(xy)log2p(xy)p(x)=yp(y)DKL(p(xy)p(x))=EYDKL(p(xy)p(x)) \\beginaligned I(X; Y)&amp;=\\sum _yp(y)\\sum _xp(x|y)\\log _2\\frac p(x|y)p(x)\\\\&amp;=\\sum _yp(y)\\; D_\\mathrm KL (p(x|y)\\|p(x))\\\\&amp;=\\mathbb E _Y\\D_\\mathrm KL (p(x|y)\\|p(x))\\ \\endaligned  entropy 
  

 
 bit ShnatHart 
            H(X)=I(X;X)H(X) = I(X;X)  I(X;X)I(X;X)  XX 
 Xx1,,xnX \\in \\x_1,\\cdots, x_n\\  HH 
H(X)=E[I(X)]=E[ln(P(X))] \\beginalign \\mathrm H (X)=\\mathrm E [\\mathrm I (X)] =\\mathrm E [-\\ln(\\mathrm P (X))] \\endalign P\\mathrm P  XX probability mass function E\\mathrm E  I(X)\\mathrm I (X)  XX  
H(X)=iP(xi)I(xi)=iP(xi)logbP(xi) \\beginalign \\mathrm H (X)=\\sum _i\\mathrm P (x_i)\\,\\mathrm I (x_i)=-\\sum _i\\mathrm P (x_i)\\log _b\\mathrm P (x_i) \\endalign  b=2b = 2  bit  b=eb = e  nat  b=10b = 10 ,  Hart Example:
 SS  S=E1,...,EnS = \\E_1,...,E_n\\  P=p1,...,pnP = \\p_1, ..., p_n\\ 
Ie=log2piI_e=-\\log _2p_i  2  bit Ie=lnpiI_e=-\\ln p_i  e\\displaystyle e  nats)  26 
Ie=log2126=4.7 \\beginalign I_e=-\\log _21 \\over 26= 4.7 \\endalign 
Ie=log2150=5.64 \\beginalign I_e=-\\log _21 \\over 50= 5.64 \\endalign  2500 
Ie=log212500=11.3 \\beginalign I_e=-\\log _21 \\over 2500= 11.3 \\endalign  H(X)=Hn(p1,,pn)\\mathrm H (X) = \\mathrm H _n(p_1,\\ldots ,p_n) 
 pip_i 
Hn(p1,p2,)=Hn(p2,p1,) \\beginalign \\mathrm H _n\\left(p_1, p_2,\\ldots \\right)=\\mathrm H _n\\left(p_2, p_1,\\ldots \\right) \\endalign 
Hn(p1,,pn)Hn(1n,,1n)=logb(n) \\beginalign \\mathrm H _n(p_1,\\ldots , p_n)\\leq \\mathrm H _n\\left(\\frac 1n,\\ldots ,\\frac 1n\\right)=\\log _b(n) \\endalign 
Hn(1n,,1nn)=logb(n)&lt;logb(n+1)=Hn+1(1n+1,,1n+1n+1) \\beginalign \\mathrm H _n\\bigg (\\underbrace \\frac 1n,\\ldots ,\\frac 1n _n\\bigg )=\\log _b(n)&lt;\\log _b(n+1)=\\mathrm H _n+1\\bigg (\\underbrace \\frac 1n+1,\\ldots ,\\frac 1n+1 _n+1\\bigg ) \\endalign 

 nn  kk  b1,...,bkb_1, ..., b_k 
 bib_i  b1+...+bk=nb_1 + ... + b_k = n 
Hn(1n,,1n)=Hk(b1n,,bkn)+i=1kbinHbi(1bi,,1bi) \\beginalign \\mathrm H _n\\left(\\frac 1n,\\ldots ,\\frac 1n\\right)=\\mathrm H _k\\left(\\frac b_1n,\\ldots ,\\frac b_kn\\right)+\\sum _i = 1^k\\frac b_in\\,\\mathrm H _b_i\\left(\\frac 1b_i,\\ldots ,\\frac 1b_i\\right) \\endalign  k=nk=n  b1=...=bn=1b_1=...=b_n=1  H1(1)=0H_1(1)=0    XX 

Hn+1(p1,,pn,0)=Hn(p1,,pn) \\beginalign \\mathrm H _n+1(p_1,\\ldots , p_n,0)=\\mathrm H _n(p_1,\\ldots , p_n) \\endalign  logbn\\log_b n 
H(X)=E[logb(1p(X))]logb(E[1p(X)])=logb(n) \\beginalign \\mathrm H (X)=\\operatorname E \\left [\\log _b\\left(\\frac 1p(X)\\right)\\right]\\leq \\log _b\\left(\\operatorname E \\left[\\frac 1p(X)\\right]\\right)=\\log _b(n) \\endalign  (X,Y)(X,Y)  XX  YY :  YY  YY  XX 
H(X,Y)=H(XY)+H(Y)=H(YX)+H(X) \\beginalign \\mathrm H (X, Y)=\\mathrm H (X|Y)+\\mathrm H (Y)=\\mathrm H (Y|X)+\\mathrm H (X) \\endalign  Y=f(X)Y=f(X)  ff  H(f(X)X)=0(f(X)|X) = 0 H(X)+H(f(X)X)=H(X)=H(f(X))+H(Xf(X)) \\beginalign \\mathrm H (X)+\\mathrm H (f(X)|X)=\\mathrm H (X) =\\mathrm H (f(X))+\\mathrm H (X|f(X)) \\endalign  H(f(X))H(X)(f(X)) \\le (X) 
 XX  YY  YY  XX 
H(XY)=H(X) \\beginalign \\mathrm H (X|Y)=\\mathrm H (X) \\endalign  XX  YY  (X,Y)(X,Y) 
H(X,Y)H(X)+H(Y) \\beginalign \\mathrm H (X, Y)\\leq \\mathrm H (X)+\\mathrm H (Y) \\endalign   
 X\\displaystyle X  Y\\displaystyle Y   
H(X,Y)=xyP(x,y)log[P(x,y)] \\beginalign \\mathrm H (X, Y)=-\\sum _x\\sum _yP(x, y)\\log [P(x, y)] \\endalign  x\\displaystyle x  y\\displaystyle y  X\\displaystyle X  Y\\displaystyle Y , , P(x,y)\\displaystyle P(x,y) ,  P(x,y)=0\\displaystyle P(x,y)=0  P(x,y)log[P(x,y)]P(x,y)\\log [P(x,y)]  0
 X1,...,Xn\\displaystyle X_1,...,X_n 
H(X1,...,Xn)=x1...xnP(x1,...,xn)log[P(x1,...,xn)] \\beginalign \\mathrm H (X_1,..., X_n)=-\\sum _x_1...\\sum _x_nP(x_1,..., x_n)\\log [P(x_1,..., x_n)] \\endalign  

H(X,Y)max[H(X),H(Y)]H(X1,...,Xn)max[H(X1),...,H(Xn)] \\beginalign \\mathrm H (X, Y) &amp;\\geq \\max [\\mathrm H (X),\\mathrm H (Y)]\\\\ \\mathrm H (X_1,..., X_n) &amp;\\geq \\max [H(X_1),..., H(X_n)] \\endalign 
 X\\displaystyle X  Y\\displaystyle Y 
H(X,Y)H(X)+H(Y)H(X1,...,Xn)H(X1)+...+H(Xn) \\beginalign \\mathrm H (X, Y) &amp;\\leq \\mathrm H (X)+\\mathrm H (Y)\\\\ \\mathrm H (X_1,..., X_n) &amp;\\leq \\mathrm H (X_1)+...+\\mathrm H (X_n) \\endalign     X\\displaystyle X  Y\\displaystyle Y  ShnatHart  X\\displaystyle X  Y\\displaystyle Y  H(YX)\\displaystyle \\mathrm H (Y|X) 
 H(YX=x)H(Y|X=x)  YY  XX  xx  H(YX)H(Y|X)  XX  xx 
 XX  YY  X\\mathcal X  Y\\mathcal Y  XX  YY 
H(YX)xXp(x)H(YX=x)=xXp(x)yYp(yx)logp(yx)=xXyYp(x,y)logp(yx)=xX,yYp(x,y)logp(yx)=xX,yYp(x,y)logp(x,y)p(x).=xX,yYp(x,y)logp(x)p(x,y). \\beginaligned \\mathrm H (Y|X)\\ &amp;\\equiv \\sum _x\\in \\mathcal X\\, p(x)\\,\\mathrm H (Y|X = x)\\\\ &amp;=-\\sum _x\\in \\mathcal Xp(x)\\sum _y\\in \\mathcal Y\\, p(y|x)\\,\\log \\, p(y|x)\\\\ &amp;=-\\sum _x\\in \\mathcal X\\sum _y\\in \\mathcal Y\\, p(x, y)\\,\\log \\, p(y|x)\\\\ &amp;=-\\sum _x\\in \\mathcal X, y\\in \\mathcal Yp(x, y)\\log \\, p(y|x)\\\\ &amp;=-\\sum _x\\in \\mathcal X, y\\in \\mathcal Yp(x, y)\\log \\frac p(x, y)p(x).\\\\ &amp;=\\sum _x\\in \\mathcal X, y\\in \\mathcal Yp(x, y)\\log \\frac p(x)p(x, y).\\\\ \\endaligned H(YX)=0\\mathrm H (Y|X)=0  YY  XX  H(YX)=H(Y)\\mathrm H (Y|X)=\\mathrm H (Y)  Y\\displaystyle Y  X\\displaystyle X    XX  YY    H(X,Y)\\displaystyle \\mathrm H (X,Y)  H(X,Y)\\displaystyle \\mathrm H (X,Y) bits 
 X\\displaystyle X  H(X)\\displaystyle \\mathrm H (X) bits   X\\displaystyle X  H(X,Y)H(X)\\displaystyle \\mathrm H (X,Y)-\\mathrm H (X) bits   H(YX)\\mathrm H (Y|X) 
H(YX)=H(X,Y)H(X) \\beginalign \\mathrm H (Y|X)\\,=\\,\\mathrm H (X, Y)-\\mathrm H(X) \\endalign 
H(YX)=xX,yYp(x,y)logp(x)p(x,y)=xX,yYp(x,y)logp(x,y)+xX,yYp(x,y)logp(x)=H(X,Y)H(X) \\beginaligned \\mathrmH(Y|X) &amp;= \\sum_x \\in \\mathcalX, y \\in \\mathcalY p(x, y) \\log \\fracp(x)p(x, y) \\\\ &amp;= -\\sum_x \\in \\mathcalX, y \\in \\mathcalY p(x, y) \\log p(x, y) + \\sum_x \\in \\mathcalX, y \\in \\mathcalY p(x, y) \\log p(x) \\\\ &amp;= \\mathrmH(X, Y) - \\mathrmH(X) \\endaligned  H(YX)=H(XY)H(X)+H(Y) \\beginalign H(Y|X)\\,=\\, H(X|Y)-H(X)+H(Y) \\endalign KL  KL Kullback-Leibler divergence KLD
 relative entropy  randomness  information gain information divergence KL   PP  QQ  
  p(x)p(x)   q(x)q(x)  q(x) q(x)  xx  q(x)q(x)  p(x)p(x)  p(x)p(x) ( nat )
 
KL(PQ)=p(x)lnq(x)(p(x)lnp(x)dx)=p(x)ln[q(x)p(x)]dx=p(x)ln[p(x)q(x)]dx \\beginalign KL(P||Q) &amp;= \\int p(x) \\ln q(x) - \\bigg( -\\int p(x) \\ln p(x) dx \\bigg)\\\\ &amp;= - \\int p(x) \\ln [\\fracq(x)p(x)] dx \\\\ &amp;= \\int p(x) \\ln [\\fracp(x)q(x)] dx \\endalign  :
KL(PQ)=ip(i)ln[q(i)p(i)]=ip(i)ln[p(i)q(i)] \\beginalign KL(P||Q) &amp;= \\sum_i p(i) \\ln [\\fracq(i)p(i)] \\\\ &amp;= \\sum_i p(i) \\ln [\\fracp(i)q(i)] \\endalign  PP  PP  QQ 
 p(x)p(x)  q(x)q(x)  (relative entropy) KL  ( Kullback-Leibler divergence )
 KL 
KL 
 PP  QQ   XX  PP  QQ  PP  QQ  KL  
KL(PQ)=Xln(dPdQ)dP \\beginalign KL(P||Q) =\\int_X \\ln (\\fracdPdQ)dP \\endalign  dQdP\\fracdQdP  QQ  PP  RN 
KL(PQ)=Xln(dPdQ)dP=XdPdQln(dPdQ)dQ \\beginalign KL(P||Q) =\\int_X\\ln(\\fracdPdQ)dP = \\int_X \\fracdPdQ\\ln(\\fracdPdQ)dQ \\endalign  PP  QQ  
 KL 
 p(x)p(x)  q(x)q(x|\\theta)  p(x)p(x)  q(x)q(x|\\theta)  \\theta )
 p(x)p(x)  q(x)q(x|\\theta)  \\theta  KL  \\theta 
 p(x)
 p(x)p(x)  xnx_n  n=1,,Nn=1,,N  p(x)p(x)  E(f)1Nn=1Nf(xn)E(f)\\simeq \\frac1N\\sum_n=1^Nf(x_n) 
KL(pq)1Nn=1N[lnq(xn)+lnp(xn)] \\beginalign KL(p||q)\\simeq \\frac1N\\sum_n = 1^N[ \\ln q(x_n|\\theta)+ \\ln p(x_n)] \\endalign  \\theta  q(x)q(x|\\theta)  \\theta 
 KL 
 
KL  KL(pq)0 KL(p||q)\\ge 0 , 
 KL   p(x)p(x)  q(x)q(x) 

KL   () KL(pq)KL(qp) KL(p||q)\\neq KL(q||p) 

KL KL  
  pp  qq  ** Cross entropy**  
 pp  qq  pp  qq  
H(p,q)=Ep[lnq]=H(p)+KL(pq) \\beginalign H(p, q)=\\operatorname E _p[-\\ln q] = H(p)+ KL(p\\|q) \\endalign  H(p)H(p)  pp  KL(pq)KL(p\\|q)   pp  qq  KL 
 
H(p,q)=p(x)ln[q(x)]dx \\beginalign H(p, q)= -\\int p(x) \\ln [q(x)] dx \\endalign  
H(p,q)=ip(i)lnq(i) \\beginalign H(p, q)=-\\sum _ip(i) \\ln q(i) \\endalign 
DKL(PQ)=i=1NP(xi)[logP(x)logQ(x)]=i=1NP(xi)logP(xi)i=1NP(xi)logQ(xi)=[i=1NP(xi)logP(xi)]+[i=1NP(xi)logQ(xi)]=H(P)+H(P,Q) \\beginequation \\beginsplit D_KL(P||Q) &amp;= \\sum_i = 1^N P(x_i)[\\log P(x) - \\log Q(x)] \\\\ &amp;= \\sum_i = 1^N P(x_i) \\log P(x_i) - \\sum_i = 1^N P(x_i) \\log Q(x_i) \\\\ &amp;= -[- \\sum_i = 1^N P(x_i) \\log P(x_i)]+ [ - \\sum_i = 1^N P(x_i) \\log Q(x_i) ] \\\\ &amp;= - H(P) + H(P, Q) \\endsplit \\endequation   x=x\\textx = x  self-information
I(x)=logP(x) \\beginalign I(x) = -\\log P(x) \\endalign x\\mathrmx  x1,x2,...,xi,...,xNx_1, x_2,...,x_i,..., x_N  xx  x\\mathrmx   2  I(x)I(x)  bit  e  I(x)I(x)  nat  10  I(x)I(x)  hart  Shannon entropy
H(x)=ExP[I(x)]=i=1NP(xi)I(xi)=i=1NP(xi)logP(xi) \\beginequation H(\\textx) = \\mathbbE_\\textx \\sim P[I(x)] = \\sum_i = 1^N P(x_i)I(x_i) = - \\sum_i = 1^N P(x_i)\\log P(x_i) \\endequation  x\\mathrmx  differential entropy
KL Kullback-Leibler (KL) divergence
KL 
 P(x)P(x)  Q(x)Q(x)  KL 
DKL(PQ)=ExP[logP(x)Q(x)]=ExP[logP(x)logQ(x)] \\beginequation D_KL(P||Q) = \\mathbbE_\\textx \\sim P[\\log \\fracP(x)Q(x)] = \\mathbbE_\\textx \\sim P[\\log P(x) - \\log Q(x)] \\endequation :
DKL(PQ)=p(x)log[p(x)q(x)]dx \\beginequation D_KL(P\\|Q) =\\int p(x) \\log [\\fracp(x)q(x)] dx \\endequation 
DKL(PQ)=iP(xi)log[P(xi)Q(xi)] \\beginalign D_KL(P||Q) &amp;=\\sum_i P(x_i)\\log [\\fracP(x_i)Q(x_i)] \\endalign 
H(P,Q)=H(P)+DKL(PQ) \\beginalign H(P, Q) = H(P) + D_KL(P||Q) \\endalign H(P)H(P)  H(x)H(x)  xPxP  PP  DKL(PQ)D_KL(P||Q)  KL   P(x)P(x)  H(P)H(P)  H(P)H(P)  KL  H(P)H(P) 
 x\\mathrmx H(P,Q)=ExPlogQ(x)=i=1NP(xi)logQ(xi) \\beginequation H(P, Q) = - \\mathbbE_\\textx \\sim P\\log Q(x) = - \\sum_i = 1^N P(x_i) \\log Q(x_i) \\endequation  PP 
KL  QQ  PP 
 QQ  PP  
Example  KL 
KL 
 label  1 1 KL  KL 
 KL  a  b a  0.6 b  0.8
Reference    ()    `}),search.addEventListener("input",showResults,!0)}function hideSuggestions(e){var t=suggestions.contains(e.target);t||(suggestions.classList.add("d-none"),background!==null&&background.style.setProperty("--image-opacity","0.1"))}function inputFocus(e){e.ctrlKey&&e.key==="/"&&(e.preventDefault(),search.focus()),e.key==="Escape"&&(search.blur(),suggestions.classList.add("d-none"))}function suggestionFocus(e){const s=suggestions.classList.contains("d-none");if(s)return;const t=[...suggestions.querySelectorAll("a")];if(t.length===0)return;const n=t.indexOf(document.activeElement);if(e.key==="ArrowUp"){e.preventDefault();const s=n>0?n-1:0;t[s].focus()}else if(e.key==="ArrowDown"){e.preventDefault();const s=n+1<t.length?n+1:n;t[s].focus()}}function showResults(){const s=5;var t,e=this.value;const o=document.documentElement.lang;t=null,e?(t=index.search(e,{index:["title","description","content"],limit:s,tag:o,enrich:!0}),background!==null&&background.style.setProperty("--image-opacity","0")):background!==null&&background.style.setProperty("--image-opacity","0.1");const n=new Map;if(t!==null)for(const e of t.flatMap(e=>e.result)){if(n.has(e.doc.href))continue;n.set(e.doc.href,e.doc)}if(suggestions.innerHTML="",suggestions.classList.remove("d-none"),n.size===0&&e){const n=suggestions.dataset.noResults,t=document.createElement("div");t.innerHTML=`${n} "<strong>${e}</strong>"`,t.classList.add("suggestion__no-results"),suggestions.appendChild(t);return}for(const[r,a]of n){const o=document.createElement("div");suggestions.appendChild(o);const e=document.createElement("a");e.href=r,o.appendChild(e);const t=document.createElement("span");t.classList.add("text-start"),t.textContent=a.title,t.classList.add("suggestion__title"),e.appendChild(t);const i=document.createElement("span");if(i.textContent=a.description,i.classList.add("suggestion__description"),e.appendChild(i),suggestions.appendChild(o),suggestions.childElementCount==s)break}}search!==null&&suggestions!==null&&(document.addEventListener("keydown",inputFocus),document.addEventListener("keydown",suggestionFocus),document.addEventListener("click",hideSuggestions),initIndex());const searchModal=document.getElementById("search-modal");searchModal!==null&&searchModal.addEventListener("shown.bs.modal",function(){const e=document.getElementById("search-input-modal");e!==null&&e.focus({focusVisible:!0})}),document.querySelectorAll(".dynamic-svg").forEach(e=>{e.onload=function(){const t=e.parentElement,s=e.contentDocument,o=e.getAttribute("data-class"),n=e.getAttribute("data-style");if(t!==null&&s!==null){const e=s.querySelector("svg");e!==null&&(e.setAttribute("class","svg-inline--fa "+(o||"")),e.setAttribute("fill","currentcolor"),e.setAttribute("aria-hidden","true"),e.setAttribute("role","img"),n!==null&&n!==""&&e.setAttribute("style",n),e.removeAttribute("height"),e.removeAttribute("width"),t.innerHTML="",t.appendChild(e))}}});const fixed=!0,navbar=document.querySelector(".navbar"),togglers=document.querySelectorAll(".main-nav-toggler"),modeSelectors=document.querySelectorAll(".switch-mode-collapsed"),colorsBG=["body","secondary","tertiary"];function updateNavbar(){let e;if(typeof getLocalStorage=="function"&&(e=getLocalStorage("theme",null,"functional")),window.scrollY>75)navbar.classList.add("nav-active"),e&&navbar.setAttribute("data-bs-theme",e);else{navbar.classList.remove("nav-active");const t=navbar.getAttribute("data-bs-overlay"),n=t||e;n&&navbar.setAttribute("data-bs-theme",t)}}if(navbar!==null&&window.performance.getEntriesByType&&window.performance.getEntriesByType("navigation")[0].type==="reload"&&fixed&&updateNavbar(),navbar!==null&&togglers!==null){const t=document.querySelector("html"),n={attributes:!0,attributeFilter:["data-bs-theme"]},s=new MutationObserver(e=>{fixed&&updateNavbar()});s.observe(t,n);const e=navbar.getAttribute("data-navbar-color")||"body",o=colorsBG.includes(e)?`var(--bs-${e}-bg)`:`var(--bs-navbar-color-${e})`;navbar.style.setProperty("--bs-navbar-expanded-color",o),window.onscroll=()=>{fixed&&updateNavbar()};for(let e=0;e<togglers.length;++e)togglers[e].onclick=()=>{navbar.classList.toggle("navbar-expanded")};for(let e=0;e<modeSelectors.length;++e)modeSelectors[e].onclick=()=>{for(let e=0;e<togglers.length;++e){const t=togglers[e];t.getAttribute("aria-expanded")==="true"&&t.click()}}}const popoverTriggerList=document.querySelectorAll('[data-bs-toggle="popover"]'),popoverList=[...popoverTriggerList].map(e=>new bootstrap.Popover(e));function webShareAPI(e,t,n){navigator.share({title:e,text:t,url:n}).then(()=>console.log("Successful share")).catch(e=>console.log("Error sharing",e))}const shareButtons=document.querySelectorAll("[data-sharing-url]");shareButtons.forEach(e=>{if(navigator.share){const t=e.getAttribute("data-sharing-title"),n=e.getAttribute("data-sharing-description"),s=e.getAttribute("data-sharing-url");e.style.display="block",e.addEventListener("click",()=>webShareAPI(t,n,s))}else e.style.display="none"});const container=document.getElementById("toast-container");container!==null&&document.querySelectorAll("[data-toast-target]").forEach(e=>{const t=document.getElementById(e.getAttribute("data-toast-target"));if(t!==null){container.appendChild(t);const n=bootstrap.Toast.getOrCreateInstance(t);n!==null&&e.addEventListener("click",()=>{n.show()})}});const tooltipTriggerList=document.querySelectorAll('[data-bs-toggle="tooltip"]'),tooltipList=[...tooltipTriggerList].map(e=>new bootstrap.Tooltip(e));document.querySelectorAll("[data-video-padding]").forEach(e=>{e.style.paddingBottom=e.getAttribute("data-video-padding")})